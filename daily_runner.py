"""
EPS Momentum Daily Runner v19 - Safety & Trend Fusion

ê¸°ëŠ¥:
1. NTM EPS ì „ ì¢…ëª© ìˆ˜ì§‘ + MA60 ê³„ì‚° & DB ì ì¬
2. í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ 2ì¢… + ë¡œê·¸ ìƒì„± & ë°œì†¡
   - [1/2] ë§¤ìˆ˜ í›„ë³´ + ì‹œì¥ì§€ìˆ˜ + Death List + ë³´ìœ  í™•ì¸
   - [2/2] AI ì ê²€ + ìµœì¢… ì¶”ì²œ í¬íŠ¸í´ë¦¬ì˜¤ (í†µí•©)
   - ì‹œìŠ¤í…œ ë¡œê·¸ (ê°œì¸ë´‡)
3. Git ìë™ commit/push

ì‹¤í–‰: python daily_runner.py
"""

import os
import sys
import io
import json
import sqlite3
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
try:
    import pytz
    HAS_PYTZ = True
except ImportError:
    HAS_PYTZ = False
import warnings
warnings.filterwarnings('ignore')

# Windowsì—ì„œ UTF-8 ì¸ì½”ë”© ê°•ì œ ì ìš© (ì´ëª¨ì§€ ì§€ì›)
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent
DB_PATH = PROJECT_ROOT / 'eps_momentum_data.db'
CONFIG_PATH = PROJECT_ROOT / 'config.json'

# ê¸°ë³¸ ì„¤ì •
DEFAULT_CONFIG = {
    "git_enabled": True,
    "git_remote": "origin",
    "git_branch": "master",
    "telegram_enabled": False,
    "telegram_bot_token": "",
    "telegram_chat_id": "",
    "telegram_channel_id": "",
    "telegram_private_id": "",
}


def load_config():
    """ì„¤ì • ë¡œë“œ (config.json â†’ í™˜ê²½ë³€ìˆ˜ ìˆœìœ¼ë¡œ ì²´í¬)"""
    if CONFIG_PATH.exists():
        with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
            config = json.load(f)
            for key, value in DEFAULT_CONFIG.items():
                if key not in config:
                    config[key] = value
    else:
        with open(CONFIG_PATH, 'w', encoding='utf-8') as f:
            json.dump(DEFAULT_CONFIG, f, indent=2, ensure_ascii=False)
        config = DEFAULT_CONFIG.copy()

    # í™˜ê²½ë³€ìˆ˜ ì˜¤ë²„ë¼ì´ë“œ (GitHub Actionsìš©)
    if os.environ.get('TELEGRAM_BOT_TOKEN'):
        config['telegram_bot_token'] = os.environ['TELEGRAM_BOT_TOKEN']
        config['telegram_enabled'] = True
    if os.environ.get('TELEGRAM_CHAT_ID'):
        config['telegram_channel_id'] = os.environ['TELEGRAM_CHAT_ID']
    if os.environ.get('TELEGRAM_PRIVATE_ID'):
        config['telegram_private_id'] = os.environ['TELEGRAM_PRIVATE_ID']
        config['telegram_chat_id'] = os.environ['TELEGRAM_PRIVATE_ID']

    config['is_github_actions'] = bool(os.environ.get('GITHUB_ACTIONS'))

    # Gemini API í‚¤ (AI ë¶„ì„ìš©)
    if os.environ.get('GEMINI_API_KEY'):
        config['gemini_api_key'] = os.environ['GEMINI_API_KEY']

    return config


def log(message, level="INFO"):
    """ë¡œê·¸ ì¶œë ¥"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] [{level}] {message}")


# ============================================================
# NTM EPS ë°ì´í„° ìˆ˜ì§‘
# ============================================================

def init_ntm_database():
    """ntm_screening í…Œì´ë¸” ìƒì„±"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    cursor.execute('''
        CREATE TABLE IF NOT EXISTS ntm_screening (
            date        TEXT,
            ticker      TEXT,
            rank        INTEGER,
            score       REAL,
            ntm_current REAL,
            ntm_7d      REAL,
            ntm_30d     REAL,
            ntm_60d     REAL,
            ntm_90d     REAL,
            is_turnaround INTEGER DEFAULT 0,
            adj_score   REAL,
            adj_gap     REAL,
            price       REAL,
            ma60        REAL,
            part2_rank  INTEGER,
            PRIMARY KEY (date, ticker)
        )
    ''')

    # ê¸°ì¡´ DB ë§ˆì´ê·¸ë ˆì´ì…˜: ìƒˆ ì»¬ëŸ¼ ì¶”ê°€
    for col, col_type in [('adj_score', 'REAL'), ('adj_gap', 'REAL'),
                          ('price', 'REAL'), ('ma60', 'REAL'), ('part2_rank', 'INTEGER')]:
        try:
            cursor.execute(f'ALTER TABLE ntm_screening ADD COLUMN {col} {col_type}')
        except sqlite3.OperationalError:
            pass  # ì´ë¯¸ ì¡´ì¬

    # ê¸°ì¡´ eps_snapshots í…Œì´ë¸” ì‚­ì œ
    cursor.execute('DROP TABLE IF EXISTS eps_snapshots')

    conn.commit()
    conn.close()
    log("NTM ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")


def run_ntm_collection(config):
    """NTM EPS ì „ ì¢…ëª© ìˆ˜ì§‘ & DB ì ì¬

    ìµœì í™”:
    - ê°€ê²© ë°ì´í„°: yf.download() ì¼ê´„ ë‹¤ìš´ë¡œë“œ (ë‚´ì¥ ìŠ¤ë ˆë”©)
    - ì¢…ëª© ì •ë³´: JSON ìºì‹œ (shortName, industry)
    - EPS ë°ì´í„°: ìˆœì°¨ ì²˜ë¦¬ (yfinance ìŠ¤ë ˆë”© ë¹„í˜¸í™˜)

    Returns:
        tuple (results_df, turnaround_df, stats_dict)
    """
    import yfinance as yf
    import pandas as pd

    from eps_momentum_system import (
        INDICES, INDUSTRY_MAP,
        calculate_ntm_eps, calculate_ntm_score, calculate_eps_change_90d,
        get_trend_lights,
    )

    init_ntm_database()

    today = datetime.now()
    today_str = os.environ.get('MARKET_DATE') or ''
    if not today_str:
        try:
            spy_hist = yf.Ticker("SPY").history(period="5d")
            today_str = spy_hist.index[-1].strftime('%Y-%m-%d')
        except Exception:
            today_str = today.strftime('%Y-%m-%d')
    log(f"ë§ˆì¼“ ë‚ ì§œ: {today_str}")

    all_tickers = sorted(set(t for tlist in INDICES.values() for t in tlist))
    log(f"ìœ ë‹ˆë²„ìŠ¤: {len(all_tickers)}ê°œ ì¢…ëª©")

    # Step 1: ì¢…ëª© ì •ë³´ ìºì‹œ ë¡œë“œ
    cache_path = PROJECT_ROOT / 'ticker_info_cache.json'
    ticker_cache = {}
    if cache_path.exists():
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                ticker_cache = json.load(f)
            log(f"ì¢…ëª© ì •ë³´ ìºì‹œ ë¡œë“œ: {len(ticker_cache)}ê°œ")
        except Exception:
            ticker_cache = {}

    # Step 2: ê°€ê²© ë°ì´í„° ì¼ê´„ ë‹¤ìš´ë¡œë“œ
    log("ê°€ê²© ë°ì´í„° ì¼ê´„ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    hist_all = None
    try:
        hist_all = yf.download(all_tickers, period='6mo', threads=True, progress=False)
        log("ê°€ê²© ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        log(f"ì¼ê´„ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}, ê°œë³„ ë‹¤ìš´ë¡œë“œë¡œ ì „í™˜", "WARN")

    # Step 3: ì¢…ëª©ë³„ EPS ë°ì´í„° ìˆœì°¨ ìˆ˜ì§‘
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    results = []
    turnaround = []
    no_data = []
    errors = []
    cache_updated = False

    for i, ticker in enumerate(all_tickers):
        if (i + 1) % 100 == 0:
            log(f"  ìˆ˜ì§‘ ì§„í–‰: {i+1}/{len(all_tickers)} (ë©”ì¸: {len(results)}, í„´ì–´ë¼ìš´ë“œ: {len(turnaround)})")
            conn.commit()

        try:
            stock = yf.Ticker(ticker)

            # NTM EPS ê³„ì‚°
            ntm = calculate_ntm_eps(stock, today)
            if ntm is None:
                no_data.append(ticker)
                continue

            # Score ê³„ì‚°
            score, seg1, seg2, seg3, seg4, is_turnaround, adj_score, direction = calculate_ntm_score(ntm)
            eps_change_90d = calculate_eps_change_90d(ntm)
            trend_lights, trend_desc = get_trend_lights(seg1, seg2, seg3, seg4)

            # EPS Revision & ì• ë„ë¦¬ìŠ¤íŠ¸ ìˆ˜ ì¶”ì¶œ â€” max(0y, +1y)ë¡œ ë‘ ê¸°ê°„ ëª¨ë‘ ë°˜ì˜
            rev_up30 = 0
            rev_down30 = 0
            num_analysts = 0
            try:
                raw_trend = stock._analysis._earnings_trend
                if raw_trend:
                    for item in raw_trend:
                        if item.get('period') in ('0y', '+1y'):
                            eps_rev = item.get('epsRevisions', {})
                            up_data = eps_rev.get('upLast30days', {})
                            down_data = eps_rev.get('downLast30days', {})
                            up_val = up_data.get('raw', 0) if isinstance(up_data, dict) else 0
                            down_val = down_data.get('raw', 0) if isinstance(down_data, dict) else 0
                            ea = item.get('earningsEstimate', {})
                            na_data = ea.get('numberOfAnalysts', {})
                            na_val = na_data.get('raw', 0) if isinstance(na_data, dict) else 0
                            rev_up30 = max(rev_up30, up_val)
                            rev_down30 = max(rev_down30, down_val)
                            num_analysts = max(num_analysts, na_val)
            except Exception:
                pass

            # DB ì ì¬ (ê¸°ë³¸ ë°ì´í„° â€” price/ma60/adj_gapì€ í›„ì† UPDATEë¡œ ì¶”ê°€)
            # INSERT ON CONFLICT: ê¸°ì¡´ part2_rank ë³´ì¡´
            cursor.execute('''
                INSERT INTO ntm_screening
                (date, ticker, rank, score, ntm_current, ntm_7d, ntm_30d, ntm_60d, ntm_90d, is_turnaround)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ON CONFLICT(date, ticker) DO UPDATE SET
                    rank=excluded.rank, score=excluded.score,
                    ntm_current=excluded.ntm_current, ntm_7d=excluded.ntm_7d,
                    ntm_30d=excluded.ntm_30d, ntm_60d=excluded.ntm_60d,
                    ntm_90d=excluded.ntm_90d, is_turnaround=excluded.is_turnaround
            ''', (today_str, ticker, 0, score,
                  ntm['current'], ntm['7d'], ntm['30d'], ntm['60d'], ntm['90d'],
                  1 if is_turnaround else 0))

            # ì¢…ëª© ì •ë³´ (ìºì‹œ ìš°ì„ , ì—†ìœ¼ë©´ API í˜¸ì¶œ)
            if ticker in ticker_cache:
                short_name = ticker_cache[ticker]['shortName']
                industry_kr = ticker_cache[ticker]['industry']
            else:
                info = stock.info
                short_name = info.get('shortName', ticker)
                industry_en = info.get('industry', 'N/A')
                industry_kr = INDUSTRY_MAP.get(industry_en, industry_en)
                ticker_cache[ticker] = {'shortName': short_name, 'industry': industry_kr}
                cache_updated = True

            # ê°€ê²© & ë‹¤ì¤‘ ì£¼ê¸° ê´´ë¦¬ìœ¨ (ì¼ê´„ ë‹¤ìš´ë¡œë“œ ë°ì´í„° ì‚¬ìš©)
            fwd_pe_now = None
            fwd_pe_chg = None  # ê°€ì¤‘í‰ê·  ê´´ë¦¬ìœ¨
            price_chg = None
            price_chg_weighted = None
            eps_chg_weighted = None
            current_price = None
            ma60_val = None

            try:
                if hist_all is not None:
                    hist = hist_all['Close'][ticker].dropna()
                else:
                    h = stock.history(period='6mo')
                    hist = h['Close']

                if len(hist) >= 60:
                    p_now = hist.iloc[-1]
                    current_price = float(p_now)
                    ma60_val = float(hist.rolling(window=60).mean().iloc[-1])
                    hist_dt = hist.index.tz_localize(None) if hist.index.tz else hist.index

                    # ê° ì‹œì ì˜ ì£¼ê°€ ì°¾ê¸°
                    prices = {}
                    for days, key in [(7, '7d'), (30, '30d'), (60, '60d'), (90, '90d')]:
                        target = today - timedelta(days=days)
                        idx = (hist_dt - target).map(lambda x: abs(x.days)).argmin()
                        prices[key] = hist.iloc[idx]

                    # 90ì¼ ì£¼ê°€ë³€í™”ìœ¨ (ë‚´ë¶€ìš©)
                    price_chg = (p_now - prices['90d']) / prices['90d'] * 100

                    # ê°€ì¤‘í‰ê·  ì£¼ê°€ë³€í™”ìœ¨ (âš ï¸ ê²½ê³  íŒë³„ìš©)
                    price_w = {'7d': 0.4, '30d': 0.3, '60d': 0.2, '90d': 0.1}
                    pw_sum = sum(
                        w * (p_now - prices[k]) / prices[k] * 100
                        for k, w in price_w.items() if prices[k] > 0
                    )
                    pw_total = sum(w for k, w in price_w.items() if prices[k] > 0)
                    price_chg_weighted = pw_sum / pw_total if pw_total > 0 else None

                    # ê°€ì¤‘í‰ê·  EPSë³€í™”ìœ¨ (âš ï¸ ê²½ê³  íŒë³„ìš©)
                    nc_val = ntm['current']
                    eps_w = {'7d': 0.4, '30d': 0.3, '60d': 0.2, '90d': 0.1}
                    ew_sum = sum(
                        w * (nc_val - ntm[k]) / abs(ntm[k]) * 100
                        for k, w in eps_w.items() if ntm[k] != 0
                    )
                    ew_total = sum(w for k, w in eps_w.items() if ntm[k] != 0)
                    eps_chg_weighted = ew_sum / ew_total if ew_total > 0 else None

                    # í˜„ì¬ Fwd PE
                    nc = ntm['current']
                    if nc > 0:
                        fwd_pe_now = p_now / nc

                    # ê° ì£¼ê¸°ë³„ ê´´ë¦¬ìœ¨ â†’ ê°€ì¤‘í‰ê· 
                    weights = {'7d': 0.4, '30d': 0.3, '60d': 0.2, '90d': 0.1}
                    weighted_sum = 0.0
                    total_weight = 0.0

                    for key, w in weights.items():
                        ntm_val = ntm[key]
                        if nc > 0 and ntm_val > 0 and prices[key] > 0:
                            fwd_pe_then = prices[key] / ntm_val
                            pe_chg_period = (fwd_pe_now - fwd_pe_then) / fwd_pe_then * 100
                            weighted_sum += w * pe_chg_period
                            total_weight += w

                    if total_weight > 0:
                        fwd_pe_chg = weighted_sum / total_weight
            except Exception as e:
                log(f"  {ticker} ê°€ê²©/PE ê³„ì‚° ì‹¤íŒ¨: {e}", "WARN")

            # adj_gap: ê´´ë¦¬ìœ¨ì— ë°©í–¥ ë³´ì • (ê°€ì† â†’ ì €í‰ê°€ ê°•í™”, ê°ì† â†’ ì €í‰ê°€ ì•½í™”)
            adj_gap = None
            if fwd_pe_chg is not None and direction is not None:
                dir_factor = max(-0.3, min(0.3, direction / 30))
                adj_gap = fwd_pe_chg * (1 + dir_factor)

            row = {
                'ticker': ticker,
                'short_name': short_name,
                'industry': industry_kr,
                'score': score,
                'adj_score': adj_score,
                'direction': direction,
                'seg1': seg1, 'seg2': seg2, 'seg3': seg3, 'seg4': seg4,
                'ntm_cur': ntm['current'],
                'ntm_7d': ntm['7d'],
                'ntm_30d': ntm['30d'],
                'ntm_60d': ntm['60d'],
                'ntm_90d': ntm['90d'],
                'eps_change_90d': eps_change_90d,
                'trend_lights': trend_lights,
                'trend_desc': trend_desc,
                'price_chg': price_chg,
                'price_chg_weighted': price_chg_weighted,
                'eps_chg_weighted': eps_chg_weighted,
                'fwd_pe': fwd_pe_now,
                'fwd_pe_chg': fwd_pe_chg,
                'adj_gap': adj_gap,
                'is_turnaround': is_turnaround,
                'rev_up30': rev_up30,
                'rev_down30': rev_down30,
                'num_analysts': num_analysts,
                'price': current_price,
                'ma60': ma60_val,
            }

            # DBì— íŒŒìƒ ë°ì´í„° ì—…ë°ì´íŠ¸
            cursor.execute('''
                UPDATE ntm_screening
                SET adj_score=?, adj_gap=?, price=?, ma60=?
                WHERE date=? AND ticker=?
            ''', (adj_score, adj_gap, current_price, ma60_val, today_str, ticker))

            if is_turnaround:
                turnaround.append(row)
            else:
                results.append(row)

        except Exception as e:
            errors.append((ticker, str(e)))
            continue

    conn.commit()

    # ì¢…ëª© ì •ë³´ ìºì‹œ ì €ì¥
    if cache_updated:
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump(ticker_cache, f, ensure_ascii=False, indent=2)
        log(f"ì¢…ëª© ì •ë³´ ìºì‹œ ì €ì¥: {len(ticker_cache)}ê°œ")

    # ë©”ì¸ ë­í‚¹: adj_score(ë°©í–¥ ë³´ì • ì ìˆ˜) ìˆœ ì •ë ¬ + rank ì—…ë°ì´íŠ¸
    results_df = pd.DataFrame(results)
    if not results_df.empty:
        results_df = results_df.sort_values('adj_score', ascending=False).reset_index(drop=True)
        results_df['rank'] = results_df.index + 1

        for _, row in results_df.iterrows():
            cursor.execute(
                'UPDATE ntm_screening SET rank = ? WHERE date = ? AND ticker = ?',
                (int(row['rank']), today_str, row['ticker'])
            )

    # í„´ì–´ë¼ìš´ë“œ: score ìˆœ ì •ë ¬
    turnaround_df = pd.DataFrame(turnaround)
    if not turnaround_df.empty:
        turnaround_df = turnaround_df.sort_values('score', ascending=False).reset_index(drop=True)

    conn.commit()
    conn.close()

    # í†µê³„
    stats = {
        'universe': len(all_tickers),
        'main_count': len(results),
        'turnaround_count': len(turnaround),
        'no_data_count': len(no_data),
        'error_count': len(errors),
        'error_tickers': [t for t, _ in errors],
        'total_collected': len(results) + len(turnaround),
    }

    # score_gt0/gt3/aligned_count ì œê±° â€” ì‹œìŠ¤í…œ ë¡œê·¸ì—ì„œ ë¯¸ì‚¬ìš©

    log(f"ìˆ˜ì§‘ ì™„ë£Œ: ë©”ì¸ {len(results)}, í„´ì–´ë¼ìš´ë“œ {len(turnaround)}, "
        f"ë°ì´í„°ì—†ìŒ {len(no_data)}, ì—ëŸ¬ {len(errors)}")

    return results_df, turnaround_df, stats


# ============================================================
# Part 2 ê³µí†µ í•„í„° & 3ì¼ êµì§‘í•©
# ============================================================

def fetch_revenue_growth(df):
    """Part 2 eligible ì¢…ëª©ì˜ ë§¤ì¶œ ì„±ì¥ë¥  ìˆ˜ì§‘ (yfinance)

    composite score = z(adj_gap)*0.7 + z(rev_growth)*0.3
    'íŒŒê´´ì  í˜ì‹  ê¸°ì—…ì„ ì‹¸ê²Œ' â€” ë§¤ì¶œ ì„±ì¥ì´ ë†’ê³  adj_gapì´ í° ì¢…ëª© ìš°ì„ 
    """
    import yfinance as yf
    import numpy as np

    # adj_gap ê¸°ì¤€ ìƒìœ„ 50ê°œë§Œ ìˆ˜ì§‘ (Top 30 + ë²„í¼)
    eligible = df[
        (df['adj_score'] > 9) &
        (df['adj_gap'].notna()) &
        (df['fwd_pe'].notna()) & (df['fwd_pe'] > 0) &
        (df['eps_change_90d'] > 0) &
        (df['price'].notna()) & (df['price'] >= 10) &
        (df['ma60'].notna()) & (df['price'] > df['ma60'])
    ].sort_values('adj_gap', ascending=True).head(50)

    tickers = list(eligible['ticker'])
    log(f"ë§¤ì¶œ ì„±ì¥ë¥  ìˆ˜ì§‘: {len(tickers)}ì¢…ëª©")

    rev_map = {}
    for t in tickers:
        try:
            info = yf.Ticker(t).info
            rev_map[t] = info.get('revenueGrowth')
        except Exception:
            rev_map[t] = None

    success = sum(1 for v in rev_map.values() if v is not None)
    log(f"ë§¤ì¶œ ì„±ì¥ë¥  ìˆ˜ì§‘ ì™„ë£Œ: {success}/{len(tickers)}")

    df['rev_growth'] = df['ticker'].map(rev_map)
    return df


def get_part2_candidates(df, top_n=None):
    """Part 2 ë§¤ìˆ˜ í›„ë³´ í•„í„°ë§ (ê³µí†µ í•¨ìˆ˜)

    í•„í„°: adj_score > 9, fwd_pe > 0, eps > 0, price â‰¥ $10, price > MA60
    ì •ë ¬: composite score (adj_gap 70% + rev_growth 30%) ë˜ëŠ” adj_gap
    """
    import numpy as np
    import pandas as pd

    filtered = df[
        (df['adj_score'] > 9) &
        (df['adj_gap'].notna()) &
        (df['fwd_pe'].notna()) & (df['fwd_pe'] > 0) &
        (df['eps_change_90d'] > 0) &
        (df['price'].notna()) & (df['price'] >= 10) &
        (df['ma60'].notna()) & (df['price'] > df['ma60'])
    ].copy()

    # rev_growth ì¹¼ëŸ¼ì´ ìˆê³  ìœ íš¨ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ë©´ composite score ì‚¬ìš©
    if 'rev_growth' in filtered.columns and filtered['rev_growth'].notna().sum() >= 10:
        valid = filtered[filtered['rev_growth'].notna()].copy()
        invalid = filtered[filtered['rev_growth'].isna()].copy()

        # ë§¤ì¶œ ì„±ì¥ë¥  10% ë¯¸ë§Œ ì œì™¸
        low_rev = valid[valid['rev_growth'] < 0.10]
        if len(low_rev) > 0:
            log(f"ë§¤ì¶œ ì„±ì¥ ë¶€ì¡±(<10%) ì œì™¸: {', '.join(low_rev['ticker'].tolist())}")
        valid = valid[valid['rev_growth'] >= 0.10].copy()

        # z-score ì •ê·œí™”
        gap_mean, gap_std = valid['adj_gap'].mean(), valid['adj_gap'].std()
        rev_mean, rev_std = valid['rev_growth'].mean(), valid['rev_growth'].std()

        if gap_std > 0 and rev_std > 0:
            z_gap = (valid['adj_gap'] - gap_mean) / gap_std
            z_rev = (valid['rev_growth'] - rev_mean) / rev_std
            # adj_gapì€ ìŒìˆ˜ê°€ ì¢‹ìœ¼ë¯€ë¡œ ë¶€í˜¸ ë°˜ì „, rev_growthëŠ” ì–‘ìˆ˜ê°€ ì¢‹ìŒ
            valid['composite'] = (-z_gap) * 0.7 + z_rev * 0.3
            valid = valid.sort_values('composite', ascending=False)
            # rev_growth ì—†ëŠ” ì¢…ëª©ì€ ë’¤ì— ë¶™ì„ (adj_gap ìˆœ)
            invalid = invalid.sort_values('adj_gap', ascending=True)
            filtered = pd.concat([valid, invalid], ignore_index=True)
        else:
            filtered = filtered.sort_values('adj_gap', ascending=True)
    else:
        filtered = filtered.sort_values('adj_gap', ascending=True)

    if top_n:
        filtered = filtered.head(top_n)
    return filtered


def save_part2_ranks(results_df, today_str):
    """Part 2 eligible ì¢…ëª© Top 30ì— part2_rank ì €ì¥ (3ì¼ êµì§‘í•© + Death Listìš©)"""
    candidates = get_part2_candidates(results_df, top_n=30)
    if candidates.empty:
        log("Part 2 í›„ë³´ 0ê°œ â€” part2_rank ì €ì¥ ìŠ¤í‚µ")
        return

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # ê¸°ì¡´ part2_rank ì´ˆê¸°í™” í›„ ìƒˆë¡œ ì €ì¥ (í•„í„° ë³€ê²½ ì‹œ ì”ì—¬ rank ë°©ì§€)
    cursor.execute('UPDATE ntm_screening SET part2_rank=NULL WHERE date=?', (today_str,))

    for i, (_, row) in enumerate(candidates.iterrows()):
        cursor.execute(
            'UPDATE ntm_screening SET part2_rank=? WHERE date=? AND ticker=?',
            (i + 1, today_str, row['ticker'])
        )

    conn.commit()
    conn.close()
    log(f"Part 2 rank ì €ì¥: {len(candidates)}ê°œ ì¢…ëª©")


def is_cold_start():
    """DBì— part2_rank ë°ì´í„°ê°€ 3ì¼ ë¯¸ë§Œì´ë©´ True (ì±„ë„ ì „ì†¡ ì œì–´ìš©)"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute('SELECT COUNT(DISTINCT date) FROM ntm_screening WHERE part2_rank IS NOT NULL')
    count = cursor.fetchone()[0]
    conn.close()
    return count < 3


def get_3day_status(today_tickers):
    """3ì¼ ì—°ì† Part 2 ì§„ì… ì—¬ë¶€ íŒë³„ â†’ {ticker: 'âœ…' or 'â³' or 'ğŸ†•'}
    âœ… = 3ì¼ ì—°ì† (í¬íŠ¸í´ë¦¬ì˜¤ í¬í•¨)
    â³ = 2ì¼ ì—°ì† (í‘œì‹œë§Œ, í¬íŠ¸í´ë¦¬ì˜¤ ì œì™¸)
    ğŸ†• = ì˜¤ëŠ˜ë§Œ (í‘œì‹œë§Œ, í¬íŠ¸í´ë¦¬ì˜¤ ì œì™¸)
    """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # ìµœê·¼ 3ê°œ distinct date (part2_rank ìˆëŠ” ë‚ ì§œë§Œ)
    cursor.execute(
        'SELECT DISTINCT date FROM ntm_screening WHERE part2_rank IS NOT NULL ORDER BY date DESC LIMIT 3'
    )
    dates = [r[0] for r in cursor.fetchall()]

    if len(dates) < 2:
        conn.close()
        log(f"3ì¼ êµì§‘í•©: DB {len(dates)}ì¼ë¿ â€” ì „ë¶€ ğŸ†• ì²˜ë¦¬ (cold start)")
        return {t: 'ğŸ†•' for t in today_tickers}

    placeholders = ','.join('?' * len(dates))

    # 3ì¼ ëª¨ë‘ Top 30ì¸ ì¢…ëª©
    verified_3d = set()
    if len(dates) >= 3:
        cursor.execute(f'''
            SELECT ticker FROM ntm_screening
            WHERE date IN ({placeholders}) AND part2_rank IS NOT NULL AND part2_rank <= 30
            GROUP BY ticker HAVING COUNT(DISTINCT date) = 3
        ''', dates)
        verified_3d = {r[0] for r in cursor.fetchall()}

    # ìµœê·¼ 2ì¼ ëª¨ë‘ Top 30ì¸ ì¢…ëª©
    dates_2d = dates[:2]
    ph2 = ','.join('?' * len(dates_2d))
    cursor.execute(f'''
        SELECT ticker FROM ntm_screening
        WHERE date IN ({ph2}) AND part2_rank IS NOT NULL AND part2_rank <= 30
        Group BY ticker HAVING COUNT(DISTINCT date) = 2
    ''', dates_2d)
    verified_2d = {r[0] for r in cursor.fetchall()}

    conn.close()

    status = {}
    for t in today_tickers:
        if t in verified_3d:
            status[t] = 'âœ…'
        elif t in verified_2d:
            status[t] = 'â³'
        else:
            status[t] = 'ğŸ†•'

    v3 = sum(1 for v in status.values() if v == 'âœ…')
    v2 = sum(1 for v in status.values() if v == 'â³')
    v1 = sum(1 for v in status.values() if v == 'ğŸ†•')
    log(f"3ì¼ êµì§‘í•©: âœ… {v3}ê°œ, â³ {v2}ê°œ, ğŸ†• {v1}ê°œ")
    return status


def get_rank_history(today_tickers):
    """ìµœê·¼ 3ì¼ê°„ part2_rank ì´ë ¥ â†’ {ticker: '3â†’4â†’1'} í˜•íƒœ"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    cursor.execute(
        'SELECT DISTINCT date FROM ntm_screening WHERE part2_rank IS NOT NULL ORDER BY date DESC LIMIT 3'
    )
    dates = sorted([r[0] for r in cursor.fetchall()])

    if len(dates) < 2:
        conn.close()
        return {}

    rank_by_date = {}
    for d in dates:
        cursor.execute(
            'SELECT ticker, part2_rank FROM ntm_screening WHERE date=? AND part2_rank IS NOT NULL AND part2_rank <= 30',
            (d,)
        )
        rank_by_date[d] = {r[0]: r[1] for r in cursor.fetchall()}
    conn.close()

    history = {}
    for t in today_tickers:
        parts = []
        for d in dates:
            r = rank_by_date.get(d, {}).get(t)
            parts.append(str(r) if r else '-')
        history[t] = 'â†’'.join(parts)
    return history


def get_daily_changes(today_tickers):
    """ì–´ì œ ëŒ€ë¹„ Top 30 ë³€ë™ â€” ì‹ ê·œ ì§„ì… / ì´íƒˆ ì¢…ëª© (ë‹¨ìˆœ set ë¹„êµ)"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # ì–´ì œ ë‚ ì§œ (part2_rank ìˆëŠ” ê°€ì¥ ìµœê·¼)
    cursor.execute(
        'SELECT DISTINCT date FROM ntm_screening WHERE part2_rank IS NOT NULL ORDER BY date DESC LIMIT 2'
    )
    dates = [r[0] for r in cursor.fetchall()]

    if len(dates) < 2:
        conn.close()
        return [], []

    yesterday = dates[1]

    cursor.execute(
        'SELECT ticker, part2_rank FROM ntm_screening WHERE date=? AND part2_rank IS NOT NULL AND part2_rank <= 30',
        (yesterday,)
    )
    yesterday_ranks = {r[0]: r[1] for r in cursor.fetchall()}
    conn.close()

    yesterday_top30 = set(yesterday_ranks.keys())
    today_set = set(today_tickers)
    entered = today_set - yesterday_top30
    exited = yesterday_top30 - today_set
    exited_with_rank = {t: yesterday_ranks[t] for t in exited}

    log(f"ì–´ì œ ëŒ€ë¹„: +{len(entered)} ì‹ ê·œ, -{len(exited)} ì´íƒˆ")
    return sorted(entered), exited_with_rank


def get_market_context():
    """ë¯¸êµ­ ì‹œì¥ ì§€ìˆ˜ ì»¨í…ìŠ¤íŠ¸"""
    try:
        import yfinance as yf
        lines = []
        for symbol, name in [("^GSPC", "S&P 500"), ("^IXIC", "ë‚˜ìŠ¤ë‹¥")]:
            try:
                hist = yf.Ticker(symbol).history(period='5d')
                if len(hist) >= 2:
                    close = hist['Close'].iloc[-1]
                    prev = hist['Close'].iloc[-2]
                    chg = (close / prev - 1) * 100
                    icon = "ğŸŸ¢" if chg > 0.5 else ("ğŸ”´" if chg < -0.5 else "ğŸŸ¡")
                    lines.append(f"{icon} {name}  {close:,.0f} ({chg:+.2f}%)")
            except Exception:
                continue
        return lines
    except Exception:
        return []


# ============================================================
# Git ìë™ ì»¤ë°‹
# ============================================================

def git_commit_push(config):
    """Git ìë™ commit/push (GitHub Actionsì—ì„œëŠ” ì›Œí¬í”Œë¡œìš°ê°€ ì²˜ë¦¬)"""
    if not config.get('git_enabled', False):
        log("Git ë™ê¸°í™” ë¹„í™œì„±í™”ë¨")
        return False

    if config.get('is_github_actions', False):
        log("GitHub Actions í™˜ê²½ â€” ì›Œí¬í”Œë¡œìš°ì—ì„œ Git ì²˜ë¦¬")
        return True

    log("Git commit/push ì‹œì‘")

    try:
        today = datetime.now().strftime('%Y-%m-%d')

        subprocess.run(['git', 'add', '-A'], cwd=PROJECT_ROOT, check=True, capture_output=True)

        commit_msg = f"Daily update: {today}"
        result = subprocess.run(
            ['git', 'commit', '-m', commit_msg],
            cwd=PROJECT_ROOT, capture_output=True, text=True
        )

        if 'nothing to commit' in result.stdout or 'nothing to commit' in result.stderr:
            log("ë³€ê²½ì‚¬í•­ ì—†ìŒ, ì»¤ë°‹ ìŠ¤í‚µ")
            return True

        remote = config.get('git_remote', 'origin')
        branch = config.get('git_branch', 'master')
        subprocess.run(['git', 'push', remote, branch], cwd=PROJECT_ROOT, check=True, capture_output=True)

        log("Git push ì™„ë£Œ")
        return True

    except subprocess.CalledProcessError as e:
        log(f"Git ì˜¤ë¥˜: {e}", "ERROR")
        return False


# ============================================================
# í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ìƒì„±
# ============================================================

def get_last_business_day():
    """ê°€ì¥ ìµœê·¼ ë¯¸êµ­ ì˜ì—…ì¼ ë‚ ì§œ"""
    if HAS_PYTZ:
        eastern = pytz.timezone('US/Eastern')
        now_et = datetime.now(eastern)
    else:
        now_et = datetime.now() - timedelta(hours=14)

    d = now_et.date()
    # í‰ì¼ ì¥ë§ˆê° í›„(16ì‹œ ì´í›„)ë©´ ì˜¤ëŠ˜ì´ ì˜ì—…ì¼
    if d.weekday() < 5 and now_et.hour >= 16:
        return d
    # ê·¸ ì™¸: ì „ì¼ë¡œ ê°€ì„œ ê°€ì¥ ìµœê·¼ í‰ì¼ ì°¾ê¸°
    d -= timedelta(days=1)
    while d.weekday() >= 5:
        d -= timedelta(days=1)
    return d


def get_today_kst():
    """ì˜¤ëŠ˜ ë‚ ì§œ (KST)"""
    if HAS_PYTZ:
        kst = pytz.timezone('Asia/Seoul')
        return datetime.now(kst).date()
    return datetime.now().date()


def create_part1_message(df, top_n=30):
    """Part 1: ì´ìµ ëª¨ë©˜í…€ ë­í‚¹ ë©”ì‹œì§€ ìƒì„± (EPS ì ìˆ˜ ìˆœ)"""
    biz_day = get_last_business_day()
    biz_str = biz_day.strftime('%Yë…„ %mì›” %dì¼')

    lines = []
    lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    lines.append(f' [1/4] ğŸ“ˆ EPS ëª¨ë©˜í…€ Top {top_n}')
    lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    lines.append(f'ğŸ“… {biz_str} (ë¯¸êµ­ì¥ ê¸°ì¤€)')
    lines.append('')
    lines.append('ë¯¸êµ­ 916ì¢…ëª© ì¤‘ ì• ë„ë¦¬ìŠ¤íŠ¸ EPS ì „ë§ì¹˜ë¥¼')
    lines.append('ê°€ì¥ ë§ì´ ì˜¬ë¦° ê¸°ì—… ìˆœìœ„ì˜ˆìš”.')
    lines.append('')
    lines.append('ğŸ’¡ <b>ì½ëŠ” ë²•</b>')
    lines.append('EPS ì ìˆ˜ = 90ì¼ê°„ 4êµ¬ê°„ ìƒìŠ¹ë¥ ì˜ í•©')
    lines.append('ì ìˆ˜ê°€ ë†’ì•„ë„ ğŸŒ§ï¸ê°€ ìˆìœ¼ë©´ ìµœê·¼ ì£¼ì˜!')
    lines.append('')
    lines.append('ì¶”ì„¸ = êµ¬ê°„ë³„ EPS ë³€í™” (ì™¼â†’ì˜¤)')
    lines.append('90â†’60ì¼ | 60â†’30ì¼ | 30â†’7ì¼ | 7ì¼â†’ì˜¤ëŠ˜')
    lines.append('ğŸ”¥ í­ë“±(20%â†‘) â˜€ï¸ ê°•ì„¸(5~20%)')
    lines.append('ğŸŒ¤ï¸ ìƒìŠ¹(1~5%) â˜ï¸ ë³´í•©(Â±1%)')
    lines.append('ğŸŒ§ï¸ í•˜ë½(1%â†“)')
    lines.append('')

    for _, row in df.head(top_n).iterrows():
        rank = int(row['rank'])
        ticker = row['ticker']
        name = row.get('short_name', ticker)
        industry = row.get('industry', '')
        adj_score = row.get('adj_score', row.get('score', 0))
        lights = row.get('trend_lights', '')
        desc = row.get('trend_desc', '')

        lines.append(f'<b>{rank}ìœ„</b> {name} ({ticker})')
        lines.append(f'<i>{industry}</i> Â· {lights} {desc} Â· <b>{adj_score:.1f}</b>ì ')
        lines.append('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')

    lines.append('')
    lines.append('ğŸ‘‰ ë‹¤ìŒ: ë§¤ìˆ˜ í›„ë³´ ì„ ì • [2/4]')

    return '\n'.join(lines)


def create_guide_message():
    """ğŸ“– íˆ¬ì ê°€ì´ë“œ â€” ì‹œìŠ¤í…œ ê°œìš”, ì„ ì • ê³¼ì •, ë³´ìœ /ë§¤ë„ ê¸°ì¤€"""
    lines = [
        'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”',
        '      ğŸ“– íˆ¬ì ê°€ì´ë“œ',
        'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”',
        '',
        'ğŸ” <b>ì–´ë–¤ ì¢…ëª©ì„ ì°¾ë‚˜ìš”?</b>',
        'ì›”ê°€ ì• ë„ë¦¬ìŠ¤íŠ¸ë“¤ì´ "ì´ìµì´ ëŠ˜ì–´ë‚  ê±°ì•¼"ë¼ê³ ',
        'ì „ë§ì¹˜ë¥¼ ì˜¬ë¦¬ëŠ” ì¢…ëª©ì„ ì°¾ì•„ìš”.',
        'ì—¬ëŸ¬ ì „ë¬¸ê°€ê°€ ë™ì‹œì— ì˜¬ë¦¬ë©´ ë” ê°•í•œ ì‹ í˜¸ì˜ˆìš”.',
        '',
        'ğŸ“Š <b>ì–´ë–»ê²Œ ê³¨ë¼ìš”?</b>',
        'ë¯¸êµ­ 916ì¢…ëª©ì„ ë§¤ì¼ 5ë‹¨ê³„ë¡œ ê±¸ëŸ¬ìš”.',
        '',
        'â‘  ì´ìµ ì „ë§ì´ ì˜¤ë¥´ëŠ” ì¢…ëª©ì„ ì°¾ê³ ',
        'â‘¡ ì£¼ê°€ íë¦„ì´ ê±´ê°•í•œ ì¢…ëª©ë§Œ ë‚¨ê¸°ê³ ',
        'â‘¢ ë§¤ì¶œ ì„±ì¥ 10%+, ë³µí•© ìˆœìœ„(ê´´ë¦¬ 70%+ë§¤ì¶œ 30%) Top 30',
        'â‘£ 3ì¼ ì—°ì† Top 30ì— ë“¤ë©´ ê²€ì¦ ì™„ë£Œ âœ…',
        'â‘¤ AI ìœ„í—˜ ì ê²€ í›„ ìµœì¢… 5ì¢…ëª© ì¶”ì²œ',
        '',
        'â±ï¸ <b>ì–¼ë§ˆë‚˜ ë³´ìœ í•˜ë‚˜ìš”?</b>',
        'ìµœì†Œ 2ì£¼ëŠ” ë³´ìœ í•˜ëŠ” ê±¸ ê¶Œì¥í•´ìš”.',
        'ì´ìµ ì „ë§ì´ ì£¼ê°€ì— ë°˜ì˜ë˜ë ¤ë©´ ì‹œê°„ì´ í•„ìš”í•˜ê±°ë“ ìš”.',
        'Top 30ì— ë‚¨ì•„ìˆëŠ” ë™ì•ˆì€ ê³„ì† ë³´ìœ í•˜ì„¸ìš”.',
        '',
        'ğŸ“‰ <b>ì–¸ì œ íŒŒë‚˜ìš”?</b>',
        'ìµœì†Œ 2ì£¼ ë³´ìœ  í›„, ëª©ë¡ì—ì„œ ë¹ ì§€ë©´ ë§¤ë„ ê²€í† ì˜ˆìš”.',
        'ë§¤ì¼ Top 30ì„ ë³´ì—¬ë“œë¦¬ë‹ˆê¹Œ',
        'ëª©ë¡ì— ìˆìœ¼ë©´ ë³´ìœ , ì—†ìœ¼ë©´ ë§¤ë„ ê²€í† .',
    ]
    return '\n'.join(lines)


def create_part2_message(df, status_map=None, exited_tickers=None, market_lines=None, rank_history=None, top_n=30):
    """[1/3] ë§¤ìˆ˜ í›„ë³´ ë©”ì‹œì§€ â€” composite ìˆœ Top 30, âœ…/â³/ğŸ†• í‘œì‹œ, ìˆœìœ„ ì´ë ¥"""
    import pandas as pd

    biz_day = get_last_business_day()
    biz_str = biz_day.strftime('%Yë…„ %mì›” %dì¼')

    # ê³µí†µ í•„í„° ì‚¬ìš©
    filtered = get_part2_candidates(df, top_n=top_n)
    count = len(filtered)

    if status_map is None:
        status_map = {}
    if exited_tickers is None:
        exited_tickers = {}
    if rank_history is None:
        rank_history = {}

    lines = []
    lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    lines.append(f' [1/3] ğŸ” ë§¤ìˆ˜ í›„ë³´ {count}ê°œ')
    lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    lines.append(f'ğŸ“… {biz_str} (ë¯¸êµ­ì¥ ê¸°ì¤€)')
    if market_lines:
        lines.append('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')
        lines.extend(market_lines)
    lines.append('')
    lines.append('ì´ìµ ì „ë§ì´ ì˜¬ë¼ê°€ë©´ì„œ ë§¤ì¶œë„ ì„±ì¥í•˜ëŠ” ì¢…ëª©ì´ì—ìš”.')
    lines.append('EPS ì €í‰ê°€ + ë§¤ì¶œ ì„±ì¥ë¥  ë³µí•© ìˆœìœ„.')
    lines.append('')
    lines.append('ğŸ’¡ <b>ì½ëŠ” ë²•</b>')
    lines.append('âœ…ë§¤ìˆ˜ â³ë‚´ì¼ê²€ì¦ ğŸ†•ê´€ì°°')
    lines.append('ğŸ”¥í­ë“± â˜€ï¸ê°•ì„¸ ğŸŒ¤ï¸ìƒìŠ¹ â˜ï¸ë³´í•© ğŸŒ§ï¸í•˜ë½')
    lines.append('')

    for idx, (_, row) in enumerate(filtered.iterrows()):
        rank = idx + 1
        ticker = row['ticker']
        industry = row.get('industry', '')
        lights = row.get('trend_lights', '')
        desc = row.get('trend_desc', '')
        eps_90d = row.get('eps_change_90d')
        price_90d = row.get('price_chg')

        # âœ…/ğŸ†• ë§ˆì»¤
        marker = status_map.get(ticker, 'ğŸ†•')

        # ìˆœìœ„ ì´ë ¥
        hist = rank_history.get(ticker, '')

        adj_gap = row.get('adj_gap', 0) or 0
        rev_g = row.get('rev_growth')
        rev_up = int(row.get('rev_up30', 0) or 0)
        rev_down = int(row.get('rev_down30', 0) or 0)

        # Line 1: ë§ˆì»¤ ìˆœìœ„ ì¢…ëª©ëª…(í‹°ì»¤) Â· ì—…ì¢…
        name = row.get('short_name', ticker)
        lines.append(f'{marker} <b>{rank}.</b> {name}({ticker}) Â· {industry}')
        # Line 2: ë‚ ì”¨
        lines.append(f'{lights} {desc}')
        # Line 3: EPS Â· ë§¤ì¶œ
        parts = []
        if pd.notna(eps_90d):
            parts.append(f'EPS {eps_90d:+.0f}%')
        if pd.notna(rev_g):
            parts.append(f'ë§¤ì¶œ {rev_g*100:+.0f}%')
        if parts:
            lines.append(' Â· '.join(parts))
        # Line 4: ì˜ê²¬ Â· ìˆœìœ„ì´ë ¥
        line4 = f'ì˜ê²¬ â†‘{rev_up}â†“{rev_down}'
        if hist:
            line4 += f' Â· ìˆœìœ„ {hist}'
        lines.append(line4)
        lines.append('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')

    # ì´íƒˆ ì¢…ëª© (ì–´ì œ ëŒ€ë¹„) + ì–´ì œâ†’ì˜¤ëŠ˜ ìˆœìœ„
    if exited_tickers:
        lines.append('')
        lines.append('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')
        lines.append(f'ğŸ“‰ ì–´ì œ ëŒ€ë¹„ ì´íƒˆ {len(exited_tickers)}ê°œ')
        # ì „ì²´ eligible ì¢…ëª©ì˜ í˜„ì¬ ìˆœìœ„ ê³„ì‚°
        all_eligible = get_part2_candidates(df)
        current_rank_map = {row['ticker']: i + 1 for i, (_, row) in enumerate(all_eligible.iterrows())}
        sorted_exits = sorted(exited_tickers.items(), key=lambda x: x[1])
        # ì´íƒˆ ì¢…ëª© ì¢…ëª©ëª… ë§µ
        name_map = dict(zip(df['ticker'], df.get('short_name', df['ticker'])))
        for t, prev_rank in sorted_exits:
            t_name = name_map.get(t, t)
            cur_rank = current_rank_map.get(t)
            if cur_rank:
                lines.append(f'{t_name}({t}) Â· ì–´ì œ {prev_rank}ìœ„ â†’ {cur_rank}ìœ„')
            else:
                lines.append(f'{t_name}({t}) Â· ì–´ì œ {prev_rank}ìœ„ â†’ ì¡°ê±´ ë¯¸ë‹¬')
        lines.append('')
        lines.append('ë³´ìœ  ì¤‘ì´ë¼ë©´ ë§¤ë„ë¥¼ ê²€í† í•˜ì„¸ìš”.')

    lines.append('')
    lines.append('ëª©ë¡ì— ìˆìœ¼ë©´ ë³´ìœ , ì—†ìœ¼ë©´ ë§¤ë„ ê²€í† .')
    lines.append('')
    lines.append('ğŸ‘‰ ë‹¤ìŒ: AI ë¦¬ìŠ¤í¬ í•„í„° [2/3]')

    return '\n'.join(lines)


def create_system_log_message(stats, elapsed, config):
    """ì‹œìŠ¤í…œ ì‹¤í–‰ ë¡œê·¸ ë©”ì‹œì§€ ìƒì„±"""
    now = datetime.now()
    if HAS_PYTZ:
        kst = pytz.timezone('Asia/Seoul')
        now = datetime.now(kst)
    time_str = now.strftime('%Y.%m.%d %H:%M')

    env = 'GitHub Actions' if config.get('is_github_actions') else 'Local'
    minutes = int(elapsed // 60)
    seconds = int(elapsed % 60)

    collected = stats.get('total_collected', 0)
    universe = stats.get('universe', 0)
    err = stats.get('error_count', 0)

    lines = [f'ğŸ”§ <b>ì‹œìŠ¤í…œ ë¡œê·¸</b>']
    lines.append(f'{time_str} KST Â· {env}')

    # ìˆ˜ì§‘ ê²°ê³¼
    if err == 0:
        lines.append(f'\nâœ… ìˆ˜ì§‘ ì„±ê³µ ({collected}/{universe})')
    else:
        lines.append(f'\nâš ï¸ ìˆ˜ì§‘ ì™„ë£Œ ({collected}/{universe}, ì‹¤íŒ¨ {err})')
        error_tickers = stats.get('error_tickers', [])
        if error_tickers:
            lines.append(f'ì‹¤íŒ¨: {", ".join(error_tickers[:10])}')

    # DB ë°ì´í„° ë²”ìœ„
    try:
        conn = sqlite3.connect(config.get('db_path', 'eps_momentum_data.db'))
        cur = conn.cursor()
        cur.execute('SELECT DISTINCT date FROM ntm_screening ORDER BY date')
        dates = [r[0] for r in cur.fetchall()]
        cur.execute('SELECT COUNT(*) FROM ntm_screening WHERE part2_rank IS NOT NULL AND date=?',
                    (dates[-1],) if dates else ('',))
        ranked = cur.fetchone()[0] if dates else 0
        conn.close()
        if dates:
            lines.append(f'\nğŸ“‚ DB: {dates[0]} ~ {dates[-1]} ({len(dates)}ì¼)')
            exited = stats.get('exited_count', 0)
            lines.append(f'ë§¤ìˆ˜ í›„ë³´: {ranked}ê°œ / ì´íƒˆ: {exited}ê°œ')
    except Exception:
        pass

    lines.append(f'\nâ±ï¸ ì†Œìš”: {minutes}ë¶„ {seconds}ì´ˆ')

    return '\n'.join(lines)


# ============================================================
# AI ë¦¬ìŠ¤í¬ ì²´í¬ (Gemini 2.5 Flash + Google Search)
# ============================================================

def run_ai_analysis(config, results_df=None, status_map=None, biz_day=None):
    """[2/2] AI ë¸Œë¦¬í•‘ â€” ì •ëŸ‰ ìœ„í—˜ ì‹ í˜¸ ê¸°ë°˜ ë¦¬ìŠ¤í¬ í•´ì„ (ë°ì´í„°ëŠ” ì½”ë“œê°€, í•´ì„ì€ AIê°€)"""
    api_key = config.get('gemini_api_key', '')
    if not api_key:
        log("GEMINI_API_KEY ë¯¸ì„¤ì • â€” AI ë¶„ì„ ìŠ¤í‚µ", "WARN")
        return None

    try:
        from google import genai
        from google.genai import types
    except ImportError:
        log("google-genai íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜ â€” AI ë¶„ì„ ìŠ¤í‚µ", "WARN")
        return None

    try:
        client = genai.Client(api_key=api_key)

        import re
        import yfinance as yf

        # Part 2 ì¢…ëª© ì¶”ì¶œ + ìœ„í—˜ ì‹ í˜¸ ìˆ˜ì§‘
        if results_df is None or results_df.empty:
            log("results_df ì—†ìŒ â€” AI ë¶„ì„ ìŠ¤í‚µ", "WARN")
            return None

        filtered = get_part2_candidates(results_df, top_n=30)

        if filtered.empty:
            log("Part 2 ì¢…ëª© ì—†ìŒ â€” AI ë¶„ì„ ìŠ¤í‚µ", "WARN")
            return None

        stock_count = len(filtered)
        if biz_day is None:
            biz_day = get_last_business_day()
        biz_str = biz_day.strftime('%Y-%m-%d')
        today_date = datetime.now().date()
        two_weeks_date = (datetime.now() + timedelta(days=14)).date()

        # ì¢…ëª©ë³„ ìœ„í—˜ ì‹ í˜¸ êµ¬ì„±
        log("ìœ„í—˜ ì‹ í˜¸ & ì–´ë‹ ì¼ì • ìˆ˜ì§‘ ì¤‘...")
        signal_lines = []
        earnings_tickers = []

        for _, row in filtered.iterrows():
            ticker = row['ticker']
            name = row.get('short_name', ticker)
            industry = row.get('industry', '')
            adj_score = row.get('adj_score', 0)
            eps_chg = row.get('eps_change_90d', 0) or 0
            price_chg = row.get('price_chg', 0) or 0
            fwd_pe = row.get('fwd_pe', 0) or 0
            rev_up = int(row.get('rev_up30', 0) or 0)
            rev_down = int(row.get('rev_down30', 0) or 0)
            lights = row.get('trend_lights', '')
            desc = row.get('trend_desc', '')

            # ìœ„í—˜ ì‹ í˜¸ í”Œë˜ê·¸ (í¬íŠ¸í´ë¦¬ì˜¤ í•„í„°ì™€ ë™ì¼ ê¸°ì¤€)
            num_analysts = int(row.get('num_analysts', 0) or 0)
            flags = []

            # 1. ì• ë„ë¦¬ìŠ¤íŠ¸ í•˜í–¥ 30% ì´ˆê³¼ (down > 30% of total revisions)
            total_rev = rev_up + rev_down
            if total_rev > 0 and rev_down / total_rev > 0.3:
                flags.append(f"ğŸ”» ì˜ê²¬ í•˜í–¥ â†“{rev_down}/â†‘{rev_up}")

            # 2. ì €ì»¤ë²„ë¦¬ì§€ (ì• ë„ë¦¬ìŠ¤íŠ¸ 3ëª… ë¯¸ë§Œ)
            if num_analysts < 3:
                flags.append(f"ğŸ“‰ ì• ë„ë¦¬ìŠ¤íŠ¸ {num_analysts}ëª… (ì €ì»¤ë²„ë¦¬ì§€)")

            # 3. ì–´ë‹ ì„ë°•
            try:
                stock = yf.Ticker(ticker)
                cal = stock.calendar
                if cal is not None:
                    earn_dates = cal.get('Earnings Date', [])
                    if not isinstance(earn_dates, list):
                        earn_dates = [earn_dates]
                    for ed in earn_dates:
                        if hasattr(ed, 'date'):
                            ed = ed.date()
                        if today_date <= ed <= two_weeks_date:
                            flags.append(f"ğŸ“… ì–´ë‹ {ed.month}/{ed.day}")
                            earnings_tickers.append(f"{name} ({ticker}) {ed.month}/{ed.day}")
                            break
            except Exception:
                pass

            # ì¢…ëª© ë¼ì¸ êµ¬ì„±
            header = f"{name} ({ticker}) Â· {industry} Â· {lights} {desc} Â· ì ìˆ˜ {adj_score:.1f}"
            header += f"\n  EPS {eps_chg:+.1f}% / ì£¼ê°€ {price_chg:+.1f}% Â· ì• ë„ë¦¬ìŠ¤íŠ¸ ì˜ê²¬ â†‘{rev_up} â†“{rev_down} Â· Fwd PE {fwd_pe:.1f}"

            if flags:
                header += "\n  " + " | ".join(flags)

            signal_lines.append(header)

        signals_data = '\n\n'.join(signal_lines)
        earnings_info = ' Â· '.join(earnings_tickers) if earnings_tickers else 'í•´ë‹¹ ì—†ìŒ'

        log(f"ìœ„í—˜ ì‹ í˜¸ ìˆ˜ì§‘ ì™„ë£Œ: {stock_count}ì¢…ëª©, ì–´ë‹ {len(earnings_tickers)}ì¢…ëª©")

        prompt = f"""ë¶„ì„ ê¸°ì¤€ì¼: {biz_str} (ë¯¸êµ­ ì˜ì—…ì¼)

ì•„ë˜ëŠ” EPS ëª¨ë©˜í…€ ì‹œìŠ¤í…œì˜ ë§¤ìˆ˜ í›„ë³´ {stock_count}ì¢…ëª©ê³¼ ê° ì¢…ëª©ì˜ ì •ëŸ‰ì  ìœ„í—˜ ì‹ í˜¸ì•¼.
ì´ ì¢…ëª©ë“¤ì€ EPS ì „ë§ì¹˜ê°€ ìƒí–¥ ì¤‘ì´ë¼ ì„ ì •ëœ ê±°ì•¼.
ë„¤ ì—­í• : ì•„ë˜ 3ê°œ ì„¹ì…˜ì„ ìˆœì„œëŒ€ë¡œ ë°˜ë“œì‹œ ëª¨ë‘ ì¶œë ¥í•˜ëŠ” ê±°ì•¼. ì¸ì‚¬ë§ì´ë‚˜ ì„œë‘ ì—†ì´ ë°”ë¡œ ì‹œì‘í•´.

[ì¢…ëª©ë³„ ë°ì´í„° & ìœ„í—˜ ì‹ í˜¸ â€” ì‹œìŠ¤í…œì´ ê³„ì‚°í•œ íŒ©íŠ¸]
{signals_data}

[ìœ„í—˜ ì‹ í˜¸ ì„¤ëª…]
ğŸ”» ì˜ê²¬ í•˜í–¥ = 30ì¼ê°„ EPS ì „ë§ ìˆ˜ì • ì¤‘ í•˜í–¥ ë¹„ìœ¨ > 30% (ì˜ë¯¸ ìˆëŠ” ë°˜ëŒ€ ì˜ê²¬)
ğŸ“‰ ì €ì»¤ë²„ë¦¬ì§€ = ì»¤ë²„ë¦¬ì§€ ì• ë„ë¦¬ìŠ¤íŠ¸ 3ëª… ë¯¸ë§Œ (ì¶”ì •ì¹˜ ì‹ ë¢°ë„ ë‚®ìŒ)
ğŸ“… ì–´ë‹ = 2ì£¼ ë‚´ ì‹¤ì  ë°œí‘œ ì˜ˆì • (ë°œí‘œ ì „í›„ ë³€ë™ì„± ì£¼ì˜)

[ì¶œë ¥ ê·œì¹™]
- í•œêµ­ì–´, ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ ë§íˆ¬ (~ì˜ˆìš”/~í•´ìš” ì²´)
- ë”±ë”±í•œ ë³´ê³ ì„œ ë§íˆ¬ ê¸ˆì§€. ì¹œêµ¬ì—ê²Œ ì„¤ëª…í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê²Œ.
- ì¸ì‚¬ë§, ì„œë‘, ë§ºìŒë§ ê¸ˆì§€. ì•„ë˜ 3ê°œ ì„¹ì…˜ë§Œ ì¶œë ¥.
- ì´ 1500ì ì´ë‚´.

=== ë°˜ë“œì‹œ ì¶œë ¥í•  3ê°œ ì„¹ì…˜ ===

ğŸ“° ì‹œì¥ ë™í–¥
(í•„ìˆ˜) ì–´ì œ ë¯¸êµ­ ì‹œì¥ ë§ˆê°ê³¼ ê¸ˆì£¼ ì£¼ìš” ì´ë²¤íŠ¸ë¥¼ Google ê²€ìƒ‰í•´ì„œ 2~3ì¤„ ìš”ì•½í•´ì¤˜. ì´ ì„¹ì…˜ì€ ë°˜ë“œì‹œ ì¶œë ¥í•´ì•¼ í•´.

âš ï¸ ë§¤ìˆ˜ ì£¼ì˜ ì¢…ëª©
ìœ„ ë°ì´í„°ì—ì„œ ìœ„í—˜ ì‹ í˜¸(ğŸ”»/ğŸ“‰/ğŸ“…)ê°€ ìˆëŠ” ì¢…ëª©ë§Œ ê³¨ë¼ì„œ ì„¤ëª…í•´ì¤˜.
í˜•ì‹: ì¢…ëª©ëª…(í‹°ì»¤)ë¥¼ êµµê²Œ(**) ì“°ê³ , 1~2ì¤„ë¡œ ì™œ ì£¼ì˜í•´ì•¼ í•˜ëŠ”ì§€ ì„¤ëª….
ì¢…ëª©ê³¼ ì¢…ëª© ì‚¬ì´ì— ë°˜ë“œì‹œ [SEP] í•œ ì¤„ì„ ë„£ì–´ì„œ êµ¬ë¶„í•´ì¤˜.
ìœ„í—˜ ì‹ í˜¸ê°€ ì—†ëŠ” ì¢…ëª©ì€ ì ˆëŒ€ ë„£ì§€ ë§ˆ. ì‹œìŠ¤í…œ ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì„ ì§€ì–´ë‚´ì§€ ë§ˆ.
ë§Œì•½ ìœ„í—˜ ì‹ í˜¸ê°€ ìˆëŠ” ì¢…ëª©ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ "âœ… ëª¨ë“  í›„ë³´ê°€ í˜„ì¬ ì–‘í˜¸í•´ìš”." í•œ ì¤„ë§Œ ì¶œë ¥í•´.

ì˜ˆì‹œ:
**ABC Corp(ABC)**
ìµœê·¼ 5ëª…ì˜ ì• ë„ë¦¬ìŠ¤íŠ¸ê°€ EPS ì „ë§ì¹˜ë¥¼ ë‚®ì·„ì–´ìš”. ì˜ê²¬ í•˜í–¥ì´ ë§ìœ¼ë‹ˆ ì¡°ì‹¬í•˜ì„¸ìš”.
[SEP]
**XYZ Inc(XYZ)**
ì»¤ë²„ë¦¬ì§€ ì• ë„ë¦¬ìŠ¤íŠ¸ê°€ 2ëª…ë¿ì´ë¼ ì¶”ì •ì¹˜ë¥¼ 100% ë¯¿ê¸° ì–´ë ¤ì›Œìš”.

ğŸ“… ì–´ë‹ ì£¼ì˜
{earnings_info}
(ìœ„ ë‚´ìš© ê·¸ëŒ€ë¡œ í‘œì‹œ. ìˆ˜ì •/ì¶”ê°€ ê¸ˆì§€. "í•´ë‹¹ ì—†ìŒ"ì´ë©´ ì´ ì„¹ì…˜ ìƒëµ.)"""

        grounding_tool = types.Tool(google_search=types.GoogleSearch())
        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt,
            config=types.GenerateContentConfig(
                tools=[grounding_tool],
                temperature=0.2,
            ),
        )

        def extract_text(resp):
            """response.textê°€ Noneì¼ ë•Œ partsì—ì„œ ì§ì ‘ ì¶”ì¶œ"""
            try:
                if resp.text:
                    return resp.text
            except Exception:
                pass
            try:
                parts = resp.candidates[0].content.parts
                texts = [p.text for p in parts if hasattr(p, 'text') and p.text]
                if texts:
                    return '\n'.join(texts)
            except Exception:
                pass
            return None

        analysis_text = extract_text(response)

        # ì‘ë‹µ ìœ íš¨ì„± ê²€ì¦: ë¹„ì–´ìˆê±°ë‚˜ í•„ìˆ˜ ì„¹ì…˜(ğŸ“°/âš ï¸) ëˆ„ë½ì´ë©´ ì¬ì‹œë„
        def is_valid_response(text):
            if not text or len(text) < 50:
                return False
            return 'ğŸ“°' in text or 'ì‹œì¥' in text

        if not is_valid_response(analysis_text):
            try:
                if hasattr(response, 'candidates') and response.candidates:
                    candidate = response.candidates[0]
                    log(f"Gemini finish_reason: {candidate.finish_reason}", "WARN")
            except Exception:
                pass
            reason = "ë¹„ì–´ìˆìŒ" if not analysis_text else f"ì„¹ì…˜ ëˆ„ë½ ({len(analysis_text)}ì)"
            log(f"Gemini ì‘ë‹µ ë¶€ì í•© ({reason}) â€” ì¬ì‹œë„", "WARN")
            response = client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt,
                config=types.GenerateContentConfig(
                    tools=[grounding_tool],
                    temperature=0.3,
                ),
            )
            analysis_text = extract_text(response)
            if not is_valid_response(analysis_text):
                log("Gemini ì¬ì‹œë„ë„ ë¶€ì í•©", "WARN")
                if not analysis_text:
                    return None

        # Markdown â†’ Telegram HTML ë³€í™˜
        analysis_html = analysis_text
        analysis_html = analysis_html.replace('&', '&amp;')
        analysis_html = analysis_html.replace('<', '&lt;')
        analysis_html = analysis_html.replace('>', '&gt;')
        analysis_html = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', analysis_html)
        analysis_html = re.sub(r'(?<!\w)\*(?!\s)(.+?)(?<!\s)\*(?!\w)', r'<i>\1</i>', analysis_html)
        analysis_html = re.sub(r'#{1,3}\s*', '', analysis_html)
        analysis_html = analysis_html.replace('---', 'â”â”â”')
        analysis_html = re.sub(r'\n*\[SEP\]\n*', '\n\n', analysis_html)

        # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í¬ë§·íŒ…
        lines = []
        lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
        lines.append('  [2/3] ğŸ›¡ï¸ AI ë¦¬ìŠ¤í¬ í•„í„°')
        lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
        lines.append(f'ğŸ“… {biz_day.strftime("%Yë…„ %mì›” %dì¼")} (ë¯¸êµ­ì¥ ê¸°ì¤€)')
        lines.append('')
        lines.append('ë§¤ìˆ˜ í›„ë³´ì˜ ìœ„í—˜ ìš”ì†Œë¥¼ AIê°€ ê±¸ëŸ¬ëƒˆì–´ìš”.')
        lines.append('')
        lines.append(analysis_html)
        lines.append('')
        lines.append('ğŸ‘‰ ë‹¤ìŒ: ìµœì¢… ì¶”ì²œ í¬íŠ¸í´ë¦¬ì˜¤ [3/3]')

        log("AI ë¦¬ìŠ¤í¬ í•„í„° ì™„ë£Œ")
        return '\n'.join(lines)

    except Exception as e:
        log(f"AI ë¶„ì„ ì‹¤íŒ¨: {e}", "ERROR")
        return None


def run_portfolio_recommendation(config, results_df, status_map=None, biz_day=None):
    """í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œ â€” 3ì¼ ê²€ì¦(âœ…) + ë¦¬ìŠ¤í¬ í•„í„° í†µê³¼ ì¢…ëª©"""
    try:
        import re
        import yfinance as yf

        if results_df is None or results_df.empty:
            return None

        # ê³µí†µ í•„í„° ì‚¬ìš©
        filtered = get_part2_candidates(results_df, top_n=30)

        if filtered.empty:
            return None

        if status_map is None:
            status_map = {}

        # âœ… (3ì¼ ê²€ì¦) ì¢…ëª©ë§Œ ëŒ€ìƒ â€” ğŸ†•ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ ì œì™¸
        verified_tickers = {t for t, s in status_map.items() if s == 'âœ…'}
        if status_map:
            filtered = filtered[filtered['ticker'].isin(verified_tickers)]

        if biz_day is None:
            biz_day = get_last_business_day()

        if filtered.empty:
            log("í¬íŠ¸í´ë¦¬ì˜¤: âœ… ê²€ì¦ ì¢…ëª© ì—†ìŒ", "WARN")
            return '\n'.join([
                'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”',
                '   [3/3] ğŸ¯ ìµœì¢… ì¶”ì²œ',
                'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”',
                f'ğŸ“… {biz_day.strftime("%Yë…„ %mì›” %dì¼")} (ë¯¸êµ­ì¥ ê¸°ì¤€)',
                '',
                'ê²€ì¦ëœ ì¢…ëª© ì¤‘ ì•ˆì „í•œ ì¢…ëª©ì´ ì—†ì–´ìš”.',
                'ì´ë²ˆ íšŒì°¨ëŠ” <b>ê´€ë§</b>ì„ ê¶Œì¥í•©ë‹ˆë‹¤.',
                '',
                'ë¬´ë¦¬í•œ ì§„ì…ë³´ë‹¤ ê¸°ë‹¤ë¦¼ì´ ë‚˜ì„ ë•Œë„ ìˆì–´ìš”.',
            ])

        today_date = datetime.now().date()
        two_weeks = (datetime.now() + timedelta(days=14)).date()

        # ë¦¬ìŠ¤í¬ í”Œë˜ê·¸ â†’ ì•ˆì „ ì¢…ëª©ë§Œ ì„ ë³„
        log("í¬íŠ¸í´ë¦¬ì˜¤: âœ… ì¢…ëª© ë¦¬ìŠ¤í¬ í•„í„° ì ìš© ì¤‘...")
        safe = []
        for _, row in filtered.iterrows():
            t = row['ticker']
            eps_chg = row.get('eps_change_90d', 0) or 0
            price_chg = row.get('price_chg', 0) or 0
            fwd_pe = row.get('fwd_pe', 0) or 0
            rev_up = int(row.get('rev_up30', 0) or 0)
            rev_down = int(row.get('rev_down30', 0) or 0)
            num_analysts = int(row.get('num_analysts', 0) or 0)

            flags = []
            total_rev = rev_up + rev_down
            if total_rev > 0 and rev_down / total_rev > 0.3:
                flags.append("í•˜í–¥ê³¼ë°˜")
            if num_analysts < 3:
                flags.append("ì €ì»¤ë²„ë¦¬ì§€")
            # ì–´ë‹ ì„ë°•: í‘œì‹œë§Œ (í¬íŠ¸í´ë¦¬ì˜¤ ì œì™¸ ì•ˆ í•¨)
            earnings_note = ""
            try:
                cal = yf.Ticker(t).calendar
                if cal:
                    eds = cal.get('Earnings Date', [])
                    if not isinstance(eds, list):
                        eds = [eds]
                    for ed in eds:
                        if hasattr(ed, 'date'):
                            ed = ed.date()
                        if today_date <= ed <= two_weeks:
                            earnings_note = f" ğŸ“…ì–´ë‹ {ed.month}/{ed.day}"
                            break
            except Exception:
                pass

            if flags:
                log(f"  âŒ {t}: {','.join(flags)} (gap={row.get('adj_gap',0):+.1f} desc={row.get('trend_desc','')})")
            else:
                v_status = status_map.get(t, 'âœ…') if status_map else 'âœ…'
                safe.append({
                    'ticker': t,
                    'name': row.get('short_name', t),
                    'industry': row.get('industry', ''),
                    'eps_chg': eps_chg, 'price_chg': price_chg,
                    'fwd_pe': fwd_pe,
                    'adj_gap': row.get('adj_gap', 0) or 0,
                    'rev_up': rev_up, 'rev_down': rev_down,
                    'adj_score': row.get('adj_score', 0) or 0,
                    'lights': row.get('trend_lights', ''),
                    'desc': row.get('trend_desc', ''),
                    'v_status': v_status,
                })
                log(f"  {v_status} {t}: gap={row.get('adj_gap',0):+.1f} desc={row.get('trend_desc','')} up={rev_up} dn={rev_down}{earnings_note}")

        if not safe:
            log("í¬íŠ¸í´ë¦¬ì˜¤: âœ… ì¢…ëª© ì—†ìŒ", "WARN")
            return None

        # composite ìˆœì„œ ìœ ì§€ (get_part2_candidates ì •ë ¬ = adj_gap 70% + rev_growth 30%) + ì„¹í„° ë¶„ì‚° (1ì„¹í„° 1ì¢…ëª©)
        log("í¬íŠ¸í´ë¦¬ì˜¤: composite ìˆœìœ„ (ê´´ë¦¬ 70% + ë§¤ì¶œì„±ì¥ 30%):")
        for i, s in enumerate(safe):
            log(f"    {i+1}. {s['ticker']}: gap={s['adj_gap']:+.1f} adj={s['adj_score']:.1f} {s['desc']} [{s['industry']}]")
        selected = []
        used_sectors = set()
        for s in safe:
            sector = s['industry']
            if sector in used_sectors:
                log(f"  â­ï¸ {s['ticker']}: ì„¹í„° ì¤‘ë³µ [{sector}] â†’ ìŠ¤í‚µ")
                continue
            selected.append(s)
            used_sectors.add(sector)
            log(f"  â†’ {s['ticker']}: [{sector}] ì„ ì •")
            if len(selected) >= 5:
                break

        if len(selected) < 3:
            log("í¬íŠ¸í´ë¦¬ì˜¤: ì„ ì • ì¢…ëª© ë¶€ì¡±", "WARN")
            return None

        # ë™ì¼ ë¹„ì¤‘ ë°°ë¶„ (5ì¢…ëª© = ê° 20%)
        n = len(selected)
        base_weight = 100 // n
        for s in selected:
            s['weight'] = base_weight
        # ë‚˜ë¨¸ì§€ 1ìœ„ë¶€í„° ë°°ë¶„ (ì˜ˆ: 3ì¢…ëª©ì´ë©´ 34/33/33)
        remainder = 100 - base_weight * n
        for i in range(remainder):
            selected[i]['weight'] += 1

        log(f"í¬íŠ¸í´ë¦¬ì˜¤: {len(selected)}ì¢…ëª© ì„ ì • â€” " +
            ", ".join(f"{s['ticker']}({s['weight']}%)" for s in selected))

        # Gemini í”„ë¡¬í”„íŠ¸
        stock_lines = []
        for i, s in enumerate(selected):
            stock_lines.append(
                f"{i+1}. {s['name']}({s['ticker']}) Â· {s['industry']} Â· "
                f"{s['lights']} {s['desc']} Â· ì ìˆ˜ {s['adj_score']:.1f}\n"
                f"   ë¹„ì¤‘ {s['weight']}% Â· EPS {s['eps_chg']:+.1f}% Â· ì£¼ê°€ {s['price_chg']:+.1f}% Â· "
                f"ê´´ë¦¬ {s['adj_gap']:+.1f}\n"
                f"   ì• ë„ë¦¬ìŠ¤íŠ¸ ì˜ê²¬ â†‘{s['rev_up']} â†“{s['rev_down']} Â· Fwd PE {s['fwd_pe']:.1f}"
            )

        prompt = f"""ë¶„ì„ ê¸°ì¤€ì¼: {biz_day.strftime('%Y-%m-%d')} (ë¯¸êµ­ ì˜ì—…ì¼)

ì•„ë˜ëŠ” EPS ëª¨ë©˜í…€ ì‹œìŠ¤í…œì´ ìë™ ì„ ì •í•œ {len(selected)}ì¢…ëª© í¬íŠ¸í´ë¦¬ì˜¤ì•¼.
ì„ ì • ê¸°ì¤€: Part 2 ë§¤ìˆ˜ í›„ë³´ ì¤‘ ìœ„í—˜ ì‹ í˜¸ ì—†ê³ (âœ…), composite ìˆœìœ„ ìƒìœ„. ë™ì¼ ë¹„ì¤‘.

[í¬íŠ¸í´ë¦¬ì˜¤]
{chr(10).join(stock_lines)}

[ì¶œë ¥ í˜•ì‹]
- í•œêµ­ì–´, ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ ë§íˆ¬ (~ì˜ˆìš”/~í•´ìš” ì²´)
- ê° ì¢…ëª©ì„ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:
  **N. ì¢…ëª©ëª…(í‹°ì»¤) Â· ë¹„ì¤‘ N%**
  ë‚ ì”¨ì•„ì´ì½˜ 1~2ì¤„ ì„ ì • ì´ìœ 
- ì¢…ëª©ê³¼ ì¢…ëª© ì‚¬ì´ì— ë°˜ë“œì‹œ [SEP] í•œ ì¤„ì„ ë„£ì–´ì„œ êµ¬ë¶„í•´ì¤˜.
- ë§¨ ëì— ë³„ë„ ë¬¸êµ¬ ë„£ì§€ ë§ˆ. (ì½”ë“œì—ì„œ ì¶”ê°€í•¨)
- 500ì ì´ë‚´

ê° ì¢…ëª©ì˜ ì„ ì • ì´ìœ ë¥¼ ì„¤ëª…í•´ì¤˜. ë¹„ì¤‘ì€ ë™ì¼(ê° {selected[0]['weight']}%)ì´ë‹ˆ ë¹„ì¤‘ ì„¤ëª…ì€ ìƒëµí•´.
ì‹œìŠ¤í…œ ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì„ ì§€ì–´ë‚´ì§€ ë§ˆ."""

        api_key = config.get('gemini_api_key', '')
        if not api_key:
            log("GEMINI_API_KEY ë¯¸ì„¤ì • â€” í¬íŠ¸í´ë¦¬ì˜¤ ì„ ì •ê¹Œì§€ë§Œ ì™„ë£Œ", "WARN")
            return None

        try:
            from google import genai
            from google.genai import types
        except ImportError:
            log("google-genai íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜ â€” í¬íŠ¸í´ë¦¬ì˜¤ ìŠ¤í‚µ", "WARN")
            return None

        client = genai.Client(api_key=api_key)
        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt,
            config=types.GenerateContentConfig(temperature=0.2),
        )

        def extract_text(resp):
            try:
                if resp.text:
                    return resp.text
            except Exception:
                pass
            try:
                parts = resp.candidates[0].content.parts
                texts = [p.text for p in parts if hasattr(p, 'text') and p.text]
                if texts:
                    return '\n'.join(texts)
            except Exception:
                pass
            return None

        text = extract_text(response)
        if not text:
            log("í¬íŠ¸í´ë¦¬ì˜¤: Gemini ì‘ë‹µ ì—†ìŒ", "WARN")
            return None

        # Markdown â†’ HTML
        html = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
        html = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', html)
        html = re.sub(r'(?<!\w)\*(?!\s)(.+?)(?<!\s)\*(?!\w)', r'<i>\1</i>', html)
        html = re.sub(r'#{1,3}\s*', '', html)
        html = re.sub(r'\n*\[SEP\]\n*', '\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n', html)

        # ë¹„ì¤‘ í•œëˆˆì— ë³´ê¸°
        summary_parts = [f'{s["name"]}({s["ticker"]}) {s["weight"]}%' for s in selected]
        summary_line = ' Â· '.join(summary_parts)

        lines = [
            'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”',
            '   [3/3] ğŸ¯ ìµœì¢… ì¶”ì²œ',
            'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”',
            f'ğŸ“… {biz_day.strftime("%Yë…„ %mì›” %dì¼")} (ë¯¸êµ­ì¥ ê¸°ì¤€)',
            '',
            f'916ì¢…ëª© â†’ Top 30 â†’ âœ… ê²€ì¦ â†’ <b>ìµœì¢… {len(selected)}ì¢…ëª©</b>',
            '',
            'ğŸ“Š <b>ë¹„ì¤‘ í•œëˆˆì— ë³´ê¸°</b>',
            summary_line,
            '',
            'â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€',
            html,
            '',
            'ğŸ’¡ <b>í™œìš©ë²•</b>',
            f'Â· ë™ì¼ ë¹„ì¤‘(ê° {selected[0]["weight"]}%) ë¶„ì‚° íˆ¬ì',
            'Â· ëª©ë¡ì—ì„œ ë¹ ì§€ë©´ ë§¤ë„ ê²€í† ',
            'Â· ìµœì†Œ 2ì£¼ ë³´ìœ , ë§¤ì¼ í›„ë³´ ê°±ì‹  í™•ì¸',
            'âš ï¸ ì°¸ê³ ìš©ì´ë©°, íˆ¬ì íŒë‹¨ì€ ë³¸ì¸ ì±…ì„ì´ì—ìš”.',
        ]

        log("í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œ ì™„ë£Œ")
        return '\n'.join(lines)

    except Exception as e:
        log(f"í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œ ì‹¤íŒ¨: {e}", "ERROR")
        return None


# ============================================================
# í…”ë ˆê·¸ë¨ ì „ì†¡
# ============================================================

def send_telegram_long(message, config, chat_id=None):
    """ê¸´ ë©”ì‹œì§€ë¥¼ ì—¬ëŸ¬ ê°œë¡œ ë¶„í• í•´ì„œ ì „ì†¡ (chat_id ì§€ì • ê°€ëŠ¥)"""
    if not config.get('telegram_enabled', False):
        return False

    bot_token = config.get('telegram_bot_token', '')
    if chat_id is None:
        chat_id = config.get('telegram_chat_id', '')

    if not bot_token or not chat_id:
        log("í…”ë ˆê·¸ë¨ ì„¤ì • ë¶ˆì™„ì „", "WARN")
        return False

    try:
        import urllib.request
        import urllib.parse

        # 4000ìì”© ë¶„í• 
        chunks = []
        remaining = message.strip()
        while remaining:
            if len(remaining) <= 4000:
                chunks.append(remaining)
                break
            else:
                split_point = remaining[:4000].rfind('\n')
                if split_point <= 0:
                    split_point = 4000
                chunks.append(remaining[:split_point])
                remaining = remaining[split_point:].strip()

        # ë¹ˆ ì²­í¬ ì œê±°
        chunks = [c for c in chunks if c.strip()]

        for i, chunk in enumerate(chunks):
            url = f"https://api.telegram.org/bot{bot_token}/sendMessage"

            data = urllib.parse.urlencode({
                'chat_id': chat_id,
                'text': chunk,
                'parse_mode': 'HTML'
            }).encode()

            req = urllib.request.Request(url, data=data)
            urllib.request.urlopen(req, timeout=10)

        log(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì™„ë£Œ ({len(chunks)}ê°œ ë©”ì‹œì§€)")
        return True

    except Exception as e:
        log(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}", "ERROR")
        return False


# ============================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================

def main():
    """NTM EPS ì‹œìŠ¤í…œ v19 ë©”ì¸ ì‹¤í–‰ â€” Safety & Trend Fusion"""
    log("=" * 60)
    log("EPS Momentum Daily Runner v19 - Safety & Trend Fusion")
    log("=" * 60)

    start_time = datetime.now()

    # ì„¤ì • ë¡œë“œ
    config = load_config()
    log(f"ì„¤ì • ë¡œë“œ ì™„ë£Œ: {CONFIG_PATH}")

    # 1. NTM ë°ì´í„° ìˆ˜ì§‘ + DB ì ì¬ (MA60, price í¬í•¨)
    log("=" * 60)
    log("NTM EPS ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    log("=" * 60)
    results_df, turnaround_df, stats = run_ntm_collection(config)

    # 2. Part 2 rank ì €ì¥ + 3ì¼ êµì§‘í•© + ì–´ì œ ëŒ€ë¹„ ë³€ë™
    import pandas as pd

    today_str = os.environ.get('MARKET_DATE') or ''
    if not today_str:
        try:
            spy_hist = yf.Ticker("SPY").history(period="5d")
            today_str = spy_hist.index[-1].strftime('%Y-%m-%d')
        except Exception:
            today_str = datetime.now().strftime('%Y-%m-%d')
    status_map = {}
    rank_history = {}
    exited_tickers = []

    if not results_df.empty:
        # ë§¤ì¶œ ì„±ì¥ë¥  ìˆ˜ì§‘ â†’ composite score (adj_gap 70% + rev_growth 30%)
        results_df = fetch_revenue_growth(results_df)
        save_part2_ranks(results_df, today_str)

        # ì˜¤ëŠ˜ Part 2 í›„ë³´ í‹°ì»¤ ëª©ë¡ (Top 30)
        candidates = get_part2_candidates(results_df, top_n=30)
        today_tickers = list(candidates['ticker']) if not candidates.empty else []

        status_map = get_3day_status(today_tickers)
        rank_history = get_rank_history(today_tickers)
        _, exited_tickers = get_daily_changes(today_tickers)

    stats['exited_count'] = len(exited_tickers) if exited_tickers else 0

    # 2.5. ì‹œì¥ ì§€ìˆ˜ ìˆ˜ì§‘
    market_lines = get_market_context()
    if market_lines:
        log(f"ì‹œì¥ ì§€ìˆ˜: {len(market_lines)}ê°œ")

    # 3. ë©”ì‹œì§€ ìƒì„±
    msg_part2 = create_part2_message(results_df, status_map, exited_tickers, market_lines, rank_history) if not results_df.empty else None

    # ì‹¤í–‰ ì‹œê°„
    elapsed = (datetime.now() - start_time).total_seconds()
    msg_log = create_system_log_message(stats, elapsed, config)

    # 4. í…”ë ˆê·¸ë¨ ë°œì†¡: ğŸ“– ê°€ì´ë“œ â†’ [1/3] ë§¤ìˆ˜ í›„ë³´ â†’ [2/3] AI ë¦¬ìŠ¤í¬ í•„í„° â†’ [3/3] ìµœì¢… ì¶”ì²œ â†’ ë¡œê·¸
    if config.get('telegram_enabled', False):
        is_github = config.get('is_github_actions', False)
        private_id = config.get('telegram_private_id') or config.get('telegram_chat_id')
        channel_id = config.get('telegram_channel_id')

        # cold start: 3ì¼ ë¯¸ë§Œ ë°ì´í„° â†’ ì±„ë„ ì „ì†¡ ì•ˆí•¨ (ê°œì¸ë´‡ë§Œ)
        cold_start = is_cold_start()
        send_to_channel = is_github and channel_id and not cold_start
        if cold_start:
            log(f"Cold start â€” ì±„ë„ ì „ì†¡ ë¹„í™œì„±í™” (3ì¼ ë°ì´í„° ì¶•ì  ì „)")

        dest = 'ì±„ë„+ê°œì¸ë´‡' if send_to_channel else 'ê°œì¸ë´‡'

        # ğŸ“– íˆ¬ì ê°€ì´ë“œ
        msg_guide = create_guide_message()
        if send_to_channel:
            send_telegram_long(msg_guide, config, chat_id=channel_id)
        send_telegram_long(msg_guide, config, chat_id=private_id)
        log(f"ğŸ“– íˆ¬ì ê°€ì´ë“œ ì „ì†¡ ì™„ë£Œ â†’ {dest}")

        # [1/3] ë§¤ìˆ˜ í›„ë³´
        if msg_part2:
            if send_to_channel:
                send_telegram_long(msg_part2, config, chat_id=channel_id)
            send_telegram_long(msg_part2, config, chat_id=private_id)
            log(f"[1/3] ë§¤ìˆ˜ í›„ë³´ ì „ì†¡ ì™„ë£Œ â†’ {dest}")

        # [2/3] AI ë¦¬ìŠ¤í¬ í•„í„°
        biz_day = get_last_business_day()
        msg_ai = run_ai_analysis(config, results_df=results_df, status_map=status_map, biz_day=biz_day)
        if msg_ai:
            if send_to_channel:
                send_telegram_long(msg_ai, config, chat_id=channel_id)
            send_telegram_long(msg_ai, config, chat_id=private_id)
            log(f"[2/3] AI ë¦¬ìŠ¤í¬ í•„í„° ì „ì†¡ ì™„ë£Œ â†’ {dest}")

        # [3/3] ìµœì¢… ì¶”ì²œ
        msg_portfolio = run_portfolio_recommendation(config, results_df, status_map, biz_day=biz_day)
        if msg_portfolio:
            if send_to_channel:
                send_telegram_long(msg_portfolio, config, chat_id=channel_id)
            send_telegram_long(msg_portfolio, config, chat_id=private_id)
            log(f"[3/3] ìµœì¢… ì¶”ì²œ ì „ì†¡ ì™„ë£Œ â†’ {dest}")

        # ì‹œìŠ¤í…œ ë¡œê·¸ â†’ ê°œì¸ë´‡ì—ë§Œ (í•­ìƒ)
        send_telegram_long(msg_log, config, chat_id=private_id)
        log("ì‹œìŠ¤í…œ ë¡œê·¸ ì „ì†¡ ì™„ë£Œ â†’ ê°œì¸ë´‡")

    # 5. Git commit/push
    git_commit_push(config)

    # ì™„ë£Œ
    elapsed = (datetime.now() - start_time).total_seconds()
    log("=" * 60)
    log(f"ì „ì²´ ì™„ë£Œ: {elapsed:.1f}ì´ˆ ì†Œìš”")
    log("=" * 60)

    return 0


if __name__ == '__main__':
    sys.exit(main())
