"""
EPS Momentum Daily Runner v19 - Safety & Trend Fusion

ê¸°ëŠ¥:
1. NTM EPS ì „ ì¢…ëª© ìˆ˜ì§‘ + MA60 ê³„ì‚° & DB ì ì¬
2. í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ 2ì¢… + ë¡œê·¸ ìƒì„± & ë°œì†¡
   - [1/2] ë§¤ìˆ˜ í›„ë³´ + ì‹œì¥ì§€ìˆ˜ + Death List + ë³´ìœ  í™•ì¸
   - [2/2] AI ì ê²€ + ìµœì¢… ì¶”ì²œ í¬íŠ¸í´ë¦¬ì˜¤ (í†µí•©)
   - ì‹œìŠ¤í…œ ë¡œê·¸ (ê°œì¸ë´‡)
3. Git ìë™ commit/push

ì‹¤í–‰: python daily_runner.py
"""

import os
import sys
import io
import json
import sqlite3
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
try:
    import pytz
    HAS_PYTZ = True
except ImportError:
    HAS_PYTZ = False
import warnings
warnings.filterwarnings('ignore')

# Windowsì—ì„œ UTF-8 ì¸ì½”ë”© ê°•ì œ ì ìš© (ì´ëª¨ì§€ ì§€ì›)
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent
DB_PATH = PROJECT_ROOT / 'eps_momentum_data.db'
CONFIG_PATH = PROJECT_ROOT / 'config.json'

# ê¸°ë³¸ ì„¤ì •
DEFAULT_CONFIG = {
    "git_enabled": True,
    "git_remote": "origin",
    "git_branch": "master",
    "telegram_enabled": False,
    "telegram_bot_token": "",
    "telegram_chat_id": "",
    "telegram_channel_id": "",
    "telegram_private_id": "",
}


def load_config():
    """ì„¤ì • ë¡œë“œ (config.json â†’ í™˜ê²½ë³€ìˆ˜ ìˆœìœ¼ë¡œ ì²´í¬)"""
    if CONFIG_PATH.exists():
        with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
            config = json.load(f)
            for key, value in DEFAULT_CONFIG.items():
                if key not in config:
                    config[key] = value
    else:
        with open(CONFIG_PATH, 'w', encoding='utf-8') as f:
            json.dump(DEFAULT_CONFIG, f, indent=2, ensure_ascii=False)
        config = DEFAULT_CONFIG.copy()

    # í™˜ê²½ë³€ìˆ˜ ì˜¤ë²„ë¼ì´ë“œ (GitHub Actionsìš©)
    if os.environ.get('TELEGRAM_BOT_TOKEN'):
        config['telegram_bot_token'] = os.environ['TELEGRAM_BOT_TOKEN']
        config['telegram_enabled'] = True
    if os.environ.get('TELEGRAM_CHAT_ID'):
        config['telegram_channel_id'] = os.environ['TELEGRAM_CHAT_ID']
    if os.environ.get('TELEGRAM_PRIVATE_ID'):
        config['telegram_private_id'] = os.environ['TELEGRAM_PRIVATE_ID']
        config['telegram_chat_id'] = os.environ['TELEGRAM_PRIVATE_ID']

    config['is_github_actions'] = bool(os.environ.get('GITHUB_ACTIONS'))

    # Gemini API í‚¤ (AI ë¶„ì„ìš©)
    if os.environ.get('GEMINI_API_KEY'):
        config['gemini_api_key'] = os.environ['GEMINI_API_KEY']

    return config


def log(message, level="INFO"):
    """ë¡œê·¸ ì¶œë ¥"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] [{level}] {message}")


# ============================================================
# NTM EPS ë°ì´í„° ìˆ˜ì§‘
# ============================================================

def init_ntm_database():
    """ntm_screening í…Œì´ë¸” ìƒì„±"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    cursor.execute('''
        CREATE TABLE IF NOT EXISTS ntm_screening (
            date        TEXT,
            ticker      TEXT,
            rank        INTEGER,
            score       REAL,
            ntm_current REAL,
            ntm_7d      REAL,
            ntm_30d     REAL,
            ntm_60d     REAL,
            ntm_90d     REAL,
            is_turnaround INTEGER DEFAULT 0,
            adj_score   REAL,
            adj_gap     REAL,
            price       REAL,
            ma60        REAL,
            part2_rank  INTEGER,
            PRIMARY KEY (date, ticker)
        )
    ''')

    # ê¸°ì¡´ DB ë§ˆì´ê·¸ë ˆì´ì…˜: ìƒˆ ì»¬ëŸ¼ ì¶”ê°€
    for col, col_type in [('adj_score', 'REAL'), ('adj_gap', 'REAL'),
                          ('price', 'REAL'), ('ma60', 'REAL'), ('part2_rank', 'INTEGER'),
                          ('rev_up30', 'INTEGER'), ('rev_down30', 'INTEGER'), ('num_analysts', 'INTEGER')]:
        try:
            cursor.execute(f'ALTER TABLE ntm_screening ADD COLUMN {col} {col_type}')
        except sqlite3.OperationalError:
            pass  # ì´ë¯¸ ì¡´ì¬

    # composite_rank: ë‹¹ì¼ composite ìˆœìœ„ (ê°€ì¤‘ìˆœìœ„ ê³„ì‚° ì›ë³¸)
    try:
        cursor.execute('ALTER TABLE ntm_screening ADD COLUMN composite_rank INTEGER')
    except sqlite3.OperationalError:
        pass

    # v33: ì¬ë¬´ í’ˆì§ˆ + rev_growth ì»¬ëŸ¼
    for col, col_type in [('rev_growth', 'REAL'),
                          ('market_cap', 'REAL'), ('free_cashflow', 'REAL'),
                          ('roe', 'REAL'), ('debt_to_equity', 'REAL'),
                          ('operating_margin', 'REAL'), ('gross_margin', 'REAL'),
                          ('current_ratio', 'REAL'), ('total_debt', 'REAL'),
                          ('total_cash', 'REAL'), ('ev', 'REAL'),
                          ('ebitda', 'REAL'), ('beta', 'REAL')]:
        try:
            cursor.execute(f'ALTER TABLE ntm_screening ADD COLUMN {col} {col_type}')
        except sqlite3.OperationalError:
            pass

    # ê¸°ì¡´ eps_snapshots í…Œì´ë¸” ì‚­ì œ
    cursor.execute('DROP TABLE IF EXISTS eps_snapshots')

    # Forward Test íŠ¸ë˜ì»¤: í¬íŠ¸í´ë¦¬ì˜¤ ì´ë ¥ í…Œì´ë¸”
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS portfolio_log (
            date        TEXT,
            ticker      TEXT,
            action      TEXT,
            price       REAL,
            weight      REAL,
            entry_date  TEXT,
            entry_price REAL,
            exit_price  REAL,
            return_pct  REAL,
            PRIMARY KEY (date, ticker)
        )
    ''')

    # AI ë¶„ì„ ì €ì¥ í…Œì´ë¸” (ëŒ€ì‹œë³´ë“œìš©)
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS ai_analysis (
            date           TEXT NOT NULL,
            analysis_type  TEXT NOT NULL,
            ticker         TEXT DEFAULT '__ALL__',
            content        TEXT NOT NULL,
            created_at     TEXT DEFAULT CURRENT_TIMESTAMP,
            PRIMARY KEY (date, analysis_type, ticker)
        )
    ''')

    conn.commit()
    conn.close()
    log("NTM ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")


def run_ntm_collection(config):
    """NTM EPS ì „ ì¢…ëª© ìˆ˜ì§‘ & DB ì ì¬

    ìµœì í™”:
    - ê°€ê²© ë°ì´í„°: yf.download() ì¼ê´„ ë‹¤ìš´ë¡œë“œ (ë‚´ì¥ ìŠ¤ë ˆë”©)
    - ì¢…ëª© ì •ë³´: JSON ìºì‹œ (shortName, industry)
    - EPS ë°ì´í„°: ìˆœì°¨ ì²˜ë¦¬ (yfinance ìŠ¤ë ˆë”© ë¹„í˜¸í™˜)

    Returns:
        tuple (results_df, turnaround_df, stats_dict)
    """
    import yfinance as yf
    import pandas as pd

    from eps_momentum_system import (
        INDICES, INDUSTRY_MAP,
        calculate_ntm_eps, calculate_ntm_score, calculate_eps_change_90d,
        get_trend_lights,
    )

    init_ntm_database()

    today = datetime.now()
    today_str = os.environ.get('MARKET_DATE') or ''
    if not today_str:
        try:
            spy_hist = yf.Ticker("SPY").history(period="5d")
            today_str = spy_hist.index[-1].strftime('%Y-%m-%d')
        except Exception:
            today_str = today.strftime('%Y-%m-%d')
    log(f"ë§ˆì¼“ ë‚ ì§œ: {today_str}")

    all_tickers = sorted(set(t for tlist in INDICES.values() for t in tlist))
    log(f"ìœ ë‹ˆë²„ìŠ¤: {len(all_tickers)}ê°œ ì¢…ëª©")

    # Step 1: ì¢…ëª© ì •ë³´ ìºì‹œ ë¡œë“œ
    cache_path = PROJECT_ROOT / 'ticker_info_cache.json'
    ticker_cache = {}
    if cache_path.exists():
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                ticker_cache = json.load(f)
            log(f"ì¢…ëª© ì •ë³´ ìºì‹œ ë¡œë“œ: {len(ticker_cache)}ê°œ")
        except Exception:
            ticker_cache = {}

    # Step 2: ê°€ê²© ë°ì´í„° ì¼ê´„ ë‹¤ìš´ë¡œë“œ
    log("ê°€ê²© ë°ì´í„° ì¼ê´„ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    hist_all = None
    try:
        hist_all = yf.download(all_tickers, period='6mo', threads=True, progress=False)
        log("ê°€ê²© ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        log(f"ì¼ê´„ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}, ê°œë³„ ë‹¤ìš´ë¡œë“œë¡œ ì „í™˜", "WARN")

    # Step 3: ì¢…ëª©ë³„ EPS ë°ì´í„° ìˆœì°¨ ìˆ˜ì§‘
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    results = []
    turnaround = []
    no_data = []
    errors = []
    cache_updated = False

    for i, ticker in enumerate(all_tickers):
        if (i + 1) % 100 == 0:
            log(f"  ìˆ˜ì§‘ ì§„í–‰: {i+1}/{len(all_tickers)} (ë©”ì¸: {len(results)}, í„´ì–´ë¼ìš´ë“œ: {len(turnaround)})")
            conn.commit()

        try:
            stock = yf.Ticker(ticker)

            # NTM EPS ê³„ì‚°
            ntm = calculate_ntm_eps(stock, today)
            if ntm is None:
                no_data.append(ticker)
                continue

            # Score ê³„ì‚°
            score, seg1, seg2, seg3, seg4, is_turnaround, adj_score, direction = calculate_ntm_score(ntm)
            eps_change_90d = calculate_eps_change_90d(ntm)
            trend_lights, trend_desc = get_trend_lights(seg1, seg2, seg3, seg4)

            # EPS Revision & ì• ë„ë¦¬ìŠ¤íŠ¸ ìˆ˜ ì¶”ì¶œ â€” max(0y, +1y)ë¡œ ë‘ ê¸°ê°„ ëª¨ë‘ ë°˜ì˜
            rev_up30 = 0
            rev_down30 = 0
            num_analysts = 0
            try:
                raw_trend = stock._analysis._earnings_trend
                if raw_trend:
                    for item in raw_trend:
                        if item.get('period') in ('0y', '+1y'):
                            eps_rev = item.get('epsRevisions', {})
                            up_data = eps_rev.get('upLast30days', {})
                            down_data = eps_rev.get('downLast30days', {})
                            up_val = up_data.get('raw', 0) if isinstance(up_data, dict) else 0
                            down_val = down_data.get('raw', 0) if isinstance(down_data, dict) else 0
                            ea = item.get('earningsEstimate', {})
                            na_data = ea.get('numberOfAnalysts', {})
                            na_val = na_data.get('raw', 0) if isinstance(na_data, dict) else 0
                            rev_up30 = max(rev_up30, up_val)
                            rev_down30 = max(rev_down30, down_val)
                            num_analysts = max(num_analysts, na_val)
            except Exception:
                pass

            # DB ì ì¬ (ê¸°ë³¸ ë°ì´í„° â€” price/ma60/adj_gapì€ í›„ì† UPDATEë¡œ ì¶”ê°€)
            # INSERT ON CONFLICT: ê¸°ì¡´ part2_rank ë³´ì¡´
            cursor.execute('''
                INSERT INTO ntm_screening
                (date, ticker, rank, score, ntm_current, ntm_7d, ntm_30d, ntm_60d, ntm_90d, is_turnaround)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ON CONFLICT(date, ticker) DO UPDATE SET
                    rank=excluded.rank, score=excluded.score,
                    ntm_current=excluded.ntm_current, ntm_7d=excluded.ntm_7d,
                    ntm_30d=excluded.ntm_30d, ntm_60d=excluded.ntm_60d,
                    ntm_90d=excluded.ntm_90d, is_turnaround=excluded.is_turnaround
            ''', (today_str, ticker, 0, score,
                  ntm['current'], ntm['7d'], ntm['30d'], ntm['60d'], ntm['90d'],
                  1 if is_turnaround else 0))

            # ì¢…ëª© ì •ë³´ (ìºì‹œ ìš°ì„ , ì—†ìœ¼ë©´ API í˜¸ì¶œ)
            if ticker in ticker_cache:
                short_name = ticker_cache[ticker]['shortName']
                industry_kr = ticker_cache[ticker]['industry']
            else:
                info = stock.info
                short_name = info.get('shortName', ticker)
                industry_en = info.get('industry', 'N/A')
                industry_kr = INDUSTRY_MAP.get(industry_en, industry_en)
                ticker_cache[ticker] = {'shortName': short_name, 'industry': industry_kr}
                cache_updated = True

            # ê°€ê²© & ë‹¤ì¤‘ ì£¼ê¸° ê´´ë¦¬ìœ¨ (ì¼ê´„ ë‹¤ìš´ë¡œë“œ ë°ì´í„° ì‚¬ìš©)
            fwd_pe_now = None
            fwd_pe_chg = None  # ê°€ì¤‘í‰ê·  ê´´ë¦¬ìœ¨
            price_chg = None
            price_chg_weighted = None
            eps_chg_weighted = None
            current_price = None
            ma60_val = None

            try:
                if hist_all is not None:
                    hist = hist_all['Close'][ticker].dropna()
                else:
                    h = stock.history(period='6mo')
                    hist = h['Close']

                if len(hist) >= 60:
                    p_now = hist.iloc[-1]
                    current_price = float(p_now)
                    ma60_val = float(hist.rolling(window=60).mean().iloc[-1])
                    hist_dt = hist.index.tz_localize(None) if hist.index.tz else hist.index

                    # ê° ì‹œì ì˜ ì£¼ê°€ ì°¾ê¸°
                    prices = {}
                    for days, key in [(7, '7d'), (30, '30d'), (60, '60d'), (90, '90d')]:
                        target = today - timedelta(days=days)
                        idx = (hist_dt - target).map(lambda x: abs(x.days)).argmin()
                        prices[key] = hist.iloc[idx]

                    # 90ì¼ ì£¼ê°€ë³€í™”ìœ¨ (ë‚´ë¶€ìš©)
                    price_chg = (p_now - prices['90d']) / prices['90d'] * 100

                    # ê°€ì¤‘í‰ê·  ì£¼ê°€ë³€í™”ìœ¨ (âš ï¸ ê²½ê³  íŒë³„ìš©)
                    price_w = {'7d': 0.4, '30d': 0.3, '60d': 0.2, '90d': 0.1}
                    pw_sum = sum(
                        w * (p_now - prices[k]) / prices[k] * 100
                        for k, w in price_w.items() if prices[k] > 0
                    )
                    pw_total = sum(w for k, w in price_w.items() if prices[k] > 0)
                    price_chg_weighted = pw_sum / pw_total if pw_total > 0 else None

                    # ê°€ì¤‘í‰ê·  EPSë³€í™”ìœ¨ (âš ï¸ ê²½ê³  íŒë³„ìš©)
                    nc_val = ntm['current']
                    eps_w = {'7d': 0.4, '30d': 0.3, '60d': 0.2, '90d': 0.1}
                    ew_sum = sum(
                        w * (nc_val - ntm[k]) / abs(ntm[k]) * 100
                        for k, w in eps_w.items() if ntm[k] != 0
                    )
                    ew_total = sum(w for k, w in eps_w.items() if ntm[k] != 0)
                    eps_chg_weighted = ew_sum / ew_total if ew_total > 0 else None

                    # í˜„ì¬ Fwd PE
                    nc = ntm['current']
                    if nc > 0:
                        fwd_pe_now = p_now / nc

                    # ê° ì£¼ê¸°ë³„ ê´´ë¦¬ìœ¨ â†’ ê°€ì¤‘í‰ê· 
                    weights = {'7d': 0.4, '30d': 0.3, '60d': 0.2, '90d': 0.1}
                    weighted_sum = 0.0
                    total_weight = 0.0

                    for key, w in weights.items():
                        ntm_val = ntm[key]
                        if nc > 0 and ntm_val > 0 and prices[key] > 0:
                            fwd_pe_then = prices[key] / ntm_val
                            pe_chg_period = (fwd_pe_now - fwd_pe_then) / fwd_pe_then * 100
                            weighted_sum += w * pe_chg_period
                            total_weight += w

                    if total_weight > 0:
                        fwd_pe_chg = weighted_sum / total_weight
            except Exception as e:
                log(f"  {ticker} ê°€ê²©/PE ê³„ì‚° ì‹¤íŒ¨: {e}", "WARN")

            # adj_gap: ê´´ë¦¬ìœ¨ì— ë°©í–¥ ë³´ì • (ê°€ì† â†’ ì €í‰ê°€ ê°•í™”, ê°ì† â†’ ì €í‰ê°€ ì•½í™”)
            adj_gap = None
            if fwd_pe_chg is not None and direction is not None:
                dir_factor = max(-0.3, min(0.3, direction / 30))
                adj_gap = fwd_pe_chg * (1 + dir_factor)

            row = {
                'ticker': ticker,
                'short_name': short_name,
                'industry': industry_kr,
                'score': score,
                'adj_score': adj_score,
                'direction': direction,
                'seg1': seg1, 'seg2': seg2, 'seg3': seg3, 'seg4': seg4,
                'ntm_cur': ntm['current'],
                'ntm_7d': ntm['7d'],
                'ntm_30d': ntm['30d'],
                'ntm_60d': ntm['60d'],
                'ntm_90d': ntm['90d'],
                'eps_change_90d': eps_change_90d,
                'trend_lights': trend_lights,
                'trend_desc': trend_desc,
                'price_chg': price_chg,
                'price_chg_weighted': price_chg_weighted,
                'eps_chg_weighted': eps_chg_weighted,
                'fwd_pe': fwd_pe_now,
                'fwd_pe_chg': fwd_pe_chg,
                'adj_gap': adj_gap,
                'is_turnaround': is_turnaround,
                'rev_up30': rev_up30,
                'rev_down30': rev_down30,
                'num_analysts': num_analysts,
                'price': current_price,
                'ma60': ma60_val,
            }

            # DBì— íŒŒìƒ ë°ì´í„° ì—…ë°ì´íŠ¸
            cursor.execute('''
                UPDATE ntm_screening
                SET adj_score=?, adj_gap=?, price=?, ma60=?,
                    rev_up30=?, rev_down30=?, num_analysts=?
                WHERE date=? AND ticker=?
            ''', (adj_score, adj_gap, current_price, ma60_val,
                  rev_up30, rev_down30, num_analysts, today_str, ticker))

            if is_turnaround:
                turnaround.append(row)
            else:
                results.append(row)

        except Exception as e:
            errors.append((ticker, str(e)))
            continue

    conn.commit()

    # ì¢…ëª© ì •ë³´ ìºì‹œ ì €ì¥
    if cache_updated:
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump(ticker_cache, f, ensure_ascii=False, indent=2)
        log(f"ì¢…ëª© ì •ë³´ ìºì‹œ ì €ì¥: {len(ticker_cache)}ê°œ")

    # ë©”ì¸ ë­í‚¹: adj_score(ë°©í–¥ ë³´ì • ì ìˆ˜) ìˆœ ì •ë ¬ + rank ì—…ë°ì´íŠ¸
    results_df = pd.DataFrame(results)
    if not results_df.empty:
        results_df = results_df.sort_values('adj_score', ascending=False).reset_index(drop=True)
        results_df['rank'] = results_df.index + 1

        for _, row in results_df.iterrows():
            cursor.execute(
                'UPDATE ntm_screening SET rank = ? WHERE date = ? AND ticker = ?',
                (int(row['rank']), today_str, row['ticker'])
            )

    # í„´ì–´ë¼ìš´ë“œ: score ìˆœ ì •ë ¬
    turnaround_df = pd.DataFrame(turnaround)
    if not turnaround_df.empty:
        turnaround_df = turnaround_df.sort_values('score', ascending=False).reset_index(drop=True)

    conn.commit()
    conn.close()

    # í†µê³„
    stats = {
        'universe': len(all_tickers),
        'main_count': len(results),
        'turnaround_count': len(turnaround),
        'no_data_count': len(no_data),
        'error_count': len(errors),
        'error_tickers': [t for t, _ in errors],
        'total_collected': len(results) + len(turnaround),
    }

    # score_gt0/gt3/aligned_count ì œê±° â€” ì‹œìŠ¤í…œ ë¡œê·¸ì—ì„œ ë¯¸ì‚¬ìš©

    log(f"ìˆ˜ì§‘ ì™„ë£Œ: ë©”ì¸ {len(results)}, í„´ì–´ë¼ìš´ë“œ {len(turnaround)}, "
        f"ë°ì´í„°ì—†ìŒ {len(no_data)}, ì—ëŸ¬ {len(errors)}")

    return results_df, turnaround_df, stats, today_str


# ============================================================
# Part 2 ê³µí†µ í•„í„° & 3ì¼ êµì§‘í•©
# ============================================================

def fetch_revenue_growth(df, today_str):
    """ì „ì²´ 916ì¢…ëª© ë§¤ì¶œ ì„±ì¥ë¥  + ì¬ë¬´ í’ˆì§ˆ ìˆ˜ì§‘ (v33)

    1) ì „ì²´ ì¢…ëª© yfinance .info â†’ rev_growth + 12ê°œ ì¬ë¬´ ì§€í‘œ DB ì €ì¥
    2) composite scoreìš© rev_growthë¥¼ dataframeì— ë§¤í•‘
    10ìŠ¤ë ˆë“œ ë³‘ë ¬ ìˆ˜ì§‘ìœ¼ë¡œ ~3ë¶„ â†’ ~30ì´ˆ ë‹¨ì¶•.
    """
    import yfinance as yf
    from concurrent.futures import ThreadPoolExecutor, as_completed
    import time as _time

    def _fetch_one(ticker):
        """ë‹¨ì¼ ì¢…ëª© .info ìˆ˜ì§‘ (ìŠ¤ë ˆë“œ ì›Œì»¤)"""
        try:
            info = yf.Ticker(ticker).info
            return ticker, info
        except Exception:
            return ticker, None

    tickers = list(df['ticker'].unique())
    log(f"ë§¤ì¶œ+í’ˆì§ˆ ìˆ˜ì§‘ ì‹œì‘: {len(tickers)}ì¢…ëª© (10ìŠ¤ë ˆë“œ)")

    # ë³‘ë ¬ ìˆ˜ì§‘
    results = {}
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = {executor.submit(_fetch_one, t): t for t in tickers}
        done = 0
        for future in as_completed(futures):
            ticker, info = future.result()
            results[ticker] = info
            done += 1
            if done % 100 == 0:
                log(f"  ìˆ˜ì§‘ ì§„í–‰: {done}/{len(tickers)}")

    # DB ì¼ê´„ ì €ì¥
    rev_map = {}
    earnings_map = {}  # {ticker: datetime.date} â€” ì–´ë‹ ë‚ ì§œ (.infoì—ì„œ ì¶”ì¶œ)
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    saved = 0

    for t in tickers:
        info = results.get(t)
        if not info:
            rev_map[t] = None
            continue

        rg = info.get('revenueGrowth')
        rev_map[t] = rg

        # ì–´ë‹ ë‚ ì§œ ì¶”ì¶œ (.info earningsTimestampEnd â†’ calendar ë³„ë„ í˜¸ì¶œ ë¶ˆí•„ìš”)
        # ì¥í›„(16ì‹œ ET ì´í›„) ë°œí‘œ â†’ ì‹œì¥ ì˜í–¥ì€ ë‹¤ìŒ ê±°ë˜ì¼ì´ë¯€ë¡œ +1ì¼
        ets = info.get('earningsTimestampEnd') or info.get('earningsTimestampStart') or info.get('earningsTimestamp')
        if ets and isinstance(ets, (int, float)) and ets > 0:
            try:
                from zoneinfo import ZoneInfo
                dt_et = datetime.fromtimestamp(ets, tz=ZoneInfo('America/New_York'))
                earn_date = dt_et.date()
                if dt_et.hour >= 16:  # ì¥í›„ ë°œí‘œ â†’ ë‹¤ìŒ ê±°ë˜ì¼
                    earn_date += timedelta(days=1)
                earnings_map[t] = earn_date
            except (ValueError, OSError):
                pass

        if info.get('marketCap'):
            cursor.execute('''
                UPDATE ntm_screening
                SET rev_growth=?, market_cap=?, free_cashflow=?, roe=?,
                    debt_to_equity=?, operating_margin=?, gross_margin=?,
                    current_ratio=?, total_debt=?, total_cash=?,
                    ev=?, ebitda=?, beta=?
                WHERE date=? AND ticker=?
            ''', (
                rg,
                info.get('marketCap'),
                info.get('freeCashflow'),
                info.get('returnOnEquity'),
                info.get('debtToEquity'),
                info.get('operatingMargins'),
                info.get('grossMargins'),
                info.get('currentRatio'),
                info.get('totalDebt'),
                info.get('totalCash'),
                info.get('enterpriseValue'),
                info.get('ebitda'),
                info.get('beta'),
                today_str, t
            ))
            saved += 1

    conn.commit()
    conn.close()

    success = sum(1 for v in rev_map.values() if v is not None)
    log(f"ë§¤ì¶œ+í’ˆì§ˆ ìˆ˜ì§‘ ì™„ë£Œ: {saved}/{len(tickers)} (rev_growth {success}ê°œ)")

    df['rev_growth'] = df['ticker'].map(rev_map)
    return df, earnings_map


def get_part2_candidates(df, top_n=None):
    """Part 2 ë§¤ìˆ˜ í›„ë³´ í•„í„°ë§ (ê³µí†µ í•¨ìˆ˜)

    í•„í„°: adj_score > 9, fwd_pe > 0, eps > 0, price â‰¥ $10, price > MA60,
          rev_growth â‰¥ 10%, num_analysts â‰¥ 3, í•˜í–¥ ë¹„ìœ¨ â‰¤ 30%
    ì •ë ¬: composite score (adj_gap 70% + rev_growth 30%) ë˜ëŠ” adj_gap
    """
    import numpy as np
    import pandas as pd

    filtered = df[
        (df['adj_score'] > 9) &
        (df['adj_gap'].notna()) &
        (df['fwd_pe'].notna()) & (df['fwd_pe'] > 0) &
        (df['eps_change_90d'] > 0) &
        (df['price'].notna()) & (df['price'] >= 10) &
        (df['ma60'].notna()) & (df['price'] > df['ma60'])
    ].copy()

    # rev_growth ì¹¼ëŸ¼ì´ ìˆê³  ìœ íš¨ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ë©´ composite score ì‚¬ìš©
    has_rev = 'rev_growth' in filtered.columns and filtered['rev_growth'].notna().sum() >= 10
    if has_rev:
        # ë§¤ì¶œ ë°ì´í„° ì—†ìŒ â†’ ì œì™¸
        na_rev = filtered[filtered['rev_growth'].isna()]
        if len(na_rev) > 0:
            log(f"ë§¤ì¶œ ë°ì´í„° ì—†ìŒ ì œì™¸: {', '.join(na_rev['ticker'].tolist())}")
        filtered = filtered[filtered['rev_growth'].notna()].copy()

        # ë§¤ì¶œ ì„±ì¥ 10% ë¯¸ë§Œ â†’ ì œì™¸ (ì‚¬ì´í´/ê¸°ì €íš¨ê³¼ ë°©ì§€)
        low_rev = filtered[filtered['rev_growth'] < 0.10]
        if len(low_rev) > 0:
            log(f"ë§¤ì¶œ ì„±ì¥ ë¶€ì¡±(<10%) ì œì™¸: {', '.join(low_rev['ticker'].tolist())}")
        filtered = filtered[filtered['rev_growth'] >= 0.10].copy()

    # ì• ë„ë¦¬ìŠ¤íŠ¸ í’ˆì§ˆ í•„í„°: ì €ì»¤ë²„ë¦¬ì§€ + í•˜í–¥ ê³¼ë‹¤
    if 'num_analysts' in filtered.columns:
        low_cov = filtered[filtered['num_analysts'].fillna(0) < 3]
        if len(low_cov) > 0:
            log(f"ì €ì»¤ë²„ë¦¬ì§€(<3ëª…) ì œì™¸: {', '.join(low_cov['ticker'].tolist())}")
        filtered = filtered[filtered['num_analysts'].fillna(0) >= 3].copy()

    if 'rev_up30' in filtered.columns and 'rev_down30' in filtered.columns:
        up = filtered['rev_up30'].fillna(0)
        dn = filtered['rev_down30'].fillna(0)
        total = up + dn
        down_ratio = dn / total.replace(0, float('nan'))
        high_down = filtered[down_ratio > 0.3]
        if len(high_down) > 0:
            details = [f"{r['ticker']}(â†‘{int(r.get('rev_up30',0))}â†“{int(r.get('rev_down30',0))})" for _, r in high_down.iterrows()]
            log(f"í•˜í–¥ ê³¼ë‹¤(>30%) ì œì™¸: {', '.join(details)}")
        filtered = filtered[~(down_ratio > 0.3)].copy()

    if has_rev:
        # z-score ì •ê·œí™”
        gap_mean, gap_std = filtered['adj_gap'].mean(), filtered['adj_gap'].std()
        rev_mean, rev_std = filtered['rev_growth'].mean(), filtered['rev_growth'].std()

        if gap_std > 0 and rev_std > 0:
            z_gap = (filtered['adj_gap'] - gap_mean) / gap_std
            z_rev = (filtered['rev_growth'] - rev_mean) / rev_std
            # adj_gapì€ ìŒìˆ˜ê°€ ì¢‹ìœ¼ë¯€ë¡œ ë¶€í˜¸ ë°˜ì „, rev_growthëŠ” ì–‘ìˆ˜ê°€ ì¢‹ìŒ
            filtered['composite'] = (-z_gap) * 0.7 + z_rev * 0.3
            filtered = filtered.sort_values('composite', ascending=False)
        else:
            filtered = filtered.sort_values('adj_gap', ascending=True)
    else:
        filtered = filtered.sort_values('adj_gap', ascending=True)

    if top_n:
        filtered = filtered.head(top_n)
    return filtered


def log_portfolio_trades(selected, today_str):
    """Forward Test: í¬íŠ¸í´ë¦¬ì˜¤ ì§„ì…/ìœ ì§€/í‡´ì¶œ ê¸°ë¡

    selected = [{'ticker', 'weight', ...}, ...] â€” ì˜¤ëŠ˜ í¬íŠ¸í´ë¦¬ì˜¤ ì¢…ëª©
    ì–´ì œ í¬íŠ¸í´ë¦¬ì˜¤ì™€ ë¹„êµí•˜ì—¬ enter/hold/exit íŒë³„
    """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # ì–´ì œ í¬íŠ¸í´ë¦¬ì˜¤ (hold ë˜ëŠ” enterì¸ ì¢…ëª©)
    cursor.execute('''
        SELECT ticker, entry_date, entry_price, price
        FROM portfolio_log
        WHERE date = (SELECT MAX(date) FROM portfolio_log WHERE date < ?)
        AND action IN ('enter', 'hold')
    ''', (today_str,))
    prev = {r[0]: {'entry_date': r[1], 'entry_price': r[2], 'price': r[3]} for r in cursor.fetchall()}

    today_tickers = {s['ticker'] for s in selected}
    prev_tickers = set(prev.keys())

    # í‡´ì¶œ: ì–´ì œ ìˆì—ˆëŠ”ë° ì˜¤ëŠ˜ ì—†ëŠ” ì¢…ëª©
    for t in prev_tickers - today_tickers:
        p = prev[t]
        # í‡´ì¶œ ê°€ê²© = ì˜¤ëŠ˜(í‡´ì¶œ ê²°ì •ì¼) ì¢…ê°€
        row = cursor.execute(
            'SELECT price FROM ntm_screening WHERE date=? AND ticker=?',
            (today_str, t)
        ).fetchone()
        exit_price = row[0] if row and row[0] else p['price']
        entry_price = p['entry_price']
        ret = ((exit_price - entry_price) / entry_price * 100) if entry_price and entry_price > 0 else 0
        cursor.execute(
            'INSERT OR REPLACE INTO portfolio_log (date, ticker, action, price, weight, entry_date, entry_price, exit_price, return_pct) VALUES (?,?,?,?,?,?,?,?,?)',
            (today_str, t, 'exit', exit_price, 0, p['entry_date'], entry_price, exit_price, round(ret, 2))
        )
        log(f"ğŸ“Š Forward Test: EXIT {t} (ì§„ì… {p['entry_date']} ${entry_price:.2f} â†’ ${exit_price:.2f}, {ret:+.1f}%)")

    # ì§„ì…/ìœ ì§€
    for s in selected:
        t = s['ticker']
        price = s.get('price', 0) or 0
        weight = s.get('weight', 20)

        if t in prev_tickers:
            # ìœ ì§€
            p = prev[t]
            cursor.execute(
                'INSERT OR REPLACE INTO portfolio_log (date, ticker, action, price, weight, entry_date, entry_price) VALUES (?,?,?,?,?,?,?)',
                (today_str, t, 'hold', price, weight, p['entry_date'], p['entry_price'])
            )
        else:
            # ì‹ ê·œ ì§„ì…
            cursor.execute(
                'INSERT OR REPLACE INTO portfolio_log (date, ticker, action, price, weight, entry_date, entry_price) VALUES (?,?,?,?,?,?,?)',
                (today_str, t, 'enter', price, weight, today_str, price)
            )
            log(f"ğŸ“Š Forward Test: ENTER {t} @ ${price:.2f} ({weight}%)")

    conn.commit()
    conn.close()


def save_part2_ranks(results_df, today_str):
    """Part 2 eligible ì¢…ëª© ì €ì¥ â€” composite_rank + ê°€ì¤‘ìˆœìœ„ Top 30

    1. ì „ì²´ eligibleì˜ composite ìˆœìœ„ â†’ composite_rank ì»¬ëŸ¼ì— ì €ì¥
    2. T-1/T-2ì˜ composite_rankë¡œ ê°€ì¤‘ìˆœìœ„ ê³„ì‚° (ëˆ„ì  ë°©ì§€)
    3. ê°€ì¤‘ìˆœìœ„ ìƒìœ„ 30ê°œ â†’ part2_rank ì €ì¥
    Returns: Top 30 í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ (ê°€ì¤‘ìˆœìœ„ ìˆœ)
    """
    all_candidates = get_part2_candidates(results_df, top_n=None)
    if all_candidates.empty:
        log("Part 2 í›„ë³´ 0ê°œ â€” part2_rank ì €ì¥ ìŠ¤í‚µ")
        return []

    # 1. ì˜¤ëŠ˜ì˜ composite ìˆœìœ„ (1~N)
    all_candidates = all_candidates.reset_index(drop=True)
    composite_ranks = {row['ticker']: i + 1 for i, (_, row) in enumerate(all_candidates.iterrows())}

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # composite_rank ì €ì¥ (ëª¨ë“  eligible ì¢…ëª©)
    cursor.execute('UPDATE ntm_screening SET composite_rank=NULL WHERE date=?', (today_str,))
    for ticker, crank in composite_ranks.items():
        cursor.execute(
            'UPDATE ntm_screening SET composite_rank=? WHERE date=? AND ticker=?',
            (crank, today_str, ticker)
        )

    # 2. ì´ì „ ë‚ ì§œì˜ composite_rank ì¡°íšŒ
    cursor.execute(
        'SELECT DISTINCT date FROM ntm_screening WHERE composite_rank IS NOT NULL AND date < ? ORDER BY date DESC LIMIT 2',
        (today_str,)
    )
    prev_dates = sorted([r[0] for r in cursor.fetchall()])

    PENALTY = 50
    rank_by_date = {}
    for d in prev_dates:
        cursor.execute(
            'SELECT ticker, composite_rank FROM ntm_screening WHERE date=? AND composite_rank IS NOT NULL',
            (d,)
        )
        rank_by_date[d] = {r[0]: r[1] for r in cursor.fetchall()}

    t1 = prev_dates[-1] if len(prev_dates) >= 1 else None
    t2 = prev_dates[-2] if len(prev_dates) >= 2 else None

    # 3. ê°€ì¤‘ìˆœìœ„ = composite_T0 Ã— 0.5 + composite_T1 Ã— 0.3 + composite_T2 Ã— 0.2
    weighted = {}
    for ticker, r0 in composite_ranks.items():
        r1 = rank_by_date.get(t1, {}).get(ticker, PENALTY) if t1 else PENALTY
        r2 = rank_by_date.get(t2, {}).get(ticker, PENALTY) if t2 else PENALTY
        weighted[ticker] = r0 * 0.5 + r1 * 0.3 + r2 * 0.2

    # 4. ê°€ì¤‘ìˆœìœ„ë¡œ ì •ë ¬ â†’ Top 30
    sorted_tickers = sorted(weighted.items(), key=lambda x: x[1])
    top30 = sorted_tickers[:30]

    # 5. part2_rank ì €ì¥ (Top 30ë§Œ)
    cursor.execute('UPDATE ntm_screening SET part2_rank=NULL WHERE date=?', (today_str,))
    top30_tickers = []
    for rank, (ticker, w) in enumerate(top30, 1):
        cursor.execute(
            'UPDATE ntm_screening SET part2_rank=? WHERE date=? AND ticker=?',
            (rank, today_str, ticker)
        )
        top30_tickers.append(ticker)

    conn.commit()
    conn.close()
    log(f"Part 2 rank ì €ì¥: {len(top30_tickers)}ê°œ ì¢…ëª© (ê°€ì¤‘ìˆœìœ„ Top 30, eligible {len(composite_ranks)}ê°œ)")
    return top30_tickers


def is_cold_start():
    """DBì— part2_rank ë°ì´í„°ê°€ 3ì¼ ë¯¸ë§Œì´ë©´ True (ì±„ë„ ì „ì†¡ ì œì–´ìš©)"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute('SELECT COUNT(DISTINCT date) FROM ntm_screening WHERE part2_rank IS NOT NULL')
    count = cursor.fetchone()[0]
    conn.close()
    return count < 3


def get_3day_status(today_tickers):
    """3ì¼ ì—°ì† Part 2 ì§„ì… ì—¬ë¶€ íŒë³„ â†’ {ticker: 'âœ…' or 'â³' or 'ğŸ†•'}
    âœ… = 3ì¼ ì—°ì† (í¬íŠ¸í´ë¦¬ì˜¤ í¬í•¨)
    â³ = 2ì¼ ì—°ì† (í‘œì‹œë§Œ, í¬íŠ¸í´ë¦¬ì˜¤ ì œì™¸)
    ğŸ†• = ì˜¤ëŠ˜ë§Œ (í‘œì‹œë§Œ, í¬íŠ¸í´ë¦¬ì˜¤ ì œì™¸)
    """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # ìµœê·¼ 3ê°œ distinct date (part2_rank ìˆëŠ” ë‚ ì§œë§Œ)
    cursor.execute(
        'SELECT DISTINCT date FROM ntm_screening WHERE part2_rank IS NOT NULL ORDER BY date DESC LIMIT 3'
    )
    dates = [r[0] for r in cursor.fetchall()]

    if len(dates) < 2:
        conn.close()
        log(f"3ì¼ êµì§‘í•©: DB {len(dates)}ì¼ë¿ â€” ì „ë¶€ ğŸ†• ì²˜ë¦¬ (cold start)")
        return {t: 'ğŸ†•' for t in today_tickers}

    placeholders = ','.join('?' * len(dates))

    # 3ì¼ ëª¨ë‘ ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ì¢…ëª©
    verified_3d = set()
    if len(dates) >= 3:
        cursor.execute(f'''
            SELECT ticker FROM ntm_screening
            WHERE date IN ({placeholders}) AND part2_rank IS NOT NULL AND part2_rank <= 30
            GROUP BY ticker HAVING COUNT(DISTINCT date) = 3
        ''', dates)
        verified_3d = {r[0] for r in cursor.fetchall()}

    # ìµœê·¼ 2ì¼ ëª¨ë‘ ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ì¢…ëª©
    dates_2d = dates[:2]
    ph2 = ','.join('?' * len(dates_2d))
    cursor.execute(f'''
        SELECT ticker FROM ntm_screening
        WHERE date IN ({ph2}) AND part2_rank IS NOT NULL AND part2_rank <= 30
        Group BY ticker HAVING COUNT(DISTINCT date) = 2
    ''', dates_2d)
    verified_2d = {r[0] for r in cursor.fetchall()}

    conn.close()

    status = {}
    for t in today_tickers:
        if t in verified_3d:
            status[t] = 'âœ…'
        elif t in verified_2d:
            status[t] = 'â³'
        else:
            status[t] = 'ğŸ†•'

    v3 = sum(1 for v in status.values() if v == 'âœ…')
    v2 = sum(1 for v in status.values() if v == 'â³')
    v1 = sum(1 for v in status.values() if v == 'ğŸ†•')
    log(f"3ì¼ êµì§‘í•©: âœ… {v3}ê°œ, â³ {v2}ê°œ, ğŸ†• {v1}ê°œ")
    return status


def get_rank_history(today_tickers):
    """ìµœê·¼ 3ì¼ê°„ part2_rank ì´ë ¥ â†’ {ticker: '3â†’4â†’1'} í˜•íƒœ"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    cursor.execute(
        'SELECT DISTINCT date FROM ntm_screening WHERE part2_rank IS NOT NULL ORDER BY date DESC LIMIT 3'
    )
    dates = sorted([r[0] for r in cursor.fetchall()])

    if len(dates) < 2:
        conn.close()
        return {}

    rank_by_date = {}
    for d in dates:
        cursor.execute(
            'SELECT ticker, part2_rank FROM ntm_screening WHERE date=? AND part2_rank IS NOT NULL AND part2_rank <= 30',
            (d,)
        )
        rank_by_date[d] = {r[0]: r[1] for r in cursor.fetchall()}
    conn.close()

    history = {}
    for t in today_tickers:
        parts = []
        for d in dates:
            r = rank_by_date.get(d, {}).get(t)
            parts.append(str(r) if r else '-')
        history[t] = 'â†’'.join(parts)
    return history


def compute_weighted_ranks(today_tickers):
    """3ì¼ ê°€ì¤‘ ìˆœìœ„ ê³„ì‚° â€” composite_rank ê¸°ë°˜
    T0_composite Ã— 0.5 + T1_composite Ã— 0.3 + T2_composite Ã— 0.2
    Returns: {ticker: {'weighted': float, 'r0': int, 'r1': int, 'r2': int}}
    """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    cursor.execute(
        'SELECT DISTINCT date FROM ntm_screening WHERE composite_rank IS NOT NULL ORDER BY date DESC LIMIT 3'
    )
    dates = sorted([r[0] for r in cursor.fetchall()])

    if not dates:
        conn.close()
        return {}

    PENALTY = 50

    rank_by_date = {}
    for d in dates:
        cursor.execute(
            'SELECT ticker, composite_rank FROM ntm_screening WHERE date=? AND composite_rank IS NOT NULL',
            (d,)
        )
        rank_by_date[d] = {r[0]: r[1] for r in cursor.fetchall()}
    conn.close()

    today = dates[-1]
    t1 = dates[-2] if len(dates) >= 2 else None
    t2 = dates[-3] if len(dates) >= 3 else None

    result = {}
    for t in today_tickers:
        r0 = rank_by_date.get(today, {}).get(t, PENALTY)
        r1 = rank_by_date.get(t1, {}).get(t, PENALTY) if t1 else PENALTY
        r2 = rank_by_date.get(t2, {}).get(t, PENALTY) if t2 else PENALTY

        weighted = r0 * 0.5 + r1 * 0.3 + r2 * 0.2
        result[t] = {
            'weighted': round(weighted, 1),
            'r0': r0, 'r1': r1, 'r2': r2
        }

    log(f"ê°€ì¤‘ ìˆœìœ„: {len(result)}ê°œ ì¢…ëª© ê³„ì‚° (ë‚ ì§œ {len(dates)}ì¼)")
    return result


def get_rank_change_tags(today_tickers, weighted_ranks):
    """ìˆœìœ„ ë³€ë™ ì›ì¸ íƒœê·¸ â€” composite_rank T-1 ëŒ€ë¹„ T0 ë³€í™” ë¶„ì„

    adj_gap ë³€ë™(ì£¼ê°€â†‘/ì €í‰ê°€â†‘) â†’ adj_score ë³€ë™(ëª¨ë©˜í…€) â†’ ìƒëŒ€ë³€ë™ ìš°ì„ ìˆœìœ„ë¡œ íŒì •.
    Returns: {ticker: tag_str} â€” tag_strì€ '' ë˜ëŠ” 'ğŸ“ˆì£¼ê°€â†‘' ë“±
    """
    RANK_THRESHOLD = 3
    GAP_DELTA_THRESHOLD = 3.0
    SCORE_DELTA_THRESHOLD = 1.5

    if not weighted_ranks:
        return {}

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # ìµœê·¼ 2ì¼ ë‚ ì§œ
    cursor.execute(
        'SELECT DISTINCT date FROM ntm_screening WHERE composite_rank IS NOT NULL ORDER BY date DESC LIMIT 2'
    )
    dates = [r[0] for r in cursor.fetchall()]
    if len(dates) < 2:
        conn.close()
        return {}

    today_date, yesterday_date = dates[0], dates[1]

    # ì–´ì œ ë©”íŠ¸ë¦­
    cursor.execute(
        'SELECT ticker, adj_gap, adj_score FROM ntm_screening '
        'WHERE date=? AND composite_rank IS NOT NULL',
        (yesterday_date,)
    )
    yesterday_data = {r[0]: {'adj_gap': r[1], 'adj_score': r[2]} for r in cursor.fetchall()}

    # ì˜¤ëŠ˜ ë©”íŠ¸ë¦­
    cursor.execute(
        'SELECT ticker, adj_gap, adj_score FROM ntm_screening '
        'WHERE date=? AND composite_rank IS NOT NULL',
        (today_date,)
    )
    today_data = {r[0]: {'adj_gap': r[1], 'adj_score': r[2]} for r in cursor.fetchall()}

    conn.close()

    tags = {}
    for ticker in today_tickers:
        w_info = weighted_ranks.get(ticker)
        if not w_info:
            tags[ticker] = ''
            continue

        r0 = w_info.get('r0', 50)
        r1 = w_info.get('r1', 50)

        # ì‹ ê·œ ì§„ì…(r1=PENALTY)ì´ë©´ íƒœê·¸ ì—†ìŒ
        if r1 >= 50:
            tags[ticker] = ''
            continue

        rank_chg = r0 - r1  # ì–‘ìˆ˜ = ìˆœìœ„â†“, ìŒìˆ˜ = ìˆœìœ„â†‘

        if abs(rank_chg) < RANK_THRESHOLD:
            tags[ticker] = ''
            continue

        t0 = today_data.get(ticker, {})
        t1 = yesterday_data.get(ticker, {})

        gap_delta = (t0.get('adj_gap') or 0) - (t1.get('adj_gap') or 0)
        score_delta = (t0.get('adj_score') or 0) - (t1.get('adj_score') or 0)

        if rank_chg > 0:  # ìˆœìœ„ í•˜ë½
            if gap_delta >= GAP_DELTA_THRESHOLD:
                tags[ticker] = 'ğŸ“ˆì£¼ê°€â†‘'
            elif score_delta <= -SCORE_DELTA_THRESHOLD:
                tags[ticker] = 'ğŸ“‰ëª¨ë©˜í…€â†“'
            else:
                tags[ticker] = 'ğŸ”„ìƒëŒ€ë³€ë™'
        else:  # ìˆœìœ„ ìƒìŠ¹
            if gap_delta <= -GAP_DELTA_THRESHOLD:
                tags[ticker] = 'ğŸ’¡ì €í‰ê°€â†‘'
            elif score_delta >= SCORE_DELTA_THRESHOLD:
                tags[ticker] = 'ğŸ“ˆëª¨ë©˜í…€â†‘'
            else:
                tags[ticker] = 'ğŸ”„ìƒëŒ€ë³€ë™'

    tag_count = sum(1 for v in tags.values() if v)
    log(f"ìˆœìœ„ ë³€ë™ íƒœê·¸: {tag_count}ê°œ ì¢…ëª© (ì„ê³„ê°’: rankÂ±{RANK_THRESHOLD}, gapÂ±{GAP_DELTA_THRESHOLD}, scoreÂ±{SCORE_DELTA_THRESHOLD})")
    return tags


def get_daily_changes(today_tickers):
    """ì–´ì œ ëŒ€ë¹„ ë¦¬ìŠ¤íŠ¸ ë³€ë™ â€” ì‹ ê·œ ì§„ì… / ì´íƒˆ ì¢…ëª© (ë‹¨ìˆœ set ë¹„êµ)"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # ì–´ì œ ë‚ ì§œ (part2_rank ìˆëŠ” ê°€ì¥ ìµœê·¼)
    cursor.execute(
        'SELECT DISTINCT date FROM ntm_screening WHERE part2_rank IS NOT NULL ORDER BY date DESC LIMIT 2'
    )
    dates = [r[0] for r in cursor.fetchall()]

    if len(dates) < 2:
        conn.close()
        return [], []

    yesterday = dates[1]

    cursor.execute(
        'SELECT ticker, part2_rank FROM ntm_screening WHERE date=? AND part2_rank IS NOT NULL AND part2_rank <= 30',
        (yesterday,)
    )
    yesterday_ranks = {r[0]: r[1] for r in cursor.fetchall()}
    conn.close()

    yesterday_top30 = set(yesterday_ranks.keys())
    today_set = set(today_tickers)
    entered = today_set - yesterday_top30
    exited = yesterday_top30 - today_set
    exited_with_rank = {t: yesterday_ranks[t] for t in exited}

    log(f"ì–´ì œ ëŒ€ë¹„: +{len(entered)} ì‹ ê·œ, -{len(exited)} ì´íƒˆ")
    return sorted(entered), exited_with_rank


def fetch_hy_quadrant():
    """HY Spread Verdad 4ë¶„ë©´ + í•´ë¹™ ì‹ í˜¸ (FRED BAMLH0A0HYM2)

    ìˆ˜ì¤€: HY vs 10ë…„ ë¡¤ë§ ì¤‘ìœ„ìˆ˜ (ë„“/ì¢)
    ë°©í–¥: í˜„ì¬ vs 63ì˜ì—…ì¼(3ê°œì›”) ì „ (ìƒìŠ¹/í•˜ë½)
    â†’ Q1 íšŒë³µ(ë„“+í•˜ë½), Q2 ì„±ì¥(ì¢+í•˜ë½), Q3 ê³¼ì—´(ì¢+ìƒìŠ¹), Q4 ì¹¨ì²´(ë„“+ìƒìŠ¹)
    """
    import urllib.request
    import io
    import pandas as pd
    import numpy as np
    import time

    for attempt in range(3):
      try:
        # FREDì—ì„œ 10ë…„ì¹˜ HY spread CSV ë‹¤ìš´ë¡œë“œ
        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(days=365 * 11)).strftime('%Y-%m-%d')
        url = f"https://fred.stlouisfed.org/graph/fredgraph.csv?id=BAMLH0A0HYM2&cosd={start_date}&coed={end_date}"
        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req, timeout=15) as response:
            csv_data = response.read().decode('utf-8')

        df = pd.read_csv(io.StringIO(csv_data), parse_dates=['observation_date'])
        df.columns = ['date', 'hy_spread']
        df = df.dropna(subset=['hy_spread'])
        df['hy_spread'] = pd.to_numeric(df['hy_spread'], errors='coerce')
        df = df.dropna().set_index('date').sort_index()

        if len(df) < 1260:  # ìµœì†Œ 5ë…„ì¹˜ í•„ìš”
            log("HY Spread: ë°ì´í„° ë¶€ì¡±", level="WARN")
            return None

        # 10ë…„ ë¡¤ë§ ì¤‘ìœ„ìˆ˜ (min 5ë…„)
        df['median_10y'] = df['hy_spread'].rolling(2520, min_periods=1260).median()

        hy_spread = df['hy_spread'].iloc[-1]
        hy_prev = df['hy_spread'].iloc[-2]
        median_10y = df['median_10y'].iloc[-1]

        if pd.isna(median_10y):
            log("HY Spread: ì¤‘ìœ„ìˆ˜ ê³„ì‚° ë¶ˆê°€", level="WARN")
            return None

        # 3ê°œì›”(63ì˜ì—…ì¼) ì „
        hy_3m_ago = df['hy_spread'].iloc[-63] if len(df) >= 63 else df['hy_spread'].iloc[0]

        # ë¶„ë©´ íŒì •
        is_wide = hy_spread >= median_10y
        is_rising = hy_spread >= hy_3m_ago

        if is_wide and not is_rising:
            quadrant, label, icon = 'Q1', 'ë´„(íšŒë³µêµ­ë©´)', 'ğŸŒ¸'
        elif not is_wide and not is_rising:
            quadrant, label, icon = 'Q2', 'ì—¬ë¦„(ì„±ì¥êµ­ë©´)', 'â˜€ï¸'
        elif not is_wide and is_rising:
            quadrant, label, icon = 'Q3', 'ê°€ì„(ê³¼ì—´êµ­ë©´)', 'ğŸ‚'
        else:  # wide and rising
            quadrant, label, icon = 'Q4', 'ê²¨ìš¸(ì¹¨ì²´êµ­ë©´)', 'â„ï¸'

        # í•´ë¹™ ì‹ í˜¸ ê°ì§€
        signals = []
        daily_change_bp = (hy_spread - hy_prev) * 100

        # 1) HY 4~5%ì—ì„œ -20bp ê¸‰ì¶•ì†Œ
        if 4 <= hy_spread <= 5 and daily_change_bp <= -20:
            signals.append(f'ğŸ’ HY {hy_spread:.2f}%, ì „ì¼ ëŒ€ë¹„ {daily_change_bp:+.0f}bp ê¸‰ë½ â€” ë°˜ë“± ë§¤ìˆ˜ ê¸°íšŒì—ìš”!')

        # 2) 5% í•˜í–¥ ëŒíŒŒ
        if hy_prev >= 5 and hy_spread < 5:
            signals.append(f'ğŸ’ HY {hy_spread:.2f}%ë¡œ 5% ë°‘ìœ¼ë¡œ ë‚´ë ¤ì™”ì–´ìš” â€” ì ê·¹ ë§¤ìˆ˜ êµ¬ê°„ì´ì—ìš”!')

        # 3) 60ì¼ ê³ ì  ëŒ€ë¹„ -300bp ì´ìƒ í•˜ë½
        peak_60d = df['hy_spread'].rolling(60).max().iloc[-1]
        from_peak_bp = (hy_spread - peak_60d) * 100
        if from_peak_bp <= -300:
            signals.append(f'ğŸ’ 60ì¼ ê³ ì  ëŒ€ë¹„ {from_peak_bp:.0f}bp í•˜ë½ â€” ë°”ë‹¥ ì‹ í˜¸, ì ê·¹ ë§¤ìˆ˜í•˜ì„¸ìš”!')

        # 4) Q4â†’Q1 ì „í™˜ (ì „ì¼ ë¶„ë©´ ê³„ì‚°)
        prev_wide = hy_prev >= median_10y
        hy_3m_ago_prev = df['hy_spread'].iloc[-64] if len(df) >= 64 else df['hy_spread'].iloc[0]
        prev_rising = hy_prev >= hy_3m_ago_prev
        prev_was_q4 = prev_wide and prev_rising
        now_is_q1 = is_wide and not is_rising
        if prev_was_q4 and now_is_q1:
            signals.append('ğŸ’ ê²¨ìš¸â†’ë´„ ì „í™˜ â€” ê°€ì¥ ì¢‹ì€ ë§¤ìˆ˜ íƒ€ì´ë°ì´ì—ìš”!')

        # í˜„ì¬ ë¶„ë©´ ì§€ì† ì¼ìˆ˜ (ìµœëŒ€ 252ì˜ì—…ì¼=1ë…„ê¹Œì§€ ì—­ì¶”ì )
        df['hy_3m'] = df['hy_spread'].shift(63)
        valid_mask = df['median_10y'].notna() & df['hy_3m'].notna()
        df.loc[valid_mask, 'q'] = np.where(
            df.loc[valid_mask, 'hy_spread'] >= df.loc[valid_mask, 'median_10y'],
            np.where(df.loc[valid_mask, 'hy_spread'] >= df.loc[valid_mask, 'hy_3m'], 'Q4', 'Q1'),
            np.where(df.loc[valid_mask, 'hy_spread'] >= df.loc[valid_mask, 'hy_3m'], 'Q3', 'Q2')
        )
        q_days = 1
        for i in range(len(df) - 2, max(len(df) - 253, 0) - 1, -1):
            if i >= 0 and df['q'].iloc[i] == quadrant:
                q_days += 1
            else:
                break

        # HY ë‹¨ë… í–‰ë™ ê¶Œì¥ (fallbackìš©, ìµœì¢…ì€ get_market_risk_statusì—ì„œ ê²°ì •)
        if quadrant == 'Q1':
            action = 'ì ê·¹ ë§¤ìˆ˜í•˜ì„¸ìš”.'
        elif quadrant == 'Q2':
            action = 'í‰ì†ŒëŒ€ë¡œ íˆ¬ìí•˜ì„¸ìš”.'
        elif quadrant == 'Q3':
            action = 'ì‹ ê·œ ë§¤ìˆ˜ ì‹œ ì‹ ì¤‘í•˜ì„¸ìš”.'
        else:  # Q4
            action = 'ì‹ ê·œ ë§¤ìˆ˜ë¥¼ ë©ˆì¶”ê³  ê´€ë§í•˜ì„¸ìš”.'

        return {
            'hy_spread': hy_spread,
            'median_10y': median_10y,
            'hy_3m_ago': hy_3m_ago,
            'hy_prev': hy_prev,
            'quadrant': quadrant,
            'quadrant_label': label,
            'quadrant_icon': icon,
            'signals': signals,
            'q_days': q_days,
            'action': action,
        }

      except Exception as e:
        if attempt < 2:
            log(f"HY Spread ìˆ˜ì§‘ ì¬ì‹œë„ ({attempt+1}/3): {e}", level="WARN")
            time.sleep(5)
        else:
            log(f"HY Spread ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", level="WARN")
            return None


def fetch_vix_data():
    """VIX(CBOE ë³€ë™ì„± ì§€ìˆ˜) ë ˆì§ íŒë‹¨ + í˜„ê¸ˆë¹„ì¤‘ ê°€ê° (FRED VIXCLS)

    252ì¼(1ë…„) í¼ì„¼íƒ€ì¼ ê¸°ë°˜ ë ˆì§ íŒì • â€” ì‹œëŒ€ ë³€í™”ì— ìë™ ì ì‘
    < 10th: ì•ˆì¼ | 10~67th: ì •ìƒ | 67~80th: ê²½ê³„ | 80~90th: ìƒìŠ¹ê²½ë³´ | 90th+: ìœ„ê¸°

    Returns:
        dict or None: {vix_current, vix_5d_ago, vix_slope, vix_slope_dir,
                       vix_ma_20, vix_percentile, regime, regime_label, regime_icon,
                       cash_adjustment, direction}
    """
    import urllib.request
    import io
    import pandas as pd
    import time

    for attempt in range(3):
      try:
        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(days=400)).strftime('%Y-%m-%d')
        url = (
            f"https://fred.stlouisfed.org/graph/fredgraph.csv"
            f"?id=VIXCLS&cosd={start_date}&coed={end_date}"
        )
        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req, timeout=15) as response:
            csv_data = response.read().decode('utf-8')

        df = pd.read_csv(io.StringIO(csv_data), parse_dates=['observation_date'])
        df.columns = ['date', 'vix']
        df['vix'] = pd.to_numeric(df['vix'], errors='coerce')
        df = df.dropna().set_index('date').sort_index()

        if len(df) < 20:
            log("VIX: ë°ì´í„° ë¶€ì¡±", level="WARN")
            return None

        vix_current = float(df['vix'].iloc[-1])
        vix_5d_ago = float(df['vix'].iloc[-5]) if len(df) >= 5 else float(df['vix'].iloc[0])
        vix_slope = vix_current - vix_5d_ago
        vix_ma_20 = float(df['vix'].rolling(20).mean().iloc[-1])

        # 252ì¼(1ë…„) í¼ì„¼íƒ€ì¼ ê³„ì‚° (ìµœì†Œ 126ì¼)
        vix_pct = float(df['vix'].rolling(252, min_periods=126).rank(pct=True).iloc[-1] * 100)

        # Slope direction (Â±0.5 threshold to avoid noise)
        if vix_slope > 0.5:
            slope_dir = 'rising'
        elif vix_slope < -0.5:
            slope_dir = 'falling'
        else:
            slope_dir = 'flat'

        # í¼ì„¼íƒ€ì¼ ê¸°ë°˜ ë ˆì§ + í˜„ê¸ˆ ê°€ê°
        if vix_pct >= 90:
            # ìœ„ê¸° (ìƒìœ„ 10%)
            if slope_dir in ('rising', 'flat'):
                regime, label, icon = 'crisis', 'ìœ„ê¸°', 'ğŸ”´'
                cash_adj = 15
            else:
                regime, label, icon = 'crisis_relief', 'ê³µí¬ì™„í™”', 'ğŸ’'
                cash_adj = -10
        elif vix_pct >= 80:
            # ìƒìŠ¹ê²½ë³´ (ìƒìœ„ 10~20%)
            if slope_dir == 'rising':
                regime, label, icon = 'high', 'ìƒìŠ¹ê²½ë³´', 'ğŸ”¶'
                cash_adj = 10
            else:
                regime, label, icon = 'high_stable', 'ë†’ì§€ë§Œì•ˆì •', 'ğŸŸ¡'
                cash_adj = 0
        elif vix_pct >= 67:
            # ê²½ê³„ (ìƒìœ„ 20~33%)
            if slope_dir == 'rising':
                regime, label, icon = 'elevated', 'ê²½ê³„', 'âš ï¸'
                cash_adj = 5
            elif slope_dir == 'falling':
                regime, label, icon = 'stabilizing', 'ì•ˆì •í™”', 'ğŸŒ¡ï¸'
                cash_adj = -5
            else:
                regime, label, icon = 'elevated_flat', 'ë³´í†µ', 'ğŸŸ¡'
                cash_adj = 0
        elif vix_pct < 10:
            # ì•ˆì¼ (í•˜ìœ„ 10% â€” ê³¼ë„í•œ ë‚™ê´€)
            regime, label, icon = 'complacency', 'ì•ˆì¼', 'âš ï¸'
            cash_adj = 5
        else:
            # ì •ìƒ (10~67th)
            regime, label, icon = 'normal', 'ì•ˆì •', 'ğŸŒ¡ï¸'
            cash_adj = 0

        # Simplified direction for concordance check
        direction = 'warn' if regime in ('crisis', 'crisis_relief', 'high', 'elevated', 'complacency') else 'stable'

        log(f"VIX: {vix_current:.1f} (252ì¼ {vix_pct:.0f}th) â†’ {regime} ({label}), ê°€ê° {cash_adj:+d}%")

        return {
            'vix_current': vix_current,
            'vix_5d_ago': vix_5d_ago,
            'vix_slope': vix_slope,
            'vix_slope_dir': slope_dir,
            'vix_ma_20': vix_ma_20,
            'vix_percentile': vix_pct,
            'regime': regime,
            'regime_label': label,
            'regime_icon': icon,
            'cash_adjustment': cash_adj,
            'direction': direction,
        }

      except Exception as e:
        if attempt < 2:
            log(f"VIX ìˆ˜ì§‘ ì¬ì‹œë„ ({attempt+1}/3): {e}", level="WARN")
            time.sleep(5)
        else:
            log(f"VIX ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", level="WARN")
            return None


def get_market_risk_status():
    """ì‹œì¥ ìœ„í—˜ í†µí•© ìƒíƒœ (HY + VIX + Concordance)

    Returns:
        dict {hy, vix, concordance, final_action}
    """
    hy = fetch_hy_quadrant()
    vix = fetch_vix_data()

    # Concordance Check
    hy_dir = 'warn' if hy and hy['quadrant'] in ('Q3', 'Q4') else 'stable'
    vix_dir = vix['direction'] if vix else 'stable'

    if hy_dir == 'warn' and vix_dir == 'warn':
        concordance = 'both_warn'
    elif hy_dir == 'warn' and vix_dir == 'stable':
        concordance = 'hy_only'
    elif hy_dir == 'stable' and vix_dir == 'warn':
        concordance = 'vix_only'
    else:
        concordance = 'both_stable'

    # Concordance ê¸°ë°˜ í–‰ë™ ê¶Œì¥ (ê³„ì ˆ Ã— ì§€í‘œ Ã— q_days ì¡°í•©, 30ë…„ EDA ê¸°ë°˜)
    if hy:
        q = hy['quadrant']
        q_days = hy.get('q_days', 1)
        vix_ok = vix_dir == 'stable'

        if q == 'Q1':
            # ë´„(íšŒë³µê¸°) â€” ì—°ìœ¨+14.3%, ì–‘ìˆ˜í™•ë¥ 86%, ì—­ì‚¬ì  ìµœê³  ìˆ˜ìµ
            if vix_ok:
                final_action = 'ëª¨ë“  ì§€í‘œê°€ ë§¤ìˆ˜ë¥¼ ê°€ë¦¬ì¼œìš”. ì ê·¹ íˆ¬ìí•˜ì„¸ìš”!'
            else:
                final_action = 'íšŒë³µ êµ¬ê°„ì´ì—ìš”. VIXê°€ ë†’ì§€ë§Œ ì˜¤íˆë ¤ ë°˜ë“± ê¸°íšŒì¼ ìˆ˜ ìˆì–´ìš”. ì ê·¹ íˆ¬ìí•˜ì„¸ìš”!'
        elif q == 'Q2':
            # ì—¬ë¦„(ì„±ì¥ê¸°) â€” ì—°ìœ¨+9.4%, ì–‘ìˆ˜í™•ë¥ 84%
            if vix_ok:
                final_action = 'ëª¨ë“  ì§€í‘œê°€ ì•ˆì •ì ì´ì—ìš”. í‰ì†ŒëŒ€ë¡œ íˆ¬ìí•˜ì„¸ìš”.'
            else:
                final_action = 'ì‹ ìš©ì‹œì¥ì€ ì•ˆì •ì ì´ì§€ë§Œ VIXê°€ ë†’ì•„ìš”. ì‹ ê·œ ë§¤ìˆ˜ ì‹œ ì‹ ì¤‘í•˜ì„¸ìš”.'
        elif q == 'Q3':
            # ê°€ì„(ê³¼ì—´ê¸°) â€” 60ì¼ ê¸°ì¤€ 2ë‹¨ê³„ (EDA: <60d +1.84%, â‰¥60d +0.39%)
            if q_days < 60:
                if vix_ok:
                    final_action = 'ê³¼ì—´ ì´ˆê¸° ì‹ í˜¸ì—ìš”. ì‹ ê·œ ë§¤ìˆ˜ ì‹œ ì‹ ì¤‘í•˜ì„¸ìš”.'
                else:
                    final_action = 'ê³¼ì—´ ì´ˆê¸° + ë³€ë™ì„± í™•ëŒ€ì—ìš”. ì‹ ê·œ ë§¤ìˆ˜ë¥¼ ë©ˆì¶”ì„¸ìš”.'
            else:
                if vix_ok:
                    final_action = 'ê³¼ì—´ì´ ì§€ì†ë˜ê³  ìˆì–´ìš”. ì‹ ê·œ ë§¤ìˆ˜ë¥¼ ì¤„ì—¬ê°€ì„¸ìš”.'
                else:
                    final_action = 'ê³¼ì—´ ì¥ê¸°í™” + ë³€ë™ì„± í™•ëŒ€ì—ìš”. ë³´ìœ  ì¢…ëª©ì„ ì ê²€í•˜ê³  ì‹ ê·œ ë§¤ìˆ˜ë¥¼ ë©ˆì¶”ì„¸ìš”.'
        else:
            # ê²¨ìš¸(Q4) â€” 20ì¼/60ì¼ ê¸°ì¤€ 3ë‹¨ê³„ (EDA: â‰¤20d ì•½ì„¸, 21~60d í„´ì–´ë¼ìš´ë“œ, >60d ë°”ë‹¥ì ‘ê·¼=Q1ìˆ˜ì¤€)
            if q_days <= 20:
                # ì´ˆê¸°: ë°˜ë“± ê°€ëŠ¥ì„± ë†’ìŒ, ê¸‰ë§¤ë„ ê¸ˆì§€
                if vix_ok:
                    final_action = 'ì‹ ìš©ì‹œì¥ì´ ì•…í™”ë˜ê¸° ì‹œì‘í–ˆì–´ìš”. ê¸‰ë§¤ë„ëŠ” ê¸ˆë¬¼, ê´€ë§í•˜ì„¸ìš”.'
                else:
                    final_action = 'ì‹œì¥ì´ í”ë“¤ë¦¬ê³  ìˆì§€ë§Œ ì´ˆê¸° ë°˜ë“± ê°€ëŠ¥ì„±ì´ ìˆì–´ìš”. ê¸‰ë§¤ë„ëŠ” ê¸ˆë¬¼, ì§€ì¼œë³´ì„¸ìš”.'
            elif q_days <= 60:
                # ì¤‘ê¸°: í„´ì–´ë¼ìš´ë“œ ì‹œì‘ ê°€ëŠ¥ (EDA: 60ì¼ +0.5~1.5%)
                if vix_ok:
                    final_action = 'ì¹¨ì²´ê°€ ì§€ì† ì¤‘ì´ì§€ë§Œ ë³€ë™ì„±ì€ ì•ˆì •ì ì´ì—ìš”. ì‹ ê·œ ë§¤ìˆ˜ë¥¼ ë©ˆì¶”ê³  ê´€ë§í•˜ì„¸ìš”.'
                else:
                    final_action = 'ì¹¨ì²´ + ë³€ë™ì„± í™•ëŒ€ì—ìš”. ë³´ìœ  ì¢…ëª©ì„ ì¤„ì—¬ê°€ì„¸ìš”.'
            else:
                # í›„ê¸°(>60d): ë°”ë‹¥ê¶Œ ì ‘ê·¼, ì‚¬ì „ í¬ì„ (EDA: 60ì¼ +1.5~3.5%, Q1 ìˆ˜ì¤€)
                if vix_ok:
                    final_action = 'ë°”ë‹¥ê¶Œì— ì ‘ê·¼í•˜ê³  ìˆì–´ìš”. ë¶„í•  ë§¤ìˆ˜ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.'
                else:
                    final_action = 'ì¥ê¸° ì¹¨ì²´ì´ì§€ë§Œ ë°”ë‹¥ ê°€ëŠ¥ì„±ì´ ìˆì–´ìš”. ê´€ë§í•˜ë©° íšŒë³µ ì‹ í˜¸ë¥¼ ê¸°ë‹¤ë¦¬ì„¸ìš”.'
    else:
        # HY ë°ì´í„° ì—†ìŒ â€” VIXë§Œìœ¼ë¡œ íŒë‹¨
        if vix and vix_dir == 'warn':
            final_action = 'ë³€ë™ì„±ì´ ë†’ì•„ìš”. ì‹ ê·œ ë§¤ìˆ˜ì— ì‹ ì¤‘í•˜ì„¸ìš”.'
        else:
            final_action = 'í‰ì†ŒëŒ€ë¡œ íˆ¬ìí•˜ì„¸ìš”.'

    log(f"Concordance: {concordance} (q_days={hy.get('q_days', 'N/A') if hy else 'N/A'}) â†’ {final_action}")

    return {
        'hy': hy,
        'vix': vix,
        'concordance': concordance,
        'final_action': final_action,
    }


def get_market_context():
    """ë¯¸êµ­ ì‹œì¥ ì§€ìˆ˜ ì»¨í…ìŠ¤íŠ¸"""
    try:
        import yfinance as yf
        lines = []
        for symbol, name in [("^GSPC", "S&P 500"), ("^IXIC", "ë‚˜ìŠ¤ë‹¥"), ("^DJI", "ë‹¤ìš°")]:
            try:
                hist = yf.Ticker(symbol).history(period='5d')
                if len(hist) >= 2:
                    close = hist['Close'].iloc[-1]
                    prev = hist['Close'].iloc[-2]
                    chg = (close / prev - 1) * 100
                    icon = "ğŸŸ¢" if chg > 0.5 else ("ğŸ”´" if chg < -0.5 else "ğŸŸ¡")
                    lines.append(f"{icon} {name}  {close:,.0f} ({chg:+.2f}%)")
                else:
                    log(f"ì‹œì¥ ì§€ìˆ˜ {symbol}: ë°ì´í„° ë¶€ì¡± ({len(hist)}í–‰)", "WARN")
            except Exception as e:
                log(f"ì‹œì¥ ì§€ìˆ˜ {symbol} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", "WARN")
                continue
        if not lines:
            log("ì‹œì¥ ì§€ìˆ˜: ì „ë¶€ ìˆ˜ì§‘ ì‹¤íŒ¨", "WARN")
        return lines
    except Exception as e:
        log(f"ì‹œì¥ ì§€ìˆ˜ ëª¨ë“ˆ ì˜¤ë¥˜: {e}", "WARN")
        return []


# ============================================================
# Git ìë™ ì»¤ë°‹
# ============================================================

def git_commit_push(config):
    """Git ìë™ commit/push (GitHub Actionsì—ì„œëŠ” ì›Œí¬í”Œë¡œìš°ê°€ ì²˜ë¦¬)"""
    if not config.get('git_enabled', False):
        log("Git ë™ê¸°í™” ë¹„í™œì„±í™”ë¨")
        return False

    if config.get('is_github_actions', False):
        log("GitHub Actions í™˜ê²½ â€” ì›Œí¬í”Œë¡œìš°ì—ì„œ Git ì²˜ë¦¬")
        return True

    log("Git commit/push ì‹œì‘")

    try:
        today = datetime.now().strftime('%Y-%m-%d')

        subprocess.run(['git', 'add', '-A'], cwd=PROJECT_ROOT, check=True, capture_output=True)

        commit_msg = f"Daily update: {today}"
        result = subprocess.run(
            ['git', 'commit', '-m', commit_msg],
            cwd=PROJECT_ROOT, capture_output=True, text=True
        )

        if 'nothing to commit' in result.stdout or 'nothing to commit' in result.stderr:
            log("ë³€ê²½ì‚¬í•­ ì—†ìŒ, ì»¤ë°‹ ìŠ¤í‚µ")
            return True

        remote = config.get('git_remote', 'origin')
        branch = config.get('git_branch', 'master')
        subprocess.run(['git', 'push', remote, branch], cwd=PROJECT_ROOT, check=True, capture_output=True)

        log("Git push ì™„ë£Œ")
        return True

    except subprocess.CalledProcessError as e:
        log(f"Git ì˜¤ë¥˜: {e}", "ERROR")
        return False


# ============================================================
# í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ìƒì„±
# ============================================================

def get_last_business_day():
    """ê°€ì¥ ìµœê·¼ ë¯¸êµ­ ì˜ì—…ì¼ ë‚ ì§œ"""
    if HAS_PYTZ:
        eastern = pytz.timezone('US/Eastern')
        now_et = datetime.now(eastern)
    else:
        now_et = datetime.now() - timedelta(hours=14)

    d = now_et.date()
    # í‰ì¼ ì¥ë§ˆê° í›„(16ì‹œ ì´í›„)ë©´ ì˜¤ëŠ˜ì´ ì˜ì—…ì¼
    if d.weekday() < 5 and now_et.hour >= 16:
        return d
    # ê·¸ ì™¸: ì „ì¼ë¡œ ê°€ì„œ ê°€ì¥ ìµœê·¼ í‰ì¼ ì°¾ê¸°
    d -= timedelta(days=1)
    while d.weekday() >= 5:
        d -= timedelta(days=1)
    return d


def get_today_kst():
    """ì˜¤ëŠ˜ ë‚ ì§œ (KST)"""
    if HAS_PYTZ:
        kst = pytz.timezone('Asia/Seoul')
        return datetime.now(kst).date()
    return datetime.now().date()


def create_part1_message(df, top_n=30):
    """Part 1: ì´ìµ ëª¨ë©˜í…€ ë­í‚¹ ë©”ì‹œì§€ ìƒì„± (EPS ì ìˆ˜ ìˆœ)"""
    biz_day = get_last_business_day()
    biz_str = biz_day.strftime('%Yë…„ %mì›” %dì¼')

    lines = []
    lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    lines.append(f' [1/4] ğŸ“ˆ EPS ëª¨ë©˜í…€ Top {top_n}')
    lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    lines.append(f'ğŸ“… {biz_str} (ë¯¸êµ­ì¥ ê¸°ì¤€)')
    lines.append('')
    lines.append('ë¯¸êµ­ 916ì¢…ëª© ì¤‘ ì• ë„ë¦¬ìŠ¤íŠ¸ EPS ì „ë§ì¹˜ë¥¼')
    lines.append('ê°€ì¥ ë§ì´ ì˜¬ë¦° ê¸°ì—… ìˆœìœ„ì˜ˆìš”.')
    lines.append('')

    for _, row in df.head(top_n).iterrows():
        rank = int(row['rank'])
        ticker = row['ticker']
        name = row.get('short_name', ticker)
        industry = row.get('industry', '')
        adj_score = row.get('adj_score', row.get('score', 0))
        lights = row.get('trend_lights', '')
        desc = row.get('trend_desc', '')

        lines.append(f'<b>{rank}ìœ„</b> {name} ({ticker})')
        lines.append(f'<i>{industry}</i> Â· {lights} {desc} Â· <b>{adj_score:.1f}</b>ì ')
        lines.append('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')

    lines.append('')
    lines.append('ğŸ‘‰ ë‹¤ìŒ: ë§¤ìˆ˜ í›„ë³´ ì„ ì • [2/4]')

    return '\n'.join(lines)


def create_guide_message():
    """ğŸ“– íˆ¬ì ê°€ì´ë“œ â€” ì‹œìŠ¤í…œ ê°œìš”, ì„ ì • ê³¼ì •, ë³´ìœ /ë§¤ë„ ê¸°ì¤€"""
    lines = [
        'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”',
        '      ğŸ“– íˆ¬ì ê°€ì´ë“œ',
        'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”',
        'ğŸ” <b>ì–´ë–¤ ì¢…ëª©ì„ ì°¾ë‚˜ìš”?</b>',
        'ì›”ê°€ ì• ë„ë¦¬ìŠ¤íŠ¸ë“¤ì´ "ì´ìµì´ ëŠ˜ì–´ë‚  ê±°ì•¼"ë¼ê³ ',
        'ì „ë§ì¹˜ë¥¼ ì˜¬ë¦¬ëŠ” ì¢…ëª©ì„ ì°¾ì•„ìš”.',
        'ì—¬ëŸ¬ ì „ë¬¸ê°€ê°€ ë™ì‹œì— ì˜¬ë¦¬ë©´ ë” ê°•í•œ ì‹ í˜¸ì˜ˆìš”.',
        '',
        'ğŸ“Š <b>ì–´ë–»ê²Œ ê³¨ë¼ìš”?</b>',
        'ë¯¸êµ­ 916ì¢…ëª©ì„ ë§¤ì¼ 5ë‹¨ê³„ë¡œ ê±¸ëŸ¬ìš”.',
        '',
        'â‘  ì´ìµ ì „ë§ì´ ì˜¤ë¥´ëŠ” ì¢…ëª©ì„ ì°¾ê³ ',
        'â‘¡ ì£¼ê°€ íë¦„ì´ ê±´ê°•í•œ ì¢…ëª©ë§Œ ë‚¨ê¸°ê³ ',
        'â‘¢ ë³µí•© ìˆœìœ„(ê´´ë¦¬ 70%+ë§¤ì¶œ 30%) ìƒìœ„ ì¢…ëª© ì„ ë³„',
        'â‘£ 3ì¼ ì—°ì† ìƒìœ„ê¶Œ ìœ ì§€ ì¢…ëª©ë§Œ ë§¤ìˆ˜ í›„ë³´ë¡œ',
        'â‘¤ AI ìœ„í—˜ ì ê²€ í›„ ì‹œì¥ ìƒí™©ì— ë§ê²Œ ìµœì¢… ì¶”ì²œ',
        '',
        'â±ï¸ <b>ì–¼ë§ˆë‚˜ ë³´ìœ í•˜ë‚˜ìš”?</b>',
        'ìµœì†Œ 2ì£¼ëŠ” ë³´ìœ í•˜ëŠ” ê±¸ ê¶Œì¥í•´ìš”.',
        'ì´ìµ ì „ë§ì´ ì£¼ê°€ì— ë°˜ì˜ë˜ë ¤ë©´ ì‹œê°„ì´ í•„ìš”í•˜ê±°ë“ ìš”.',
        'ë§¤ìˆ˜ í›„ë³´ ëª©ë¡ì— ë‚¨ì•„ìˆëŠ” ë™ì•ˆì€ ê³„ì† ë³´ìœ í•˜ì„¸ìš”.',
        '',
        'ğŸ“‰ <b>ì–¸ì œ íŒŒë‚˜ìš”?</b>',
        'ìµœì†Œ 2ì£¼ ë³´ìœ  í›„, ëª©ë¡ì—ì„œ ë¹ ì§€ë©´ ë§¤ë„ ê²€í† ì˜ˆìš”.',
        'ë§¤ì¼ ìˆœìœ„ë¥¼ ë³´ì—¬ë“œë¦¬ë‹ˆê¹Œ',
        'ëª©ë¡ì— ìˆìœ¼ë©´ ë³´ìœ , ì—†ìœ¼ë©´ ë§¤ë„ ê²€í† .',
        '',
        'ğŸ’° <b>ì–¼ë§ˆë¥¼ íˆ¬ìí•˜ë‚˜ìš”?</b>',
        'ì „ì²´ íˆ¬ì ìì‚°ì˜ 20~30%ë§Œ ì´ ì „ëµì— ì ìš©í•˜ì„¸ìš”.',
        'ë‚˜ë¨¸ì§€ 70~80%ëŠ” VTI ê°™ì€ ì§€ìˆ˜ ETFì— ë¶„ì‚°í•˜ë©´',
        'ì•ˆì •ì ì¸ í¬íŠ¸í´ë¦¬ì˜¤ê°€ ë©ë‹ˆë‹¤.',
        '',
        'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”',
        '       ğŸ’¡ ì½ëŠ” ë²•',
        'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”',
        'ğŸš¨ <b>ì‹œì¥ í˜„í™© [1/4]</b>',
        'ê³„ì ˆ = ì‹ ìš©ì‹œì¥ ê¸°ë°˜ ì‹œì¥ êµ­ë©´',
        'ğŸŒ¸ë´„(íšŒë³µ) Â· â˜€ï¸ì—¬ë¦„(ì„±ì¥)',
        'ğŸ‚ê°€ì„(ê³¼ì—´) Â· â„ï¸ê²¨ìš¸(ì¹¨ì²´)',
        'ğŸŸ¢ì•ˆì • ğŸ”´ìœ„í—˜ â€” ğŸ¦ì‹ ìš© Â· âš¡ë³€ë™ì„±',
        'ğŸŸ¢ ë§ìœ¼ë©´ ì ê·¹, ğŸ”´ ë§ìœ¼ë©´ ë§¤ìˆ˜ ì¤‘ë‹¨',
        '',
        'ğŸ“‹ <b>ë§¤ìˆ˜ í›„ë³´ [2/4]</b>',
        'âœ… 3ì¼ ì—°ì† Top 30 â†’ ë§¤ìˆ˜ í›„ë³´',
        'â³ 2ì¼ ì—°ì† â†’ ë‚´ì¼ ê²€ì¦ ì™„ë£Œ',
        'ğŸ†• ì˜¤ëŠ˜ ì²« ì§„ì… â†’ ê´€ì°°',
        '',
        'ì¶”ì„¸ ì•„ì´ì½˜ (90â†’60â†’30â†’7â†’ì˜¤ëŠ˜):',
        'ğŸ”¥í­ë“± â˜€ï¸ê°•ì„¸ ğŸŒ¤ï¸ìƒìŠ¹ â˜ï¸ë³´í•© ğŸŒ§ï¸í•˜ë½',
        'ì˜ˆ) â˜ï¸ğŸŒ¤ï¸â˜€ï¸ğŸ”¥ = ê°€ì† Â· ğŸ”¥â˜€ï¸ğŸŒ¤ï¸â˜ï¸ = ë‘”í™”',
    ]
    return '\n'.join(lines)


def create_market_message(df, market_lines=None, risk_status=None, top_n=30):
    """[1/4] ì‹œì¥ í˜„í™© â€” ì§€ìˆ˜, ì‹œì¥ ìœ„í—˜ ì§€í‘œ"""
    biz_day = get_last_business_day()
    biz_str = biz_day.strftime('%Yë…„ %mì›” %dì¼')

    hy_data = risk_status['hy'] if risk_status else None
    vix_data = risk_status.get('vix') if risk_status else None

    lines = []
    lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    lines.append(' [1/4] ğŸ“Š ì‹œì¥ í˜„í™©')
    lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    lines.append(f'ğŸ“… {biz_str} (ë¯¸êµ­ì¥ ê¸°ì¤€)')
    if market_lines:
        lines.extend(market_lines)

    # ì‹œì¥ ìœ„í—˜ â€” HY + VIX + ì‹ í˜¸ë“± + ì•¡ì…˜ì„ í•˜ë‚˜ì˜ ë¸”ë¡ìœ¼ë¡œ
    if hy_data or vix_data:
        lines.append('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')
        if hy_data:
            q_days = hy_data.get('q_days', 0)
            lines.append(f"ğŸš¨ <b>ì‹œì¥ ìœ„í—˜</b> â€” {hy_data['quadrant_icon']} {hy_data['quadrant_label']} {q_days}ì¼ì§¸")
        else:
            lines.append('ğŸš¨ <b>ì‹œì¥ ìœ„í—˜</b>')
        lines.append('')

        # HY 1ì¤„ ìš”ì•½
        if hy_data:
            hy_val = hy_data['hy_spread']
            med_val = hy_data['median_10y']
            q = hy_data['quadrant']
            if q == 'Q1':
                hy_desc = 'í‰ê·  ì´ìƒì´ì§€ë§Œ í•˜ë½ ì¤‘'
            elif q == 'Q2':
                hy_desc = 'í‰ê·  ì´í•˜, ì•ˆì •'
            elif q == 'Q3':
                hy_desc = 'í‰ê·  ì´í•˜ì§€ë§Œ ìƒìŠ¹ ì¤‘'
            else:
                hy_desc = 'í‰ê·  ì´ìƒ, ê³„ì† ìƒìŠ¹'
            lines.append(f"ğŸ¦ <b>HY Spread</b>: {hy_val:.2f}% Â· {hy_desc}")

        # VIX 1ì¤„ ìš”ì•½
        if vix_data:
            v = vix_data['vix_current']
            vix_pct = vix_data.get('vix_percentile', 0)
            slope_arrow = 'â†‘' if vix_data['vix_slope_dir'] == 'rising' else ('â†“' if vix_data['vix_slope_dir'] == 'falling' else '')
            regime_label = vix_data['regime_label']
            if vix_data['regime'] == 'normal':
                lines.append(f"âš¡ <b>VIX</b>: {v:.1f} ({vix_pct:.0f}th) Â· ì•ˆì •")
            else:
                lines.append(f"âš¡ <b>VIX</b>: {v:.1f} ({vix_pct:.0f}th) {slope_arrow} Â· {regime_label}")
        lines.append('')

        # ì‹ í˜¸ë“± + ì•¡ì…˜ (ê²°ë¡ )
        signals = []
        if hy_data:
            hy_ok = hy_data['quadrant'] in ('Q1', 'Q2')
            signals.append(('HY', hy_ok))
        if vix_data:
            vix_ok = vix_data['direction'] == 'stable'
            signals.append(('VIX', vix_ok))

        if signals:
            n_ok = sum(1 for _, ok in signals if ok)
            n_total = len(signals)
            dots = ''.join('ğŸŸ¢' if ok else 'ğŸ”´' for _, ok in signals)
            if n_ok == n_total:
                conf = 'í™•ì‹¤í•œ ì‹ í˜¸'
            elif n_ok == 0:
                conf = 'ìœ„í—˜ ì‹ í˜¸'
            else:
                conf = 'ì—‡ê°ˆë¦° ì‹ í˜¸'
            lines.append(f"{dots} {n_ok}/{n_total} ì•ˆì • â€” {conf}")

        action = risk_status.get('final_action', '') if risk_status else ''
        if not action and hy_data:
            action = hy_data['action']
        if action:
            lines.append(f"â†’ {action}")
        if hy_data:
            for sig in hy_data.get('signals', []):
                lines.append(sig)

        # Q1 ë´„ + ì „ì§€í‘œ ì•ˆì • â†’ ğŸ’ ë§¤ìˆ˜ ê¸°íšŒ ê°•ì¡°
        concordance = risk_status.get('concordance', '') if risk_status else ''
        if hy_data and hy_data['quadrant'] == 'Q1' and concordance == 'both_stable':
            lines.append('')
            lines.append('ğŸ’ <b>ì—­ì‚¬ì  ë§¤ìˆ˜ ê¸°íšŒ</b>')
            lines.append('íšŒë³µê¸°ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ìˆ˜ìµë¥ ì´ ê°€ì¥ ë†’ì€ êµ¬ê°„ì´ì—ìš”.')

    lines.append('')
    lines.append('ğŸ‘‰ ë‹¤ìŒ: ë§¤ìˆ˜ í›„ë³´ [2/4]')

    return '\n'.join(lines)


def create_candidates_message(df, status_map=None, exited_tickers=None, rank_history=None, top_n=30, risk_status=None, weighted_ranks=None, rank_change_tags=None):
    """[2/4] ë§¤ìˆ˜ í›„ë³´ â€” ê°€ì¤‘ ìˆœìœ„(T0Ã—0.5+T1Ã—0.3+T2Ã—0.2) ì •ë ¬, âœ…/â³/ğŸ†• í‘œì‹œ, ì´íƒˆ ì‚¬ìœ """
    import pandas as pd
    from collections import Counter

    filtered = get_part2_candidates(df, top_n=top_n)
    count = len(filtered)

    if status_map is None:
        status_map = {}
    if exited_tickers is None:
        exited_tickers = {}
    if rank_history is None:
        rank_history = {}
    if weighted_ranks is None:
        weighted_ranks = {}
    if rank_change_tags is None:
        rank_change_tags = {}

    # ê°€ì¤‘ ìˆœìœ„ë¡œ ì •ë ¬ (ì—†ìœ¼ë©´ composite ìˆœ ìœ ì§€)
    if weighted_ranks:
        filtered = filtered.copy()
        filtered['_weighted'] = filtered['ticker'].map(
            lambda t: weighted_ranks.get(t, {}).get('weighted', 50.0)
        )
        filtered = filtered.sort_values('_weighted').reset_index(drop=True)

    lines = []
    lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    lines.append(f' [2/4] ğŸ“‹ ë§¤ìˆ˜ í›„ë³´ {count}ê°œ')
    lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')

    # ì£¼ë„ ì—…ì¢… (ì–´ë–¤ ì—…ì¢…ì´ ë§ì´ ì˜¬ë¼ì˜¤ëŠ”ì§€)
    sector_counts = Counter(row.get('industry', 'ê¸°íƒ€') for _, row in filtered.iterrows())
    top_sectors = sector_counts.most_common()
    sector_parts = [f'{name} {cnt}' for name, cnt in top_sectors if cnt >= 2]

    if sector_parts:
        lines.append(f'ğŸ“Š ì£¼ë„ ì—…ì¢…: {" Â· ".join(sector_parts)}')

    lines.append('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')

    for idx, (_, row) in enumerate(filtered.iterrows()):
        rank = idx + 1
        ticker = row['ticker']
        industry = row.get('industry', '')
        lights = row.get('trend_lights', '')
        desc = row.get('trend_desc', '')
        eps_90d = row.get('eps_change_90d')

        marker = status_map.get(ticker, 'ğŸ†•')
        rev_g = row.get('rev_growth')
        rev_up = int(row.get('rev_up30', 0) or 0)
        rev_down = int(row.get('rev_down30', 0) or 0)

        name = row.get('short_name', ticker)
        lines.append(f'{marker} <b>{rank}.</b> {name}({ticker})')
        lines.append(f'{industry} Â· {lights} {desc}')
        parts = []
        if pd.notna(eps_90d):
            parts.append(f'EPS {eps_90d:+.0f}%')
        if pd.notna(rev_g):
            parts.append(f'ë§¤ì¶œ {rev_g*100:+.0f}%')
        if parts:
            lines.append(' Â· '.join(parts))

        # ìˆœìœ„ ì´ë ¥ + ê°€ì¤‘ ìˆœìœ„ í‘œì‹œ
        w_info = weighted_ranks.get(ticker)
        if w_info:
            r0, r1, r2 = w_info['r0'], w_info['r1'], w_info['r2']
            r2_str = str(r2) if r2 < 50 else '-'
            r1_str = str(r1) if r1 < 50 else '-'
            r0_str = str(r0)
            rank_str = f'{r2_str}â†’{r1_str}â†’{r0_str}'
        else:
            hist = rank_history.get(ticker, '')
            if hist and not all(p == '-' for p in hist.split('â†’')):
                rank_str = hist
            else:
                rank_str = f'-â†’-â†’{rank}'
        tag = rank_change_tags.get(ticker, '')
        tag_suffix = f' {tag}' if tag else ''
        lines.append(f'ì˜ê²¬ â†‘{rev_up}â†“{rev_down} Â· ìˆœìœ„ {rank_str}{tag_suffix}')
        lines.append('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')

    # ì´íƒˆ ì¢…ëª©: êµ¬ë¶„ì„  + ë¶„ë¥˜
    if exited_tickers:
        all_eligible = get_part2_candidates(df)
        current_rank_map = {row['ticker']: i + 1 for i, (_, row) in enumerate(all_eligible.iterrows())}
        sorted_exits = sorted(exited_tickers.items(), key=lambda x: x[1])
        name_map = dict(zip(df['ticker'], df.get('short_name', df['ticker'])))
        full_data = {row['ticker']: row for _, row in df.iterrows()}

        # ì´íƒˆ ë¶„ë¥˜: ëª©í‘œë‹¬ì„±(ê´´ë¦¬+ë§Œ) vs í€ë”ë©˜íƒˆ ì•…í™”
        achieved = []  # âœ… ì£¼ê°€ê°€ EPS ìƒí–¥ë¶„ ë°˜ì˜
        degraded = []  # âš ï¸ í€ë”ë©˜íƒˆ ì•…í™”
        for t, prev_rank in sorted_exits:
            t_name = name_map.get(t, t)
            cur_rank = current_rank_map.get(t)
            reasons = []
            if t in full_data:
                r = full_data[t]
                if (r.get('price', 0) or 0) < (r.get('ma60', 0) or 0) and (r.get('ma60', 0) or 0) > 0:
                    reasons.append('MA60â†“')
                if (r.get('adj_gap', 0) or 0) > 0:
                    reasons.append('ê´´ë¦¬+')
                if (r.get('adj_score', 0) or 0) <= 9:
                    reasons.append('ì ìˆ˜â†“')
                if (r.get('eps_change_90d', 0) or 0) <= 0:
                    reasons.append('EPSâ†“')
            if not reasons and cur_rank and cur_rank > top_n:
                reasons.append('ìˆœìœ„â†“')
            if not reasons:
                reasons.append('ìˆœìœ„â†“')
            reason_tag = ' '.join(f'[{r}]' for r in reasons)
            rank_info = f'{prev_rank}ìœ„â†’{cur_rank}ìœ„' if cur_rank else f'{prev_rank}ìœ„â†’íƒˆë½'
            line = f'{t_name}({t}) Â· {rank_info} {reason_tag}'

            # ê´´ë¦¬+ë§Œ ìˆìœ¼ë©´ ëª©í‘œë‹¬ì„±, ë‚˜ë¨¸ì§€ëŠ” ì•…í™”
            if reasons == ['ê´´ë¦¬+']:
                achieved.append(line)
            else:
                degraded.append(line)

        lines.append('')
        lines.append('ğŸ“‰ <b>ì´íƒˆ ì¢…ëª©</b>')
        lines.append('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')
        if achieved:
            lines.append(f'âœ… <b>ëª©í‘œ ë‹¬ì„±</b> ({len(achieved)}ê°œ) â€” ìˆ˜ìµ ì‹¤í˜„ ê²€í† ')
            for a in achieved:
                lines.append(f'  {a}')
        if degraded:
            if achieved:
                lines.append('')
            lines.append(f'âš ï¸ <b>í€ë”ë©˜íƒˆ ì•…í™”</b> ({len(degraded)}ê°œ) â€” ë§¤ë„ ê²€í† ')
            for d in degraded:
                lines.append(f'  {d}')

    lines.append('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')
    lines.append('ğŸ‘‰ ë‹¤ìŒ: AI ë¦¬ìŠ¤í¬ í•„í„° [3/4]')

    return '\n'.join(lines)


def create_system_log_message(stats, elapsed, config):
    """ì‹œìŠ¤í…œ ì‹¤í–‰ ë¡œê·¸ ë©”ì‹œì§€ ìƒì„±"""
    now = datetime.now()
    if HAS_PYTZ:
        kst = pytz.timezone('Asia/Seoul')
        now = datetime.now(kst)
    time_str = now.strftime('%Y.%m.%d %H:%M')

    env = 'GitHub Actions' if config.get('is_github_actions') else 'Local'
    minutes = int(elapsed // 60)
    seconds = int(elapsed % 60)

    collected = stats.get('total_collected', 0)
    universe = stats.get('universe', 0)
    err = stats.get('error_count', 0)

    lines = [f'ğŸ”§ <b>ì‹œìŠ¤í…œ ë¡œê·¸</b>']
    lines.append(f'{time_str} KST Â· {env}')

    # ìˆ˜ì§‘ ê²°ê³¼
    if err == 0:
        lines.append(f'\nâœ… ìˆ˜ì§‘ ì„±ê³µ ({collected}/{universe})')
    else:
        lines.append(f'\nâš ï¸ ìˆ˜ì§‘ ì™„ë£Œ ({collected}/{universe}, ì‹¤íŒ¨ {err})')
        error_tickers = stats.get('error_tickers', [])
        if error_tickers:
            lines.append(f'ì‹¤íŒ¨: {", ".join(error_tickers[:10])}')

    # DB ë°ì´í„° ë²”ìœ„
    try:
        conn = sqlite3.connect(config.get('db_path', 'eps_momentum_data.db'))
        cur = conn.cursor()
        cur.execute('SELECT DISTINCT date FROM ntm_screening ORDER BY date')
        dates = [r[0] for r in cur.fetchall()]
        cur.execute('SELECT COUNT(*) FROM ntm_screening WHERE part2_rank IS NOT NULL AND date=?',
                    (dates[-1],) if dates else ('',))
        ranked = cur.fetchone()[0] if dates else 0
        conn.close()
        if dates:
            lines.append(f'\nğŸ“‚ DB: {dates[0]} ~ {dates[-1]} ({len(dates)}ì¼)')
            exited = stats.get('exited_count', 0)
            lines.append(f'ë§¤ìˆ˜ í›„ë³´: {ranked}ê°œ / ì´íƒˆ: {exited}ê°œ')
    except Exception:
        pass

    lines.append(f'\nâ±ï¸ ì†Œìš”: {minutes}ë¶„ {seconds}ì´ˆ')

    return '\n'.join(lines)


# ============================================================
# AI ë¦¬ìŠ¤í¬ ì²´í¬ (Gemini 2.5 Flash + Google Search)
# ============================================================

def run_ai_analysis(config, results_df=None, status_map=None, biz_day=None, risk_status=None, earnings_map=None):
    """[3/4] AI ë¸Œë¦¬í•‘ â€” ì •ëŸ‰ ìœ„í—˜ ì‹ í˜¸ + ì‹œì¥ í™˜ê²½ ê¸°ë°˜ ë¦¬ìŠ¤í¬ í•´ì„"""
    api_key = config.get('gemini_api_key', '')
    if not api_key:
        log("GEMINI_API_KEY ë¯¸ì„¤ì • â€” AI ë¶„ì„ ìŠ¤í‚µ", "WARN")
        return None

    try:
        from google import genai
        from google.genai import types
    except ImportError:
        log("google-genai íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜ â€” AI ë¶„ì„ ìŠ¤í‚µ", "WARN")
        return None

    try:
        client = genai.Client(api_key=api_key)

        import re
        import yfinance as yf

        if earnings_map is None:
            earnings_map = {}

        # Part 2 ì¢…ëª© ì¶”ì¶œ + ìœ„í—˜ ì‹ í˜¸ ìˆ˜ì§‘
        if results_df is None or results_df.empty:
            log("results_df ì—†ìŒ â€” AI ë¶„ì„ ìŠ¤í‚µ", "WARN")
            return None

        filtered = get_part2_candidates(results_df, top_n=30)

        if filtered.empty:
            log("Part 2 ì¢…ëª© ì—†ìŒ â€” AI ë¶„ì„ ìŠ¤í‚µ", "WARN")
            return None

        stock_count = len(filtered)
        if biz_day is None:
            biz_day = get_last_business_day()
        biz_str = biz_day.strftime('%Y-%m-%d')
        today_date = datetime.now().date()
        two_weeks_date = (datetime.now() + timedelta(days=14)).date()

        # ì¢…ëª©ë³„ ìœ„í—˜ ì‹ í˜¸ êµ¬ì„±
        log("ìœ„í—˜ ì‹ í˜¸ & ì–´ë‹ ì¼ì • ìˆ˜ì§‘ ì¤‘...")
        signal_lines = []
        earnings_tickers = []

        for _, row in filtered.iterrows():
            ticker = row['ticker']
            name = row.get('short_name', ticker)
            industry = row.get('industry', '')
            adj_score = row.get('adj_score', 0)
            eps_chg = row.get('eps_change_90d', 0) or 0
            price_chg = row.get('price_chg', 0) or 0
            fwd_pe = row.get('fwd_pe', 0) or 0
            rev_up = int(row.get('rev_up30', 0) or 0)
            rev_down = int(row.get('rev_down30', 0) or 0)
            lights = row.get('trend_lights', '')
            desc = row.get('trend_desc', '')

            # ìœ„í—˜ ì‹ í˜¸ í”Œë˜ê·¸ (í¬íŠ¸í´ë¦¬ì˜¤ í•„í„°ì™€ ë™ì¼ ê¸°ì¤€)
            num_analysts = int(row.get('num_analysts', 0) or 0)
            flags = []

            # 1. ì• ë„ë¦¬ìŠ¤íŠ¸ í•˜í–¥ ê²½ê³ : ì ˆëŒ€ 30% ì´ˆê³¼ OR í•˜í–¥â‰¥ìƒí–¥(2ê±´ ì´ìƒ)
            total_rev = rev_up + rev_down
            if total_rev > 0 and rev_down / total_rev > 0.3:
                flags.append(f"ğŸ”» ì˜ê²¬ í•˜í–¥ â†“{rev_down}/â†‘{rev_up}")
            elif rev_down >= rev_up and rev_down >= 2:
                flags.append(f"ğŸ”» í•˜í–¥ ìš°ì„¸ â†“{rev_down}/â†‘{rev_up}")

            # 2. ì €ì»¤ë²„ë¦¬ì§€ (ì• ë„ë¦¬ìŠ¤íŠ¸ 3ëª… ë¯¸ë§Œ)
            if num_analysts < 3:
                flags.append(f"ğŸ“‰ ì• ë„ë¦¬ìŠ¤íŠ¸ {num_analysts}ëª… (ì €ì»¤ë²„ë¦¬ì§€)")

            # 3. ì–´ë‹ ì„ë°• (earnings_mapì—ì„œ ì¡°íšŒ â€” .calendar ë³„ë„ í˜¸ì¶œ ë¶ˆí•„ìš”)
            ed = earnings_map.get(ticker)
            if ed and today_date <= ed <= two_weeks_date:
                flags.append(f"ğŸ“… ì–´ë‹ {ed.month}/{ed.day}")
                earnings_tickers.append(f"{name} ({ticker}) {ed.month}/{ed.day}")

            # ì¢…ëª© ë¼ì¸ êµ¬ì„±
            header = f"{name} ({ticker}) Â· {industry} Â· {lights} {desc} Â· ì ìˆ˜ {adj_score:.1f}"
            header += f"\n  EPS {eps_chg:+.1f}% / ì£¼ê°€ {price_chg:+.1f}% Â· ì• ë„ë¦¬ìŠ¤íŠ¸ ì˜ê²¬ â†‘{rev_up} â†“{rev_down} Â· Fwd PE {fwd_pe:.1f}"

            if flags:
                header += "\n  " + " | ".join(flags)

            signal_lines.append(header)

        signals_data = '\n\n'.join(signal_lines)
        earnings_info = ' Â· '.join(earnings_tickers) if earnings_tickers else 'í•´ë‹¹ ì—†ìŒ'

        log(f"ìœ„í—˜ ì‹ í˜¸ ìˆ˜ì§‘ ì™„ë£Œ: {stock_count}ì¢…ëª©, ì–´ë‹ {len(earnings_tickers)}ì¢…ëª©")

        # #3: ì‹œì¥ í™˜ê²½ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        market_env = ""
        if risk_status:
            hy = risk_status.get('hy')
            vix = risk_status.get('vix')
            conc = risk_status.get('concordance', '')
            f_action = risk_status.get('final_action', '')
            if hy:
                market_env += f"ì‹ ìš©ì‹œì¥: HY Spread {hy['hy_spread']:.2f}% Â· {hy['quadrant_label']} ({hy.get('q_days', 0)}ì¼ì§¸)\n"
            if vix:
                market_env += f"ë³€ë™ì„±: VIX {vix['vix_current']:.1f} (1ë…„ ì¤‘ {vix.get('vix_percentile', 0):.0f}th) Â· {vix['regime_label']}\n"
            market_env += f"ì¢…í•© íŒë‹¨: {conc}\n"
            if f_action:
                market_env += f"í–‰ë™ ê¶Œì¥: {f_action}\n"

        prompt = f"""ë¶„ì„ ê¸°ì¤€ì¼: {biz_str} (ë¯¸êµ­ ì˜ì—…ì¼)

[í˜„ì¬ ì‹œì¥ í™˜ê²½]
{market_env if market_env else 'ë°ì´í„° ì—†ìŒ'}

ì•„ë˜ëŠ” EPS ëª¨ë©˜í…€ ì‹œìŠ¤í…œì˜ ë§¤ìˆ˜ í›„ë³´ {stock_count}ì¢…ëª©ê³¼ ê° ì¢…ëª©ì˜ ì •ëŸ‰ì  ìœ„í—˜ ì‹ í˜¸ì•¼.
ì´ ì¢…ëª©ë“¤ì€ EPS ì „ë§ì¹˜ê°€ ìƒí–¥ ì¤‘ì´ë¼ ì„ ì •ëœ ê±°ì•¼.
ë„¤ ì—­í• : ì•„ë˜ 3ê°œ ì„¹ì…˜ì„ ìˆœì„œëŒ€ë¡œ ë°˜ë“œì‹œ ëª¨ë‘ ì¶œë ¥í•˜ëŠ” ê±°ì•¼. ì¸ì‚¬ë§ì´ë‚˜ ì„œë‘ ì—†ì´ ë°”ë¡œ ì‹œì‘í•´.

[ì¢…ëª©ë³„ ë°ì´í„° & ìœ„í—˜ ì‹ í˜¸ â€” ì‹œìŠ¤í…œì´ ê³„ì‚°í•œ íŒ©íŠ¸]
{signals_data}

[ìœ„í—˜ ì‹ í˜¸ ì„¤ëª…]
ğŸ”» ì˜ê²¬ í•˜í–¥ = 30ì¼ê°„ EPS ì „ë§ í•˜í–¥ ë¹„ìœ¨ > 30% ë˜ëŠ” í•˜í–¥ ê±´ìˆ˜ â‰¥ ìƒí–¥ ê±´ìˆ˜ (ì˜ë¯¸ ìˆëŠ” ë°˜ëŒ€ ì˜ê²¬)
ğŸ“‰ ì €ì»¤ë²„ë¦¬ì§€ = ì»¤ë²„ë¦¬ì§€ ì• ë„ë¦¬ìŠ¤íŠ¸ 3ëª… ë¯¸ë§Œ (ì¶”ì •ì¹˜ ì‹ ë¢°ë„ ë‚®ìŒ)
ğŸ“… ì–´ë‹ = 2ì£¼ ë‚´ ì‹¤ì  ë°œí‘œ ì˜ˆì • (ë°œí‘œ ì „í›„ ë³€ë™ì„± ì£¼ì˜)

[ì¶œë ¥ ê·œì¹™]
- í•œêµ­ì–´, ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ ë§íˆ¬ (~ì˜ˆìš”/~í•´ìš” ì²´)
- ë”±ë”±í•œ ë³´ê³ ì„œ ë§íˆ¬ ê¸ˆì§€. ì¹œêµ¬ì—ê²Œ ì„¤ëª…í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê²Œ.
- ì¸ì‚¬ë§, ì„œë‘, ë§ºìŒë§ ê¸ˆì§€. ì•„ë˜ 3ê°œ ì„¹ì…˜ë§Œ ì¶œë ¥.
- ì´ 1500ì ì´ë‚´.

=== ë°˜ë“œì‹œ ì¶œë ¥í•  3ê°œ ì„¹ì…˜ ===

ğŸ“° ì‹œì¥ ë™í–¥
(í•„ìˆ˜) {biz_str} ë¯¸êµ­ ì‹œì¥ ë§ˆê° ê²°ê³¼ë¥¼ Google ê²€ìƒ‰í•´ì„œ 2~3ì¤„ë¡œ ìš”ì•½í•´ì¤˜. ì´ ì„¹ì…˜ì€ ë°˜ë“œì‹œ ì¶œë ¥í•´ì•¼ í•´.
- ì–´ì œ ì‹œì¥ì˜ í•µì‹¬ ì´ìŠˆ(ì›ì¸, í…Œë§ˆ)ë§Œ 2~3ì¤„ë¡œ. ì§€ìˆ˜ ìˆ˜ì¹˜(S&P ëª‡ í¬ì¸íŠ¸, ë‚˜ìŠ¤ë‹¥ ëª‡% ë“±)ëŠ” [1/4]ì— ì´ë¯¸ ìˆìœ¼ë‹ˆ ë°˜ë³µí•˜ì§€ ë§ˆ.
- "ì´ë²ˆ ì£¼" ì „ì²´ ìš”ì•½ì€ í•˜ì§€ ë§ˆ.
- ì˜¤ëŠ˜/ë‚´ì¼ ì˜ˆì •ëœ ì£¼ìš” ì´ë²¤íŠ¸(FOMC, ê³ ìš©ì§€í‘œ, ëŒ€í˜• ì–´ë‹ ë“±)ê°€ ìˆìœ¼ë©´ í•œ ì¤„ ì¶”ê°€.
- ìœ„ [í˜„ì¬ ì‹œì¥ í™˜ê²½]ì˜ ê³„ì ˆê³¼ í–‰ë™ ê¶Œì¥ì„ ì°¸ê³ í•´ì„œ íˆ¬ì íŒë‹¨ í•œë§ˆë”” ë§ë¶™ì—¬ì¤˜.

âš ï¸ ë§¤ìˆ˜ ì£¼ì˜ ì¢…ëª©
ìœ„ ë°ì´í„°ì—ì„œ ìœ„í—˜ ì‹ í˜¸(ğŸ”»/ğŸ“‰/ğŸ“…)ê°€ ìˆëŠ” ì¢…ëª©ë§Œ ê³¨ë¼ì„œ ì„¤ëª…í•´ì¤˜.
í˜•ì‹: ì¢…ëª©ëª…(í‹°ì»¤)ë¥¼ êµµê²Œ(**) ì“°ê³ , 1~2ì¤„ë¡œ ì™œ ì£¼ì˜í•´ì•¼ í•˜ëŠ”ì§€ ì„¤ëª….
ì¢…ëª©ê³¼ ì¢…ëª© ì‚¬ì´ì— ë°˜ë“œì‹œ [SEP] í•œ ì¤„ì„ ë„£ì–´ì„œ êµ¬ë¶„í•´ì¤˜.
ìœ„í—˜ ì‹ í˜¸ê°€ ì—†ëŠ” ì¢…ëª©ì€ ì ˆëŒ€ ë„£ì§€ ë§ˆ. ì‹œìŠ¤í…œ ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì„ ì§€ì–´ë‚´ì§€ ë§ˆ.
ë§Œì•½ ìœ„í—˜ ì‹ í˜¸ê°€ ìˆëŠ” ì¢…ëª©ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ "âœ… ëª¨ë“  í›„ë³´ê°€ í˜„ì¬ ì–‘í˜¸í•´ìš”." í•œ ì¤„ë§Œ ì¶œë ¥í•´.

ì˜ˆì‹œ:
**ABC Corp(ABC)**
ìµœê·¼ 5ëª…ì˜ ì• ë„ë¦¬ìŠ¤íŠ¸ê°€ EPS ì „ë§ì¹˜ë¥¼ ë‚®ì·„ì–´ìš”. ì˜ê²¬ í•˜í–¥ì´ ë§ìœ¼ë‹ˆ ì¡°ì‹¬í•˜ì„¸ìš”.
[SEP]
**XYZ Inc(XYZ)**
ì»¤ë²„ë¦¬ì§€ ì• ë„ë¦¬ìŠ¤íŠ¸ê°€ 2ëª…ë¿ì´ë¼ ì¶”ì •ì¹˜ë¥¼ 100% ë¯¿ê¸° ì–´ë ¤ì›Œìš”.

ğŸ“… ì–´ë‹ ì£¼ì˜
{earnings_info}
(ìœ„ ë‚´ìš© ê·¸ëŒ€ë¡œ í‘œì‹œ. ìˆ˜ì •/ì¶”ê°€ ê¸ˆì§€. "í•´ë‹¹ ì—†ìŒ"ì´ë©´ ì´ ì„¹ì…˜ ìƒëµ.)"""

        grounding_tool = types.Tool(google_search=types.GoogleSearch())
        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt,
            config=types.GenerateContentConfig(
                tools=[grounding_tool],
                temperature=0.2,
            ),
        )

        def extract_text(resp):
            """response.textê°€ Noneì¼ ë•Œ partsì—ì„œ ì§ì ‘ ì¶”ì¶œ"""
            try:
                if resp.text:
                    return resp.text
            except Exception:
                pass
            try:
                parts = resp.candidates[0].content.parts
                texts = [p.text for p in parts if hasattr(p, 'text') and p.text]
                if texts:
                    return '\n'.join(texts)
            except Exception:
                pass
            return None

        analysis_text = extract_text(response)

        # ì‘ë‹µ ìœ íš¨ì„± ê²€ì¦: ë¹„ì–´ìˆê±°ë‚˜ í•„ìˆ˜ ì„¹ì…˜(ğŸ“°/âš ï¸) ëˆ„ë½ì´ë©´ ì¬ì‹œë„
        def is_valid_response(text):
            if not text or len(text) < 50:
                return False
            return 'ğŸ“°' in text or 'ì‹œì¥' in text

        if not is_valid_response(analysis_text):
            try:
                if hasattr(response, 'candidates') and response.candidates:
                    candidate = response.candidates[0]
                    log(f"Gemini finish_reason: {candidate.finish_reason}", "WARN")
            except Exception:
                pass
            reason = "ë¹„ì–´ìˆìŒ" if not analysis_text else f"ì„¹ì…˜ ëˆ„ë½ ({len(analysis_text)}ì)"
            log(f"Gemini ì‘ë‹µ ë¶€ì í•© ({reason}) â€” ì¬ì‹œë„", "WARN")
            response = client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt,
                config=types.GenerateContentConfig(
                    tools=[grounding_tool],
                    temperature=0.3,
                ),
            )
            analysis_text = extract_text(response)
            if not is_valid_response(analysis_text):
                log("Gemini ì¬ì‹œë„ë„ ë¶€ì í•©", "WARN")
                if not analysis_text:
                    return None

        # Markdown â†’ Telegram HTML ë³€í™˜
        analysis_html = analysis_text
        analysis_html = analysis_html.replace('&', '&amp;')
        analysis_html = analysis_html.replace('<', '&lt;')
        analysis_html = analysis_html.replace('>', '&gt;')
        analysis_html = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', analysis_html)
        analysis_html = re.sub(r'(?<!\w)\*(?!\s)(.+?)(?<!\s)\*(?!\w)', r'<i>\1</i>', analysis_html)
        analysis_html = re.sub(r'#{1,3}\s*', '', analysis_html)
        analysis_html = analysis_html.replace('---', 'â”â”â”')
        analysis_html = re.sub(r'\n*\[SEP\]\n*', '\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€\n', analysis_html)

        # DB ì €ì¥ (ëŒ€ì‹œë³´ë“œìš©)
        if biz_day and analysis_text:
            try:
                conn = sqlite3.connect(DB_PATH)
                conn.execute(
                    'INSERT OR REPLACE INTO ai_analysis (date, analysis_type, ticker, content) VALUES (?,?,?,?)',
                    (biz_day.strftime('%Y-%m-%d'), 'ai_review', '__ALL__', analysis_text)
                )
                conn.commit()
                conn.close()
                log("AI ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì™„ë£Œ")
            except Exception as e:
                log(f"AI ë¶„ì„ DB ì €ì¥ ì‹¤íŒ¨: {e}", "WARN")

        # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í¬ë§·íŒ…
        lines = []
        lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
        lines.append('  [3/4] ğŸ¤– AI ë¦¬ìŠ¤í¬ í•„í„°')
        lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
        lines.append(f'ğŸ“… {biz_day.strftime("%Yë…„ %mì›” %dì¼")} (ë¯¸êµ­ì¥ ê¸°ì¤€)')
        lines.append('')
        lines.append('ë§¤ìˆ˜ í›„ë³´ì˜ ìœ„í—˜ ìš”ì†Œë¥¼ AIê°€ ê±¸ëŸ¬ëƒˆì–´ìš”.')
        lines.append('')
        lines.append(analysis_html)
        lines.append('')
        lines.append('ğŸ‘‰ ë‹¤ìŒ: ìµœì¢… ì¶”ì²œ í¬íŠ¸í´ë¦¬ì˜¤ [4/4]')

        log("AI ë¦¬ìŠ¤í¬ í•„í„° ì™„ë£Œ")
        return '\n'.join(lines)

    except Exception as e:
        log(f"AI ë¶„ì„ ì‹¤íŒ¨: {e}", "ERROR")
        return None


def run_portfolio_recommendation(config, results_df, status_map=None, biz_day=None, risk_status=None, weighted_ranks=None, earnings_map=None):
    """í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œ â€” 3ì¼ ê²€ì¦(âœ…) + ë¦¬ìŠ¤í¬ í•„í„° í†µê³¼ ì¢…ëª© + ê°€ì¤‘ ìˆœìœ„ ì •ë ¬"""
    try:
        import re
        import yfinance as yf

        if earnings_map is None:
            earnings_map = {}

        if results_df is None or results_df.empty:
            return None

        # ê³µí†µ í•„í„° ì‚¬ìš©
        filtered = get_part2_candidates(results_df, top_n=30)

        if filtered.empty:
            return None

        if status_map is None:
            status_map = {}
        if weighted_ranks is None:
            weighted_ranks = {}

        # âœ… (3ì¼ ê²€ì¦) ì¢…ëª©ë§Œ ëŒ€ìƒ â€” ğŸ†•ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ ì œì™¸
        verified_tickers = {t for t, s in status_map.items() if s == 'âœ…'}
        if status_map:
            filtered = filtered[filtered['ticker'].isin(verified_tickers)]

        # ê°€ì¤‘ ìˆœìœ„ë¡œ ì •ë ¬ (âœ… ì¢…ëª© ì¤‘ ê°€ì¤‘ ìˆœìœ„ ë†’ì€ ìˆœ)
        if weighted_ranks:
            filtered = filtered.copy()
            filtered['_weighted'] = filtered['ticker'].map(
                lambda t: weighted_ranks.get(t, {}).get('weighted', 50.0)
            )
            filtered = filtered.sort_values('_weighted').reset_index(drop=True)

        if biz_day is None:
            biz_day = get_last_business_day()

        if filtered.empty:
            log("í¬íŠ¸í´ë¦¬ì˜¤: âœ… ê²€ì¦ ì¢…ëª© ì—†ìŒ", "WARN")
            return '\n'.join([
                'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”',
                '   [4/4] ğŸ¯ ìµœì¢… ì¶”ì²œ',
                'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”',
                f'ğŸ“… {biz_day.strftime("%Yë…„ %mì›” %dì¼")} (ë¯¸êµ­ì¥ ê¸°ì¤€)',
                '',
                'ê²€ì¦ëœ ì¢…ëª© ì¤‘ ì•ˆì „í•œ ì¢…ëª©ì´ ì—†ì–´ìš”.',
                'ì´ë²ˆ íšŒì°¨ëŠ” <b>ê´€ë§</b>ì„ ê¶Œì¥í•©ë‹ˆë‹¤.',
                '',
                'ë¬´ë¦¬í•œ ì§„ì…ë³´ë‹¤ ê¸°ë‹¤ë¦¼ì´ ë‚˜ì„ ë•Œë„ ìˆì–´ìš”.',
            ])

        today_date = datetime.now().date()
        two_weeks = (datetime.now() + timedelta(days=14)).date()

        # ë¦¬ìŠ¤í¬ í”Œë˜ê·¸ â†’ ì•ˆì „ ì¢…ëª©ë§Œ ì„ ë³„
        log("í¬íŠ¸í´ë¦¬ì˜¤: âœ… ì¢…ëª© ë¦¬ìŠ¤í¬ í•„í„° ì ìš© ì¤‘...")
        safe = []
        for _, row in filtered.iterrows():
            t = row['ticker']
            eps_chg = row.get('eps_change_90d', 0) or 0
            price_chg = row.get('price_chg', 0) or 0
            fwd_pe = row.get('fwd_pe', 0) or 0
            rev_up = int(row.get('rev_up30', 0) or 0)
            rev_down = int(row.get('rev_down30', 0) or 0)
            num_analysts = int(row.get('num_analysts', 0) or 0)

            flags = []
            total_rev = rev_up + rev_down
            if total_rev > 0 and rev_down / total_rev > 0.3:
                flags.append("í•˜í–¥ê³¼ë°˜")
            elif rev_down >= rev_up and rev_down >= 2:
                flags.append("í•˜í–¥ìš°ì„¸")
            if num_analysts < 3:
                flags.append("ì €ì»¤ë²„ë¦¬ì§€")
            # ì–´ë‹ ì„ë°•: í‘œì‹œë§Œ (í¬íŠ¸í´ë¦¬ì˜¤ ì œì™¸ ì•ˆ í•¨, earnings_map í™œìš©)
            earnings_note = ""
            ed = earnings_map.get(t)
            if ed and today_date <= ed <= two_weeks:
                earnings_note = f" ğŸ“…ì–´ë‹ {ed.month}/{ed.day}"

            if flags:
                log(f"  âŒ {t}: {','.join(flags)} (gap={row.get('adj_gap',0):+.1f} desc={row.get('trend_desc','')})")
            else:
                v_status = status_map.get(t, 'âœ…') if status_map else 'âœ…'
                safe.append({
                    'ticker': t,
                    'name': row.get('short_name', t),
                    'industry': row.get('industry', ''),
                    'eps_chg': eps_chg, 'price_chg': price_chg,
                    'fwd_pe': fwd_pe,
                    'adj_gap': row.get('adj_gap', 0) or 0,
                    'rev_up': rev_up, 'rev_down': rev_down,
                    'adj_score': row.get('adj_score', 0) or 0,
                    'lights': row.get('trend_lights', ''),
                    'desc': row.get('trend_desc', ''),
                    'v_status': v_status,
                    'price': row.get('price', 0) or 0,
                    'rev_growth': row.get('rev_growth', 0) or 0,
                    'earnings_note': earnings_note,
                })
                log(f"  {v_status} {t}: gap={row.get('adj_gap',0):+.1f} desc={row.get('trend_desc','')} up={rev_up} dn={rev_down}{earnings_note}")

        if not safe:
            log("í¬íŠ¸í´ë¦¬ì˜¤: âœ… ì¢…ëª© ì—†ìŒ", "WARN")
            return None

        concordance = risk_status.get('concordance', 'both_stable') if risk_status else 'both_stable'
        final_action = risk_status.get('final_action', '') if risk_status else ''

        # ì¢…ëª© ì„ ì • = ì•ŒíŒŒ (í•­ìƒ Top 5) â€” ê°€ì¤‘ ìˆœìœ„ìˆœ
        if weighted_ranks:
            for s in safe:
                s['_weighted'] = weighted_ranks.get(s['ticker'], {}).get('weighted', 50.0)
            safe.sort(key=lambda x: x['_weighted'])

        log("í¬íŠ¸í´ë¦¬ì˜¤: ê°€ì¤‘ ìˆœìœ„ (T0Ã—0.5 + T1Ã—0.3 + T2Ã—0.2):")
        for i, s in enumerate(safe):
            w = s.get('_weighted', '-')
            log(f"    {i+1}. {s['ticker']}: ê°€ì¤‘={w} gap={s['adj_gap']:+.1f} adj={s['adj_score']:.1f} {s['desc']} [{s['industry']}]")

        # L3: both_warn ì‹œ ì‹ ê·œ ì§„ì… ì¢…ëª© í¬íŠ¸í´ë¦¬ì˜¤ ì œì™¸
        if concordance == 'both_warn':
            before = len(safe)
            safe = [s for s in safe if s['v_status'] == 'âœ…']
            excluded = before - len(safe)
            if excluded > 0:
                log(f"L3 ì‹œì¥ ë™ê²°: both_warn â€” ì‹ ê·œ ì§„ì… {excluded}ê°œ ì œì™¸ (ê¸°ì¡´ âœ…ë§Œ ìœ ì§€)")

        selected = safe[:5]

        if len(selected) < 3:
            log("í¬íŠ¸í´ë¦¬ì˜¤: ì„ ì • ì¢…ëª© ë¶€ì¡±", "WARN")
            return None

        # ì°¨ë“± ë¹„ì¤‘: composite ìƒìœ„ì— ë” ë§ì´ ë°°ë¶„
        weight_table = {
            5: [25, 25, 20, 15, 15],
            4: [30, 25, 25, 20],
            3: [35, 35, 30],
        }
        n = len(selected)
        weights = weight_table.get(n, [100 // n] * n)
        for i, s in enumerate(selected):
            s['weight'] = weights[i]

        log(f"í¬íŠ¸í´ë¦¬ì˜¤: {n}ì¢…ëª© ì„ ì • â€” " +
            ", ".join(f"{s['ticker']}({s['weight']}%)" for s in selected))

        # Forward Test: í¬íŠ¸í´ë¦¬ì˜¤ ì´ë ¥ ê¸°ë¡
        try:
            log_portfolio_trades(selected, biz_day.strftime('%Y-%m-%d'))
        except Exception as e:
            log(f"Forward Test ê¸°ë¡ ì‹¤íŒ¨: {e}", "WARN")

        # ì‹œì¥ ìœ„í—˜ ì»¨í…ìŠ¤íŠ¸ (Gemini í”„ë¡¬í”„íŠ¸ìš©)
        market_ctx = ""
        if risk_status:
            hy = risk_status.get('hy')
            if hy:
                market_ctx += f"HY Spread: {hy['hy_spread']:.2f}% ({hy['quadrant_label']}, {hy.get('q_days', 0)}ì¼ì§¸)\n"
            vix = risk_status.get('vix')
            if vix:
                market_ctx += f"VIX: {vix['vix_current']:.1f} (1ë…„ ì¤‘ {vix.get('vix_percentile', 0):.0f}th, {vix['regime_label']})\n"
            market_ctx += f"ì‹œì¥ íŒë‹¨: {concordance}\n"
            if final_action:
                market_ctx += f"í–‰ë™ ê¶Œì¥: {final_action}\n"

        # Gemini í”„ë¡¬í”„íŠ¸
        stock_lines = []
        for i, s in enumerate(selected):
            stock_lines.append(
                f"{i+1}. {s['name']}({s['ticker']}) Â· {s['industry']}\n"
                f"   {s['lights']} {s['desc']} Â· ë¹„ì¤‘ {s['weight']}%\n"
                f"   EPS {s['eps_chg']:+.1f}% Â· ë§¤ì¶œ {s.get('rev_growth', 0) or 0:+.0%}\n"
                f"   ì˜ê²¬ â†‘{s['rev_up']} â†“{s['rev_down']}"
            )

        prompt = f"""ì•„ë˜ {len(selected)}ì¢…ëª© ê°ê°ì˜ ìµœê·¼ ì‹¤ì  ì„±ì¥ ë°°ê²½ì„ Google ê²€ìƒ‰í•´ì„œ í•œ ì¤„ì”© ì¨ì¤˜.

[ì¢…ëª©]
{chr(10).join(stock_lines)}

[í˜•ì‹]
- í•œêµ­ì–´, ~ì˜ˆìš” ì²´
- ì¢…ëª©ë³„: **N. ì¢…ëª©ëª…(í‹°ì»¤) Â· ë¹„ì¤‘ N%**
  ë‚ ì”¨ì•„ì´ì½˜ + ë¹„ì¦ˆë‹ˆìŠ¤ ë§¤ë ¥ í•œ ì¤„
- ì¢…ëª© ì‚¬ì´ì— [SEP]
- ë§¨ ë ë³„ë„ ë¬¸êµ¬ ì—†ìŒ

[ê·œì¹™]
- ê° ì¢…ëª©ì˜ ì‹¤ì  ì„±ì¥ ë°°ê²½(ì™œ EPS/ë§¤ì¶œì´ ì˜¤ë¥´ëŠ”ì§€)ì„ ê²€ìƒ‰í•´ì„œ ì¨.
  ì˜ˆ: "AI ë°ì´í„°ì„¼í„° ìˆ˜ìš” í™•ëŒ€ë¡œ GPU ë§¤ì¶œ ê¸‰ì¦ ì¤‘ì´ì—ìš”"
  ì˜ˆ: "ì „ë ¥ ìˆ˜ìš” í­ì¦ì— ì›ì „ ì¬ê°€ë™ ê¸°ëŒ€ê°ê¹Œì§€ ë”í•´ì¡Œì–´ìš”"
- ë‹¨ìˆœíˆ "EPS X% ìƒìŠ¹"ì²˜ëŸ¼ ìˆ«ìë§Œ ë°˜ë³µí•˜ì§€ ë§ˆ. ê·¸ ìˆ«ì ë’¤ì˜ ì‚¬ì—…ì  ì´ìœ ë¥¼ ì¨.
- ì£¼ì˜/ê²½ê³ /ìœ ì˜ í‘œí˜„ ê¸ˆì§€. ê¸ì •ì  ë§¤ë ¥ë§Œ.
- "ì„ ì •", "í¬í•¨", "ì„ íƒ" ê°™ì€ ì‹œìŠ¤í…œ ìš©ì–´ ê¸ˆì§€.
- ì„œë‘/ì¸ì‚¬ë§/ë„ì…ë¬¸ ê¸ˆì§€. "ë‹¤ìŒì€", "ìš”ì²­í•˜ì‹ ", "ì†Œê°œí•´" ë“± ì ˆëŒ€ ì“°ì§€ ë§ˆ. ì²« ë²ˆì§¸ ì¢…ëª©ë¶€í„° ë°”ë¡œ ì‹œì‘.
- ì¢…ëª©ë§ˆë‹¤ ë‹¤ë¥¸ ë¬¸ì¥ êµ¬ì¡°ë¡œ ì¨."""

        def generate_template_descriptions(stocks):
            """Approach B: ì½”ë“œ í…œí”Œë¦¿ â€” AI ì—†ì´ ê¸°ì¡´ ë°ì´í„°ë¡œ ìƒì„±"""
            parts = []
            for i, s in enumerate(stocks):
                eps = s['eps_chg']
                rev = s.get('rev_growth', 0) or 0
                rev_up = s['rev_up']
                rev_down = s['rev_down']
                detail_parts = []
                if eps >= 100:
                    detail_parts.append(f'EPS {eps:+.0f}% í­ë“±')
                elif eps >= 30:
                    detail_parts.append(f'EPS {eps:+.0f}% ê¸‰ë“±')
                elif eps >= 10:
                    detail_parts.append(f'EPS {eps:+.0f}% ìƒìŠ¹')
                else:
                    detail_parts.append(f'EPS {eps:+.1f}%')
                if rev >= 0.5:
                    detail_parts.append(f'ë§¤ì¶œ {rev:+.0%} ê³ ì„±ì¥')
                elif rev >= 0.1:
                    detail_parts.append(f'ë§¤ì¶œ {rev:+.0%}')
                if rev_down == 0 and rev_up >= 3:
                    detail_parts.append(f'ì „ì› ìƒí–¥({rev_up}ëª…)')
                elif rev_up > rev_down * 2 and rev_up >= 3:
                    detail_parts.append(f'ìƒí–¥ ìš°ì„¸(â†‘{rev_up}â†“{rev_down})')
                detail = ' Â· '.join(detail_parts)
                parts.append(
                    f"<b>{i+1}. {s['name']}({s['ticker']}) Â· ë¹„ì¤‘ {s['weight']}%</b>\n"
                    f"{s['lights']} {s['desc']} Â· {detail}"
                )
            return '\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n'.join(parts)

        api_key = config.get('gemini_api_key', '')
        html = None

        if api_key:
            try:
                from google import genai
                from google.genai import types

                client = genai.Client(api_key=api_key)
                grounding_tool = types.Tool(google_search=types.GoogleSearch())
                response = client.models.generate_content(
                    model='gemini-2.5-flash',
                    contents=prompt,
                    config=types.GenerateContentConfig(
                        tools=[grounding_tool],
                        temperature=0.3,
                    ),
                )

                def extract_text(resp):
                    try:
                        if resp.text:
                            return resp.text
                    except Exception:
                        pass
                    try:
                        parts = resp.candidates[0].content.parts
                        texts = [p.text for p in parts if hasattr(p, 'text') and p.text]
                        if texts:
                            return '\n'.join(texts)
                    except Exception:
                        pass
                    return None

                text = extract_text(response)
                if text:
                    # Gemini ì„œë‘ ì œê±°: ì²« ë²ˆì§¸ ì¢…ëª©(**1.) ì „ í…ìŠ¤íŠ¸ ì‚­ì œ
                    first_stock = re.search(r'\*\*1\.', text)
                    if first_stock and first_stock.start() > 0:
                        removed = text[:first_stock.start()].strip()
                        if removed:
                            log(f"í¬íŠ¸í´ë¦¬ì˜¤: Gemini ì„œë‘ ì œê±° â€” '{removed[:50]}'")
                        text = text[first_stock.start():]
                    html = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                    html = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', html)
                    html = re.sub(r'(?<!\w)\*(?!\s)(.+?)(?<!\s)\*(?!\w)', r'<i>\1</i>', html)
                    html = re.sub(r'#{1,3}\s*', '', html)
                    html = re.sub(r'\n*\[SEP\]\n*', '\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n', html)
                    log("í¬íŠ¸í´ë¦¬ì˜¤: Gemini Search Grounding ì‘ë‹µ ì‚¬ìš©")
                else:
                    log("í¬íŠ¸í´ë¦¬ì˜¤: Gemini ì‘ë‹µ ì—†ìŒ â€” í…œí”Œë¦¿ fallback", "WARN")
            except Exception as e:
                log(f"í¬íŠ¸í´ë¦¬ì˜¤: Gemini í˜¸ì¶œ ì‹¤íŒ¨ ({e}) â€” í…œí”Œë¦¿ fallback", "WARN")
        else:
            log("GEMINI_API_KEY ë¯¸ì„¤ì • â€” í…œí”Œë¦¿ ëª¨ë“œ")

        if not html:
            html = generate_template_descriptions(selected)
            log("í¬íŠ¸í´ë¦¬ì˜¤: ì½”ë“œ í…œí”Œë¦¿ fallback")

        # DB ì €ì¥ (ëŒ€ì‹œë³´ë“œìš©) â€” í¬íŠ¸í´ë¦¬ì˜¤ AI ì„¤ëª…
        if biz_day and html:
            try:
                conn = sqlite3.connect(DB_PATH)
                conn.execute(
                    'INSERT OR REPLACE INTO ai_analysis (date, analysis_type, ticker, content) VALUES (?,?,?,?)',
                    (biz_day.strftime('%Y-%m-%d'), 'portfolio_narrative', '__ALL__', html)
                )
                conn.commit()
                conn.close()
                log("í¬íŠ¸í´ë¦¬ì˜¤ AI ì„¤ëª… DB ì €ì¥ ì™„ë£Œ")
            except Exception as e:
                log(f"í¬íŠ¸í´ë¦¬ì˜¤ AI ì„¤ëª… DB ì €ì¥ ì‹¤íŒ¨: {e}", "WARN")

        lines = [
            'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”',
            '   [4/4] ğŸ¯ ìµœì¢… ì¶”ì²œ',
            'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”',
            f'ğŸ“… {biz_day.strftime("%Yë…„ %mì›” %dì¼")} (ë¯¸êµ­ì¥ ê¸°ì¤€)',
            '',
            f'916ì¢…ëª© â†’ Top 30 â†’ âœ… 3ì¼ ê²€ì¦ â†’ <b>ìµœì¢… {len(selected)}ì¢…ëª©</b>',
        ]

        # #6: Q1 ë´„ + ì „ì§€í‘œ ì•ˆì • â†’ ğŸ’ ê¸°íšŒ ê°•ì¡°
        hy_q = (risk_status.get('hy') or {}).get('quadrant', '') if risk_status else ''
        if hy_q == 'Q1' and concordance == 'both_stable':
            lines.append('')
            lines.append('ğŸ’ <b>ì—­ì‚¬ì  ë§¤ìˆ˜ ê¸°íšŒ!</b> ëª¨ë“  ì§€í‘œê°€ ë§¤ìˆ˜ë¥¼ ê°€ë¦¬ì¼œìš”.')

        lines.extend([
            '',
            'â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€',
            html,
        ])

        # ì£¼ì˜ì‚¬í•­ â€” ì‹¤ì§ˆì  ê²½ê³ ë§Œ í‘œì‹œ
        warnings = []

        # ì–´ë‹ ì„ë°• ì¢…ëª©
        earnings_stocks = [s for s in selected if s.get('earnings_note')]
        for s in earnings_stocks:
            ed = s["earnings_note"].replace("ğŸ“…ì–´ë‹", "").replace("ğŸ“…", "").strip()
            warnings.append(f'{s["name"]}({s["ticker"]}) {ed} ì–´ë‹ ë³€ë™ì„± ì£¼ì˜')

        # ì„¹í„° ì§‘ì¤‘ ê²½ê³ 
        from collections import Counter
        industries = [s['industry'] for s in selected if s.get('industry')]
        tech_keywords = ['ë°˜ë„ì²´', 'ì „ìë¶€í’ˆ', 'HW', 'í†µì‹ ì¥ë¹„', 'ê³„ì¸¡']
        tech_count = sum(1 for ind in industries if any(kw in ind for kw in tech_keywords))
        sector_counts = Counter(industries)
        concentrated = [f'{name} {cnt}' for name, cnt in sector_counts.most_common() if cnt >= 3]
        if tech_count >= 3:
            warnings.append(f'í…Œí¬/ë°˜ë„ì²´ {tech_count}/{len(selected)}ì¢…ëª© ì§‘ì¤‘ â€” ë™ë°˜ í•˜ë½ ë¦¬ìŠ¤í¬')
        elif concentrated:
            warnings.append(f'ì—…ì¢… ì§‘ì¤‘: {", ".join(concentrated)} â€” ë¶„ì‚° ì ê²€')

        if warnings:
            lines.append('')
            lines.append('âš ï¸ <b>ì£¼ì˜</b>')
            for w in warnings:
                lines.append(f'  {w}')

        lines.extend([
            '',
            'ëª©ë¡ì— ìˆìœ¼ë©´ ë³´ìœ , ë¹ ì§€ë©´ ë§¤ë„ ê²€í† ',
            'ìµœì†Œ 2ì£¼ ë³´ìœ  Â· ë§¤ì¼ í›„ë³´ ê°±ì‹  í™•ì¸',
            '<i>ì°¸ê³ ìš©ì´ë©°, íˆ¬ì íŒë‹¨ì€ ë³¸ì¸ ì±…ì„ì´ì—ìš”.</i>',
        ])

        log("í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œ ì™„ë£Œ")
        return '\n'.join(lines)

    except Exception as e:
        log(f"í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œ ì‹¤íŒ¨: {e}", "ERROR")
        return None


# ============================================================
# í…”ë ˆê·¸ë¨ ì „ì†¡
# ============================================================

def send_telegram_long(message, config, chat_id=None):
    """ê¸´ ë©”ì‹œì§€ë¥¼ ì—¬ëŸ¬ ê°œë¡œ ë¶„í• í•´ì„œ ì „ì†¡ (chat_id ì§€ì • ê°€ëŠ¥)"""
    if not config.get('telegram_enabled', False):
        return False

    bot_token = config.get('telegram_bot_token', '')
    if chat_id is None:
        chat_id = config.get('telegram_chat_id', '')

    if not bot_token or not chat_id:
        log("í…”ë ˆê·¸ë¨ ì„¤ì • ë¶ˆì™„ì „", "WARN")
        return False

    try:
        import urllib.request
        import urllib.parse

        # 4000ìì”© ë¶„í• 
        chunks = []
        remaining = message.strip()
        while remaining:
            if len(remaining) <= 4000:
                chunks.append(remaining)
                break
            else:
                split_point = remaining[:4000].rfind('\n')
                if split_point <= 0:
                    split_point = 4000
                chunks.append(remaining[:split_point])
                remaining = remaining[split_point:].strip()

        # ë¹ˆ ì²­í¬ ì œê±°
        chunks = [c for c in chunks if c.strip()]

        for i, chunk in enumerate(chunks):
            url = f"https://api.telegram.org/bot{bot_token}/sendMessage"

            data = urllib.parse.urlencode({
                'chat_id': chat_id,
                'text': chunk,
                'parse_mode': 'HTML'
            }).encode()

            req = urllib.request.Request(url, data=data)
            urllib.request.urlopen(req, timeout=10)

        log(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì™„ë£Œ ({len(chunks)}ê°œ ë©”ì‹œì§€)")
        return True

    except Exception as e:
        log(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}", "ERROR")
        return False


# ============================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================

def main():
    """NTM EPS ì‹œìŠ¤í…œ v31 ë©”ì¸ ì‹¤í–‰ â€” Balanced Review"""
    log("=" * 60)
    log("EPS Momentum Daily Runner v31 - Balanced Review")
    log("=" * 60)

    start_time = datetime.now()

    # ì„¤ì • ë¡œë“œ
    config = load_config()
    log(f"ì„¤ì • ë¡œë“œ ì™„ë£Œ: {CONFIG_PATH}")

    # 1. NTM ë°ì´í„° ìˆ˜ì§‘ + DB ì ì¬ (MA60, price í¬í•¨)
    log("=" * 60)
    log("NTM EPS ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    log("=" * 60)
    results_df, turnaround_df, stats, today_str = run_ntm_collection(config)

    # 2. Part 2 rank ì €ì¥ + 3ì¼ êµì§‘í•© + ì–´ì œ ëŒ€ë¹„ ë³€ë™
    import pandas as pd

    status_map = {}
    rank_history = {}
    weighted_ranks = {}
    rank_change_tags = {}
    exited_tickers = []

    # 2.5. ì‹œì¥ ì§€ìˆ˜ ìˆ˜ì§‘ (yfinance rate limit ì „ì— ë¨¼ì €)
    market_lines = get_market_context()
    if market_lines:
        log(f"ì‹œì¥ ì§€ìˆ˜: {len(market_lines)}ê°œ")

    if not results_df.empty:
        # ë§¤ì¶œ+í’ˆì§ˆ ìˆ˜ì§‘ â†’ rev_growth composite score + 12ê°œ ì¬ë¬´ì§€í‘œ DB ì €ì¥ (v33)
        results_df, earnings_map = fetch_revenue_growth(results_df, today_str)

        # ê°€ì¤‘ìˆœìœ„ ê¸°ë°˜ Top 30 ì„ ì • + DB ì €ì¥
        today_tickers = save_part2_ranks(results_df, today_str) or []

        status_map = get_3day_status(today_tickers)
        rank_history = get_rank_history(today_tickers)
        weighted_ranks = compute_weighted_ranks(today_tickers)
        rank_change_tags = get_rank_change_tags(today_tickers, weighted_ranks)
        _, exited_tickers = get_daily_changes(today_tickers)

    stats['exited_count'] = len(exited_tickers) if exited_tickers else 0

    # HY Spread + VIX ìˆ˜ì§‘ (FRED â€” yfinanceì™€ ë³„ê°œ)
    risk_status = get_market_risk_status()
    hy_data = risk_status['hy']
    vix_data = risk_status['vix']
    if hy_data:
        log(f"HY Spread: {hy_data['hy_spread']:.2f}% | ë¶„ë©´: {hy_data['quadrant']} {hy_data['quadrant_label']} ({hy_data['q_days']}ì¼ì§¸)")
        log(f"  {hy_data['action']}")
        if hy_data['signals']:
            for sig in hy_data['signals']:
                log(f"  í•´ë¹™ ì‹ í˜¸: {sig}")
    if vix_data:
        log(f"VIX: {vix_data['vix_current']:.1f} (252ì¼ {vix_data.get('vix_percentile', 0):.0f}th) | slope {vix_data['vix_slope']:+.1f} ({vix_data['vix_slope_dir']}) | {vix_data['regime_label']}")
    log(f"ì¼ì¹˜ë„: {risk_status['concordance']} | {risk_status['final_action']}")

    # 3. ë©”ì‹œì§€ ìƒì„±
    msg_market = create_market_message(results_df, market_lines, risk_status=risk_status) if not results_df.empty else None
    msg_candidates = create_candidates_message(results_df, status_map, exited_tickers, rank_history, risk_status=risk_status, weighted_ranks=weighted_ranks, rank_change_tags=rank_change_tags) if not results_df.empty else None

    # ì‹¤í–‰ ì‹œê°„
    elapsed = (datetime.now() - start_time).total_seconds()
    msg_log = create_system_log_message(stats, elapsed, config)

    # 4. í…”ë ˆê·¸ë¨ ë°œì†¡: ğŸ“– ê°€ì´ë“œ â†’ [1/4] ì‹œì¥ â†’ [2/4] ë§¤ìˆ˜ í›„ë³´ â†’ [3/4] AI â†’ [4/4] ìµœì¢… â†’ ë¡œê·¸
    if config.get('telegram_enabled', False):
        is_github = config.get('is_github_actions', False)
        private_id = config.get('telegram_private_id') or config.get('telegram_chat_id')
        channel_id = config.get('telegram_channel_id')

        # cold start: 3ì¼ ë¯¸ë§Œ ë°ì´í„° â†’ ì±„ë„ ì „ì†¡ ì•ˆí•¨ (ê°œì¸ë´‡ë§Œ)
        cold_start = is_cold_start()
        send_to_channel = is_github and channel_id and not cold_start
        if cold_start:
            log(f"Cold start â€” ì±„ë„ ì „ì†¡ ë¹„í™œì„±í™” (3ì¼ ë°ì´í„° ì¶•ì  ì „)")

        dest = 'ì±„ë„+ê°œì¸ë´‡' if send_to_channel else 'ê°œì¸ë´‡'

        # ğŸ“– íˆ¬ì ê°€ì´ë“œ
        msg_guide = create_guide_message()
        if send_to_channel:
            send_telegram_long(msg_guide, config, chat_id=channel_id)
        send_telegram_long(msg_guide, config, chat_id=private_id)
        log(f"ğŸ“– íˆ¬ì ê°€ì´ë“œ ì „ì†¡ ì™„ë£Œ â†’ {dest}")

        # [1/4] ì‹œì¥ í˜„í™©
        if msg_market:
            if send_to_channel:
                send_telegram_long(msg_market, config, chat_id=channel_id)
            send_telegram_long(msg_market, config, chat_id=private_id)
            log(f"[1/4] ì‹œì¥ í˜„í™© ì „ì†¡ ì™„ë£Œ â†’ {dest}")

        # [2/4] ë§¤ìˆ˜ í›„ë³´
        if msg_candidates:
            if send_to_channel:
                send_telegram_long(msg_candidates, config, chat_id=channel_id)
            send_telegram_long(msg_candidates, config, chat_id=private_id)
            log(f"[2/4] ë§¤ìˆ˜ í›„ë³´ ì „ì†¡ ì™„ë£Œ â†’ {dest}")

        # [3/4] AI ë¦¬ìŠ¤í¬ í•„í„°
        biz_day = get_last_business_day()
        msg_ai = run_ai_analysis(config, results_df=results_df, status_map=status_map, biz_day=biz_day, risk_status=risk_status, earnings_map=earnings_map)
        if msg_ai:
            if send_to_channel:
                send_telegram_long(msg_ai, config, chat_id=channel_id)
            send_telegram_long(msg_ai, config, chat_id=private_id)
            log(f"[3/4] AI ë¦¬ìŠ¤í¬ í•„í„° ì „ì†¡ ì™„ë£Œ â†’ {dest}")

        # [4/4] ìµœì¢… ì¶”ì²œ
        msg_portfolio = run_portfolio_recommendation(config, results_df, status_map, biz_day=biz_day, risk_status=risk_status, weighted_ranks=weighted_ranks, earnings_map=earnings_map)
        if msg_portfolio:
            if send_to_channel:
                send_telegram_long(msg_portfolio, config, chat_id=channel_id)
            send_telegram_long(msg_portfolio, config, chat_id=private_id)
            log(f"[4/4] ìµœì¢… ì¶”ì²œ ì „ì†¡ ì™„ë£Œ â†’ {dest}")

        # ì‹œìŠ¤í…œ ë¡œê·¸ â†’ ê°œì¸ë´‡ì—ë§Œ (í•­ìƒ)
        send_telegram_long(msg_log, config, chat_id=private_id)
        log("ì‹œìŠ¤í…œ ë¡œê·¸ ì „ì†¡ ì™„ë£Œ â†’ ê°œì¸ë´‡")

    # 5. Git commit/push
    git_commit_push(config)

    # ì™„ë£Œ
    elapsed = (datetime.now() - start_time).total_seconds()
    log("=" * 60)
    log(f"ì „ì²´ ì™„ë£Œ: {elapsed:.1f}ì´ˆ ì†Œìš”")
    log("=" * 60)

    return 0


if __name__ == '__main__':
    sys.exit(main())
