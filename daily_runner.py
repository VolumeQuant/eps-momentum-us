"""
EPS Momentum Daily Runner v9.0 - NTM EPS ì‹œìŠ¤í…œ

ê¸°ëŠ¥:
1. NTM EPS ì „ ì¢…ëª© ìˆ˜ì§‘ & DB ì ì¬
2. í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ 4ì¢… ìƒì„± & ë°œì†¡
   - Part 1: ì´ìµ ëª¨ë©˜í…€ ë­í‚¹ (ì±„ë„/ê°œì¸ë´‡)
   - Part 2: ë§¤ìˆ˜ í›„ë³´ â€” ê´´ë¦¬ìœ¨+ì˜ê²¬ (ì±„ë„/ê°œì¸ë´‡)
   - AI ë¦¬ìŠ¤í¬ ì²´í¬ (ê°œì¸ë´‡) â€” Gemini 2.5 Flash + Google Search
   - ì‹œìŠ¤í…œ ë¡œê·¸ (ê°œì¸ë´‡)
3. Git ìë™ commit/push

ì‹¤í–‰: python daily_runner.py
"""

import os
import sys
import io
import json
import sqlite3
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
try:
    import pytz
    HAS_PYTZ = True
except ImportError:
    HAS_PYTZ = False
import warnings
warnings.filterwarnings('ignore')

# Windowsì—ì„œ UTF-8 ì¸ì½”ë”© ê°•ì œ ì ìš© (ì´ëª¨ì§€ ì§€ì›)
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent
DB_PATH = PROJECT_ROOT / 'eps_momentum_data.db'
CONFIG_PATH = PROJECT_ROOT / 'config.json'

# ê¸°ë³¸ ì„¤ì •
DEFAULT_CONFIG = {
    "git_enabled": True,
    "git_remote": "origin",
    "git_branch": "master",
    "telegram_enabled": False,
    "telegram_bot_token": "",
    "telegram_chat_id": "",
    "telegram_channel_id": "",
    "telegram_private_id": "",
}


def load_config():
    """ì„¤ì • ë¡œë“œ (config.json â†’ í™˜ê²½ë³€ìˆ˜ ìˆœìœ¼ë¡œ ì²´í¬)"""
    if CONFIG_PATH.exists():
        with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
            config = json.load(f)
            for key, value in DEFAULT_CONFIG.items():
                if key not in config:
                    config[key] = value
    else:
        with open(CONFIG_PATH, 'w', encoding='utf-8') as f:
            json.dump(DEFAULT_CONFIG, f, indent=2, ensure_ascii=False)
        config = DEFAULT_CONFIG.copy()

    # í™˜ê²½ë³€ìˆ˜ ì˜¤ë²„ë¼ì´ë“œ (GitHub Actionsìš©)
    if os.environ.get('TELEGRAM_BOT_TOKEN'):
        config['telegram_bot_token'] = os.environ['TELEGRAM_BOT_TOKEN']
        config['telegram_enabled'] = True
    if os.environ.get('TELEGRAM_CHAT_ID'):
        config['telegram_channel_id'] = os.environ['TELEGRAM_CHAT_ID']
    if os.environ.get('TELEGRAM_PRIVATE_ID'):
        config['telegram_private_id'] = os.environ['TELEGRAM_PRIVATE_ID']
        config['telegram_chat_id'] = os.environ['TELEGRAM_PRIVATE_ID']

    config['is_github_actions'] = bool(os.environ.get('GITHUB_ACTIONS'))

    # Gemini API í‚¤ (AI ë¶„ì„ìš©)
    if os.environ.get('GEMINI_API_KEY'):
        config['gemini_api_key'] = os.environ['GEMINI_API_KEY']

    return config


def log(message, level="INFO"):
    """ë¡œê·¸ ì¶œë ¥"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] [{level}] {message}")


# ============================================================
# NTM EPS ë°ì´í„° ìˆ˜ì§‘
# ============================================================

def init_ntm_database():
    """ntm_screening í…Œì´ë¸” ìƒì„±"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    cursor.execute('''
        CREATE TABLE IF NOT EXISTS ntm_screening (
            date        TEXT,
            ticker      TEXT,
            rank        INTEGER,
            score       REAL,
            ntm_current REAL,
            ntm_7d      REAL,
            ntm_30d     REAL,
            ntm_60d     REAL,
            ntm_90d     REAL,
            is_turnaround INTEGER DEFAULT 0,
            PRIMARY KEY (date, ticker)
        )
    ''')

    # ê¸°ì¡´ eps_snapshots í…Œì´ë¸” ì‚­ì œ
    cursor.execute('DROP TABLE IF EXISTS eps_snapshots')

    conn.commit()
    conn.close()
    log("NTM ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")


def run_ntm_collection(config):
    """NTM EPS ì „ ì¢…ëª© ìˆ˜ì§‘ & DB ì ì¬

    ìµœì í™”:
    - ê°€ê²© ë°ì´í„°: yf.download() ì¼ê´„ ë‹¤ìš´ë¡œë“œ (ë‚´ì¥ ìŠ¤ë ˆë”©)
    - ì¢…ëª© ì •ë³´: JSON ìºì‹œ (shortName, industry)
    - EPS ë°ì´í„°: ìˆœì°¨ ì²˜ë¦¬ (yfinance ìŠ¤ë ˆë”© ë¹„í˜¸í™˜)

    Returns:
        tuple (results_df, turnaround_df, stats_dict)
    """
    import yfinance as yf
    import pandas as pd

    from eps_momentum_system import (
        INDICES, INDUSTRY_MAP,
        calculate_ntm_eps, calculate_ntm_score, calculate_eps_change_90d,
        get_trend_lights,
    )

    init_ntm_database()

    today = datetime.now()
    today_str = today.strftime('%Y-%m-%d')

    all_tickers = sorted(set(t for tlist in INDICES.values() for t in tlist))
    log(f"ìœ ë‹ˆë²„ìŠ¤: {len(all_tickers)}ê°œ ì¢…ëª©")

    # Step 1: ì¢…ëª© ì •ë³´ ìºì‹œ ë¡œë“œ
    cache_path = PROJECT_ROOT / 'ticker_info_cache.json'
    ticker_cache = {}
    if cache_path.exists():
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                ticker_cache = json.load(f)
            log(f"ì¢…ëª© ì •ë³´ ìºì‹œ ë¡œë“œ: {len(ticker_cache)}ê°œ")
        except Exception:
            ticker_cache = {}

    # Step 2: ê°€ê²© ë°ì´í„° ì¼ê´„ ë‹¤ìš´ë¡œë“œ
    log("ê°€ê²© ë°ì´í„° ì¼ê´„ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    hist_all = None
    try:
        hist_all = yf.download(all_tickers, period='6mo', threads=True, progress=False)
        log("ê°€ê²© ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        log(f"ì¼ê´„ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}, ê°œë³„ ë‹¤ìš´ë¡œë“œë¡œ ì „í™˜", "WARN")

    # Step 3: ì¢…ëª©ë³„ EPS ë°ì´í„° ìˆœì°¨ ìˆ˜ì§‘
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    results = []
    turnaround = []
    no_data = []
    errors = []
    cache_updated = False

    for i, ticker in enumerate(all_tickers):
        if (i + 1) % 100 == 0:
            log(f"  ìˆ˜ì§‘ ì§„í–‰: {i+1}/{len(all_tickers)} (ë©”ì¸: {len(results)}, í„´ì–´ë¼ìš´ë“œ: {len(turnaround)})")
            conn.commit()

        try:
            stock = yf.Ticker(ticker)

            # NTM EPS ê³„ì‚°
            ntm = calculate_ntm_eps(stock, today)
            if ntm is None:
                no_data.append(ticker)
                continue

            # Score ê³„ì‚°
            score, seg1, seg2, seg3, seg4, is_turnaround, adj_score, direction = calculate_ntm_score(ntm)
            eps_change_90d = calculate_eps_change_90d(ntm)
            trend_lights, trend_desc = get_trend_lights(seg1, seg2, seg3, seg4)

            # EPS Revision ë°ì´í„° ì¶”ì¶œ (ì´ë¯¸ ìºì‹œëœ _earnings_trendì—ì„œ)
            rev_up30 = 0
            rev_down30 = 0
            try:
                raw_trend = stock._analysis._earnings_trend
                if raw_trend:
                    for item in raw_trend:
                        if item.get('period') == '0y':
                            eps_rev = item.get('epsRevisions', {})
                            up_data = eps_rev.get('upLast30days', {})
                            down_data = eps_rev.get('downLast30days', {})
                            rev_up30 = up_data.get('raw', 0) if isinstance(up_data, dict) else 0
                            rev_down30 = down_data.get('raw', 0) if isinstance(down_data, dict) else 0
                            break
            except Exception:
                pass

            # DB ì ì¬
            cursor.execute('''
                INSERT OR REPLACE INTO ntm_screening
                (date, ticker, rank, score, ntm_current, ntm_7d, ntm_30d, ntm_60d, ntm_90d, is_turnaround)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (today_str, ticker, 0, score,
                  ntm['current'], ntm['7d'], ntm['30d'], ntm['60d'], ntm['90d'],
                  1 if is_turnaround else 0))

            # ì¢…ëª© ì •ë³´ (ìºì‹œ ìš°ì„ , ì—†ìœ¼ë©´ API í˜¸ì¶œ)
            if ticker in ticker_cache:
                short_name = ticker_cache[ticker]['shortName']
                industry_kr = ticker_cache[ticker]['industry']
            else:
                info = stock.info
                short_name = info.get('shortName', ticker)
                industry_en = info.get('industry', 'N/A')
                industry_kr = INDUSTRY_MAP.get(industry_en, industry_en)
                ticker_cache[ticker] = {'shortName': short_name, 'industry': industry_kr}
                cache_updated = True

            # ê°€ê²© & ë‹¤ì¤‘ ì£¼ê¸° ê´´ë¦¬ìœ¨ (ì¼ê´„ ë‹¤ìš´ë¡œë“œ ë°ì´í„° ì‚¬ìš©)
            fwd_pe_now = None
            fwd_pe_chg = None  # ê°€ì¤‘í‰ê·  ê´´ë¦¬ìœ¨
            price_chg = None
            price_chg_weighted = None
            eps_chg_weighted = None

            try:
                if hist_all is not None:
                    hist = hist_all['Close'][ticker].dropna()
                else:
                    h = stock.history(period='6mo')
                    hist = h['Close']

                if len(hist) >= 60:
                    p_now = hist.iloc[-1]
                    hist_dt = hist.index.tz_localize(None) if hist.index.tz else hist.index

                    # ê° ì‹œì ì˜ ì£¼ê°€ ì°¾ê¸°
                    prices = {}
                    for days, key in [(7, '7d'), (30, '30d'), (60, '60d'), (90, '90d')]:
                        target = today - timedelta(days=days)
                        idx = (hist_dt - target).map(lambda x: abs(x.days)).argmin()
                        prices[key] = hist.iloc[idx]

                    # 90ì¼ ì£¼ê°€ë³€í™”ìœ¨ (ë‚´ë¶€ìš©)
                    price_chg = (p_now - prices['90d']) / prices['90d'] * 100

                    # ê°€ì¤‘í‰ê·  ì£¼ê°€ë³€í™”ìœ¨ (âš ï¸ ê²½ê³  íŒë³„ìš©)
                    price_w = {'7d': 0.4, '30d': 0.3, '60d': 0.2, '90d': 0.1}
                    pw_sum = sum(
                        w * (p_now - prices[k]) / prices[k] * 100
                        for k, w in price_w.items() if prices[k] > 0
                    )
                    pw_total = sum(w for k, w in price_w.items() if prices[k] > 0)
                    price_chg_weighted = pw_sum / pw_total if pw_total > 0 else None

                    # ê°€ì¤‘í‰ê·  EPSë³€í™”ìœ¨ (âš ï¸ ê²½ê³  íŒë³„ìš©)
                    nc_val = ntm['current']
                    eps_w = {'7d': 0.4, '30d': 0.3, '60d': 0.2, '90d': 0.1}
                    ew_sum = sum(
                        w * (nc_val - ntm[k]) / abs(ntm[k]) * 100
                        for k, w in eps_w.items() if ntm[k] != 0
                    )
                    ew_total = sum(w for k, w in eps_w.items() if ntm[k] != 0)
                    eps_chg_weighted = ew_sum / ew_total if ew_total > 0 else None

                    # í˜„ì¬ Fwd PE
                    nc = ntm['current']
                    if nc > 0:
                        fwd_pe_now = p_now / nc

                    # ê° ì£¼ê¸°ë³„ ê´´ë¦¬ìœ¨ â†’ ê°€ì¤‘í‰ê· 
                    weights = {'7d': 0.4, '30d': 0.3, '60d': 0.2, '90d': 0.1}
                    weighted_sum = 0.0
                    total_weight = 0.0

                    for key, w in weights.items():
                        ntm_val = ntm[key]
                        if nc > 0 and ntm_val > 0 and prices[key] > 0:
                            fwd_pe_then = prices[key] / ntm_val
                            pe_chg_period = (fwd_pe_now - fwd_pe_then) / fwd_pe_then * 100
                            weighted_sum += w * pe_chg_period
                            total_weight += w

                    if total_weight > 0:
                        fwd_pe_chg = weighted_sum / total_weight
            except Exception as e:
                log(f"  {ticker} ê°€ê²©/PE ê³„ì‚° ì‹¤íŒ¨: {e}", "WARN")

            row = {
                'ticker': ticker,
                'short_name': short_name,
                'industry': industry_kr,
                'score': score,
                'adj_score': adj_score,
                'direction': direction,
                'seg1': seg1, 'seg2': seg2, 'seg3': seg3, 'seg4': seg4,
                'ntm_cur': ntm['current'],
                'ntm_7d': ntm['7d'],
                'ntm_30d': ntm['30d'],
                'ntm_60d': ntm['60d'],
                'ntm_90d': ntm['90d'],
                'eps_change_90d': eps_change_90d,
                'trend_lights': trend_lights,
                'trend_desc': trend_desc,
                'price_chg': price_chg,
                'price_chg_weighted': price_chg_weighted,
                'eps_chg_weighted': eps_chg_weighted,
                'fwd_pe': fwd_pe_now,
                'fwd_pe_chg': fwd_pe_chg,
                'is_turnaround': is_turnaround,
                'rev_up30': rev_up30,
                'rev_down30': rev_down30,
            }

            if is_turnaround:
                turnaround.append(row)
            else:
                results.append(row)

        except Exception as e:
            errors.append((ticker, str(e)))
            continue

    conn.commit()

    # ì¢…ëª© ì •ë³´ ìºì‹œ ì €ì¥
    if cache_updated:
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump(ticker_cache, f, ensure_ascii=False, indent=2)
        log(f"ì¢…ëª© ì •ë³´ ìºì‹œ ì €ì¥: {len(ticker_cache)}ê°œ")

    # ë©”ì¸ ë­í‚¹: adj_score(ë°©í–¥ ë³´ì • ì ìˆ˜) ìˆœ ì •ë ¬ + rank ì—…ë°ì´íŠ¸
    results_df = pd.DataFrame(results)
    if not results_df.empty:
        results_df = results_df.sort_values('adj_score', ascending=False).reset_index(drop=True)
        results_df['rank'] = results_df.index + 1

        for _, row in results_df.iterrows():
            cursor.execute(
                'UPDATE ntm_screening SET rank = ? WHERE date = ? AND ticker = ?',
                (int(row['rank']), today_str, row['ticker'])
            )

    # í„´ì–´ë¼ìš´ë“œ: score ìˆœ ì •ë ¬
    turnaround_df = pd.DataFrame(turnaround)
    if not turnaround_df.empty:
        turnaround_df = turnaround_df.sort_values('score', ascending=False).reset_index(drop=True)

    conn.commit()
    conn.close()

    # í†µê³„
    stats = {
        'universe': len(all_tickers),
        'main_count': len(results),
        'turnaround_count': len(turnaround),
        'no_data_count': len(no_data),
        'error_count': len(errors),
        'error_tickers': [t for t, _ in errors],
        'total_collected': len(results) + len(turnaround),
    }

    if not results_df.empty:
        stats['score_gt0'] = int((results_df['score'] > 0).sum())
        stats['score_gt3'] = int((results_df['score'] > 3).sum())
        stats['aligned_count'] = int((~results_df['trend_lights'].str.contains('ğŸ”´|ğŸŸ¥')).sum())

    log(f"ìˆ˜ì§‘ ì™„ë£Œ: ë©”ì¸ {len(results)}, í„´ì–´ë¼ìš´ë“œ {len(turnaround)}, "
        f"ë°ì´í„°ì—†ìŒ {len(no_data)}, ì—ëŸ¬ {len(errors)}")

    return results_df, turnaround_df, stats


# ============================================================
# Git ìë™ ì»¤ë°‹
# ============================================================

def git_commit_push(config):
    """Git ìë™ commit/push (GitHub Actionsì—ì„œëŠ” ì›Œí¬í”Œë¡œìš°ê°€ ì²˜ë¦¬)"""
    if not config.get('git_enabled', False):
        log("Git ë™ê¸°í™” ë¹„í™œì„±í™”ë¨")
        return False

    if config.get('is_github_actions', False):
        log("GitHub Actions í™˜ê²½ â€” ì›Œí¬í”Œë¡œìš°ì—ì„œ Git ì²˜ë¦¬")
        return True

    log("Git commit/push ì‹œì‘")

    try:
        today = datetime.now().strftime('%Y-%m-%d')

        subprocess.run(['git', 'add', '-A'], cwd=PROJECT_ROOT, check=True, capture_output=True)

        commit_msg = f"Daily update: {today}"
        result = subprocess.run(
            ['git', 'commit', '-m', commit_msg],
            cwd=PROJECT_ROOT, capture_output=True, text=True
        )

        if 'nothing to commit' in result.stdout or 'nothing to commit' in result.stderr:
            log("ë³€ê²½ì‚¬í•­ ì—†ìŒ, ì»¤ë°‹ ìŠ¤í‚µ")
            return True

        remote = config.get('git_remote', 'origin')
        branch = config.get('git_branch', 'master')
        subprocess.run(['git', 'push', remote, branch], cwd=PROJECT_ROOT, check=True, capture_output=True)

        log("Git push ì™„ë£Œ")
        return True

    except subprocess.CalledProcessError as e:
        log(f"Git ì˜¤ë¥˜: {e}", "ERROR")
        return False


# ============================================================
# í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ìƒì„±
# ============================================================

def get_last_business_day():
    """ê°€ì¥ ìµœê·¼ ë¯¸êµ­ ì˜ì—…ì¼ ë‚ ì§œ"""
    if HAS_PYTZ:
        eastern = pytz.timezone('US/Eastern')
        now_et = datetime.now(eastern)
    else:
        now_et = datetime.now() - timedelta(hours=14)

    d = now_et.date()
    # í‰ì¼ ì¥ë§ˆê° í›„(16ì‹œ ì´í›„)ë©´ ì˜¤ëŠ˜ì´ ì˜ì—…ì¼
    if d.weekday() < 5 and now_et.hour >= 16:
        return d
    # ê·¸ ì™¸: ì „ì¼ë¡œ ê°€ì„œ ê°€ì¥ ìµœê·¼ í‰ì¼ ì°¾ê¸°
    d -= timedelta(days=1)
    while d.weekday() >= 5:
        d -= timedelta(days=1)
    return d


def get_today_kst():
    """ì˜¤ëŠ˜ ë‚ ì§œ (KST)"""
    if HAS_PYTZ:
        kst = pytz.timezone('Asia/Seoul')
        return datetime.now(kst).date()
    return datetime.now().date()


def create_part1_message(df, top_n=30):
    """Part 1: ì´ìµ ëª¨ë©˜í…€ ë­í‚¹ ë©”ì‹œì§€ ìƒì„± (EPS ì ìˆ˜ ìˆœ)"""
    today = get_today_kst()
    biz_day = get_last_business_day()
    today_str = today.strftime('%mì›”%dì¼')
    biz_str = biz_day.strftime('%Yë…„ %mì›” %dì¼')

    lines = []
    lines.append(f'ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜({today_str}) EPS ëª¨ë©˜í…€ ë¦¬í¬íŠ¸ì˜ˆìš” ğŸ“Š')
    lines.append('')
    lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    lines.append(f'      ğŸ“ˆ EPS ëª¨ë©˜í…€ Top {top_n}')
    lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    lines.append(f'ğŸ“… {biz_str} (ë¯¸êµ­ì¥ ê¸°ì¤€)')
    lines.append('')
    lines.append('ì›”ê°€ ì• ë„ë¦¬ìŠ¤íŠ¸ë“¤ì˜')
    lines.append('EPS ì „ë§ì¹˜(í–¥í›„ 12ê°œì›” ì£¼ë‹¹ìˆœì´ìµ ì˜ˆìƒ)ë¥¼')
    lines.append('ê°€ì¥ ë§ì´ ì˜¬ë¦° ê¸°ì—… ìˆœìœ„ì˜ˆìš”.')
    lines.append('EPS ì „ë§ì¹˜ ìƒí–¥ì€ ì‹¤ì  ì„œí”„ë¼ì´ì¦ˆì™€')
    lines.append('ì£¼ê°€ ìƒìŠ¹ì˜ ê°•ë ¥í•œ ì„ í–‰ ì‹ í˜¸ì˜ˆìš”.')
    lines.append('')
    lines.append('ğŸ’¡ <b>ì½ëŠ” ë²•</b>')
    lines.append('EPS ì ìˆ˜ = 90ì¼ê°„ 4êµ¬ê°„ ìƒìŠ¹ë¥ ì˜ í•©')
    lines.append('ì ìˆ˜ê°€ ë†’ì•„ë„ ğŸ”´ì´ ìˆìœ¼ë©´ ìµœê·¼ ì£¼ì˜!')
    lines.append('')
    lines.append('ì‹ í˜¸ë“± = êµ¬ê°„ë³„ EPS ë³€í™” (ì™¼â†’ì˜¤)')
    lines.append('90â†’60ì¼ | 60â†’30ì¼ | 30â†’7ì¼ | 7ì¼â†’ì˜¤ëŠ˜')
    lines.append('ğŸŸ© í­ë°œ(20%â†‘) ğŸŸ¢ ìƒìŠ¹(2~20%)')
    lines.append('ğŸ”µ ì–‘í˜¸(0.5~2%) ğŸŸ¡ ë³´í•©(0~0.5%)')
    lines.append('ğŸ”´ í•˜ë½(0~-10%) ğŸŸ¥ ê¸‰ë½(-10%â†“)')
    lines.append('ë„¤ëª¨(ğŸŸ©ğŸŸ¥) = ë³€ë™í­ í° êµ¬ê°„')
    lines.append('')

    for _, row in df.head(top_n).iterrows():
        rank = int(row['rank'])
        ticker = row['ticker']
        name = row.get('short_name', ticker)
        industry = row.get('industry', '')
        adj_score = row.get('adj_score', row.get('score', 0))
        lights = row.get('trend_lights', '')
        desc = row.get('trend_desc', '')

        lines.append(f'<b>{rank}ìœ„</b> {name} ({ticker})')
        lines.append(f'<i>{industry}</i> Â· {lights} {desc} Â· <b>{adj_score:.1f}</b>ì ')
        lines.append('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')

    return '\n'.join(lines)


def create_part2_message(df, top_n=30):
    """Part 2: ë§¤ìˆ˜ í›„ë³´ ë©”ì‹œì§€ ìƒì„± (ê´´ë¦¬ìœ¨ ìˆœ, adj_score > 9 í•„í„°)"""
    import pandas as pd

    today = get_today_kst()
    biz_day = get_last_business_day()
    today_str = today.strftime('%mì›”%dì¼')
    biz_str = biz_day.strftime('%Yë…„ %mì›” %dì¼')

    # adj_score > 9 í•„í„° (ë°©í–¥ ë³´ì • ì ìš©, EPS ëª¨ë©˜í…€ + íŒ¨í„´ í’ˆì§ˆ)
    filtered = df[df['adj_score'] > 9].copy()

    # ê´´ë¦¬ìœ¨(fwd_pe_chg) ìˆëŠ” ê²ƒë§Œ + Fwd PE > 0 + EPS ë³€í™” ì–‘ìˆ˜
    filtered = filtered[
        filtered['fwd_pe_chg'].notna() &
        filtered['fwd_pe'].notna() &
        (filtered['fwd_pe'] > 0) &
        (filtered['eps_change_90d'] > 0)
    ].copy()

    # ê´´ë¦¬ìœ¨ ì˜¤ë¦„ì°¨ìˆœ (ë” ë§ˆì´ë„ˆìŠ¤ = ë” ì¢‹ì€ ë§¤ìˆ˜ ê¸°íšŒ)
    filtered = filtered.sort_values('fwd_pe_chg').head(top_n)

    count = min(top_n, len(filtered))

    lines = []
    lines.append(f'ì˜¤ëŠ˜({today_str})ì˜ í•µì‹¬ ë¦¬í¬íŠ¸ì˜ˆìš” ğŸ’°')
    lines.append('')
    lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    lines.append(f'      ğŸ’° ë§¤ìˆ˜ í›„ë³´ Top {count}')
    lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    lines.append(f'ğŸ“… {biz_str} (ë¯¸êµ­ì¥ ê¸°ì¤€)')
    lines.append('')
    lines.append('EPS ì „ë§ì¹˜ëŠ” ì¢‹ì•„ì¡ŒëŠ”ë°')
    lines.append('ì£¼ê°€ê°€ ì•„ì§ ëª» ë”°ë¼ê°„ ì¢…ëª©ì´ì—ìš”.')
    lines.append('')
    lines.append('ğŸ’¡ <b>ì½ëŠ” ë²•</b>')
    lines.append('EPSÂ·ì£¼ê°€ = 90ì¼ ë³€í™”ìœ¨')
    lines.append('ê´´ë¦¬ = EPS ëŒ€ë¹„ ì£¼ê°€ ë¯¸ë°˜ì˜ë„ (ìˆœìœ„ ê¸°ì¤€)')
    lines.append('ì˜ê²¬ â†‘â†“ = 30ì¼ê°„ EPS ìƒí–¥/í•˜í–¥ ì• ë„ë¦¬ìŠ¤íŠ¸ ìˆ˜')
    lines.append('âš ï¸ = ì¶”ê°€ í™•ì¸ í•„ìš”')
    lines.append('')
    lines.append('ì‹ í˜¸ë“± = êµ¬ê°„ë³„ EPS ë³€í™” (ì™¼â†’ì˜¤)')
    lines.append('90â†’60ì¼ | 60â†’30ì¼ | 30â†’7ì¼ | 7ì¼â†’ì˜¤ëŠ˜')
    lines.append('ğŸŸ© í­ë°œ(20%â†‘) ğŸŸ¢ ìƒìŠ¹(2~20%)')
    lines.append('ğŸ”µ ì–‘í˜¸(0.5~2%) ğŸŸ¡ ë³´í•©(0~0.5%)')
    lines.append('ğŸ”´ í•˜ë½(0~-10%) ğŸŸ¥ ê¸‰ë½(-10%â†“)')
    lines.append('')

    for idx, (_, row) in enumerate(filtered.iterrows()):
        rank = idx + 1
        ticker = row['ticker']
        name = row.get('short_name', ticker)
        industry = row.get('industry', '')
        lights = row.get('trend_lights', '')
        desc = row.get('trend_desc', '')
        eps_90d = row.get('eps_change_90d')
        price_90d = row.get('price_chg')
        fwd_pe_chg = row.get('fwd_pe_chg')

        # Line 3: EPS / ì£¼ê°€ / ê´´ë¦¬
        change_str = ''
        if pd.notna(eps_90d) and pd.notna(price_90d):
            change_str = f"EPS {eps_90d:+.1f}% / ì£¼ê°€ {price_90d:+.1f}%"
            if pd.notna(fwd_pe_chg):
                change_str += f" Â· ê´´ë¦¬ {fwd_pe_chg:+.1f}"

        # Line 4: ì˜ê²¬ â†‘N â†“N
        rev_up = row.get('rev_up30', 0) or 0
        rev_down = row.get('rev_down30', 0) or 0
        opinion_str = f"ì˜ê²¬ â†‘{rev_up} â†“{rev_down}"

        # âš ï¸ íŒë³„: EPS > 0ì´ê³  ì£¼ê°€ < 0ì¼ ë•Œ, |ì£¼ê°€ë³€í™”| / |EPSë³€í™”| > 5
        eps_chg_w = row.get('eps_chg_weighted')
        price_chg_w = row.get('price_chg_weighted')
        is_warning = False
        if (pd.notna(eps_chg_w) and pd.notna(price_chg_w)
                and eps_chg_w > 0 and price_chg_w < 0):
            ratio = abs(price_chg_w) / abs(eps_chg_w)
            if ratio > 5:
                is_warning = True

        warn_mark = ' âš ï¸' if is_warning else ''
        lines.append(f'<b>{rank}ìœ„</b> {name} ({ticker}){warn_mark}')
        lines.append(f'<i>{industry}</i> Â· {lights} {desc}')
        lines.append(change_str)
        lines.append(opinion_str)
        lines.append('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')

    lines.append('ì£¼ê°€ í•˜ë½ì—ëŠ” í•­ìƒ ì´ìœ ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ')
    lines.append('ë‰´ìŠ¤ì™€ ì‹¤ì  ë°œí‘œ ì¼ì •ì„ ê¼­ í™•ì¸í•˜ì„¸ìš”.')

    return '\n'.join(lines)


def create_system_log_message(stats, elapsed, config):
    """ì‹œìŠ¤í…œ ì‹¤í–‰ ë¡œê·¸ ë©”ì‹œì§€ ìƒì„±"""
    now = datetime.now()
    if HAS_PYTZ:
        kst = pytz.timezone('Asia/Seoul')
        now = datetime.now(kst)
    time_str = now.strftime('%Y.%m.%d %H:%M')

    env = 'GitHub Actions' if config.get('is_github_actions') else 'Local'
    minutes = int(elapsed // 60)
    seconds = int(elapsed % 60)

    main_cnt = stats.get('main_count', 0)
    turn_cnt = stats.get('turnaround_count', 0)
    err = stats.get('error_count', 0)

    lines = [f'ğŸ”§ <b>ì‹œìŠ¤í…œ ë¡œê·¸</b>']
    lines.append(f'{time_str} KST Â· {env}\n')

    lines.append(f'ìˆ˜ì§‘ {main_cnt + turn_cnt}/{stats.get("universe", 0)} (ì—ëŸ¬ {err})')
    lines.append(f'â”œ ë©”ì¸ {main_cnt}')
    lines.append(f'â”” í„´ì–´ë¼ìš´ë“œ {turn_cnt}')

    if err > 0:
        error_tickers = stats.get('error_tickers', [])
        lines.append(f'ì—ëŸ¬: {", ".join(error_tickers)}')

    lines.append('')
    lines.append(f'Score &gt; 0: {stats.get("score_gt0", 0)} ({stats.get("score_gt0", 0) * 100 // max(main_cnt, 1)}%)')
    lines.append(f'Score &gt; 3: {stats.get("score_gt3", 0)} ({stats.get("score_gt3", 0) * 100 // max(main_cnt, 1)}%)')
    lines.append(f'ì „êµ¬ê°„ ì–‘í˜¸(ğŸ”´ğŸŸ¥ ì—†ìŒ): {stats.get("aligned_count", 0)}')

    lines.append(f'\nì†Œìš”: {minutes}ë¶„ {seconds}ì´ˆ')

    return '\n'.join(lines)


# ============================================================
# AI ë¦¬ìŠ¤í¬ ì²´í¬ (Gemini 2.5 Flash + Google Search)
# ============================================================

def run_ai_analysis(msg_part1, msg_part2, msg_turnaround, config, results_df=None):
    """AI ë¸Œë¦¬í•‘ â€” ë§¤ìˆ˜ í›„ë³´ ë‰´ìŠ¤ ê¸°ë°˜ ë¦¬ìŠ¤í¬ ì²´í¬ (ê²€ìƒ‰ì€ ì½”ë“œê°€, ë¶„ì„ì€ AIê°€)"""
    api_key = config.get('gemini_api_key', '')
    if not api_key:
        log("GEMINI_API_KEY ë¯¸ì„¤ì • â€” AI ë¶„ì„ ìŠ¤í‚µ", "WARN")
        return None

    try:
        from google import genai
        from google.genai import types
    except ImportError:
        log("google-genai íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜ â€” AI ë¶„ì„ ìŠ¤í‚µ", "WARN")
        return None

    try:
        client = genai.Client(api_key=api_key)

        import re
        import yfinance as yf

        # Part 2 ì¢…ëª© ì¶”ì¶œ (ê¸°ì¡´ í•„í„° ë¡œì§)
        part2_stocks = []
        if results_df is not None and not results_df.empty:
            filtered = results_df[results_df['adj_score'] > 9].copy()
            filtered = filtered[
                filtered['fwd_pe_chg'].notna() &
                filtered['fwd_pe'].notna() &
                (filtered['fwd_pe'] > 0) &
                (filtered['eps_change_90d'] > 0)
            ].copy()
            filtered = filtered.sort_values('fwd_pe_chg').head(30)
            for _, row in filtered.iterrows():
                part2_stocks.append((row['ticker'], row.get('industry', 'N/A')))

        if not part2_stocks:
            log("Part 2 ì¢…ëª© ì—†ìŒ â€” AI ë¶„ì„ ìŠ¤í‚µ", "WARN")
            return None

        stock_count = len(part2_stocks)
        today_dt = datetime.now()
        today_str = today_dt.strftime('%Y-%m-%d')
        today_date = today_dt.date()
        week_ago = (today_dt - timedelta(days=7)).date()
        two_weeks_date = (today_dt + timedelta(days=14)).date()

        # ì¢…ëª©ë³„ ë‰´ìŠ¤ + ì–´ë‹ ì¼ì • ìˆ˜ì§‘ (ê°™ì€ Ticker ê°ì²´ ì¬ì‚¬ìš©)
        log("ë‰´ìŠ¤ & ì–´ë‹ ì¼ì • ìˆ˜ì§‘ ì¤‘...")
        news_by_ticker = {}
        earnings_tickers = []

        for ticker, industry in part2_stocks:
            try:
                stock = yf.Ticker(ticker)

                # ì–´ë‹ ì¼ì •
                cal = stock.calendar
                if cal is not None:
                    earn_dates = cal.get('Earnings Date', [])
                    if not isinstance(earn_dates, list):
                        earn_dates = [earn_dates]
                    for ed in earn_dates:
                        if hasattr(ed, 'date'):
                            ed = ed.date()
                        if today_date <= ed <= two_weeks_date:
                            earnings_tickers.append(f"{ticker} {ed.month}/{ed.day}")
                            break

                # ë‰´ìŠ¤ ìˆ˜ì§‘ (ìµœê·¼ 7ì¼, ìµœëŒ€ 5ê±´)
                news_items = []
                raw_news = stock.news or []
                for item in raw_news[:5]:
                    c = item.get('content', {})
                    title = c.get('title', '')
                    summary = c.get('summary', '')
                    pub_date = c.get('pubDate', '')[:10]
                    provider = c.get('provider', {}).get('displayName', '')

                    if not title:
                        continue

                    # 7ì¼ ì´ë‚´ í•„í„°
                    try:
                        from datetime import date as date_type
                        pub = datetime.strptime(pub_date, '%Y-%m-%d').date()
                        if pub < week_ago:
                            continue
                    except (ValueError, TypeError):
                        pass  # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ì‹œ í¬í•¨

                    news_items.append({
                        'title': title,
                        'summary': summary,
                        'date': pub_date,
                        'provider': provider,
                    })

                if news_items:
                    news_by_ticker[ticker] = news_items

            except Exception:
                pass

        log(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {len(news_by_ticker)}/{stock_count}ì¢…ëª©, "
            f"2ì£¼ë‚´ ì–´ë‹: {len(earnings_tickers)}ì¢…ëª©")

        earnings_info = ' Â· '.join(earnings_tickers) if earnings_tickers else 'í•´ë‹¹ ì—†ìŒ'

        # ë‰´ìŠ¤ ë°ì´í„° í¬ë§·íŒ…
        news_sections = []
        no_news_tickers = []
        for ticker, industry in part2_stocks:
            if ticker in news_by_ticker:
                lines = [f"[{ticker} ({industry})]"]
                for n in news_by_ticker[ticker]:
                    date_short = n['date'][5:].replace('-', '/')  # "02/08"
                    lines.append(f"- [{date_short}] {n['title']}")
                    if n['summary']:
                        lines.append(f"  > {n['summary'][:100]}")
                news_sections.append('\n'.join(lines))
            else:
                no_news_tickers.append(ticker)

        news_data = '\n\n'.join(news_sections) if news_sections else 'ë‰´ìŠ¤ ì—†ìŒ'

        # í‹°ì»¤ ëª©ë¡ (ë¦¬ìŠ¤í¬ ë¯¸ë°œê²¬ ë¶„ë¥˜ìš©)
        all_tickers_str = ' Â· '.join(t for t, _ in part2_stocks)

        prompt = f"""ì˜¤ëŠ˜ ë‚ ì§œ: {today_str}

ì•„ë˜ëŠ” EPS ëª¨ë©˜í…€ ì‹œìŠ¤í…œì´ ì„ ì •í•œ ë§¤ìˆ˜ í›„ë³´ {stock_count}ì¢…ëª©ê³¼, ê° ì¢…ëª©ì˜ ìµœê·¼ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì´ì•¼.
ì´ ì¢…ëª©ë“¤ì€ EPS ì „ë§ì¹˜ê°€ ìƒí–¥ë˜ê³  ìˆëŠ” ì¢‹ì€ ì¢…ëª©ë“¤ì´ì•¼. ë„¤ ì—­í• ì€ ì´ ì¤‘ì—ì„œ "ìˆ¨ì€ ë¦¬ìŠ¤í¬"ë¥¼ ì°¾ì•„ë‚´ëŠ” ê±°ì•¼.

[ë§¤ìˆ˜ í›„ë³´ ì „ì²´]
{all_tickers_str}

[ì¢…ëª©ë³„ ìµœê·¼ ë‰´ìŠ¤ â€” ì½”ë“œê°€ Yahoo Financeì—ì„œ ìˆ˜ì§‘]
{news_data}

[ì–´ë‹ ì¼ì • â€” ì½”ë“œê°€ yfinanceì—ì„œ í™•ì¸ ì™„ë£Œ]
{earnings_info}

[ì¶œë ¥ ê·œì¹™]
ì–¸ì–´: í•œêµ­ì–´, ì¹œì ˆí•œ ë§íˆ¬(~ì˜ˆìš”/~í•´ìš”)
ì´ 1500ì ì´ë‚´. ê°„ê²°í•˜ê²Œ.

ğŸ“° ì‹œì¥ ë™í–¥
ì–´ì œ ë¯¸êµ­ ì‹œì¥ ë§ˆê° ë™í–¥ê³¼ ê¸ˆì£¼ ì£¼ìš” ì´ë²¤íŠ¸ë¥¼ Google ê²€ìƒ‰í•´ì„œ 2~3ì¤„ë¡œ ìš”ì•½í•´ì¤˜.

âš ï¸ ë¦¬ìŠ¤í¬ ì²´í¬
ìœ„ ë‰´ìŠ¤ì—ì„œ ì£¼ê°€ì— ë¶€ì •ì  ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ” í•­ëª©ë§Œ ê³¨ë¼ì¤˜:
- ì• ë„ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ê·¸ë ˆì´ë“œ, ëª©í‘œê°€ í•˜í–¥
- ì–´ë‹ ë¯¸ìŠ¤, ê°€ì´ë˜ìŠ¤ í•˜í–¥
- ì†Œì†¡, ê·œì œ, ë‚´ë¶€ì ë§¤ë„
- ëŒ€í­ ì£¼ê°€ í•˜ë½ + ë¶€ì •ì  ì›ì¸

í˜•ì‹: ê° ì¢…ëª© 1ì¤„
í‹°ì»¤ â€” ë¦¬ìŠ¤í¬ ìš”ì•½ (ì¶œì²˜ ë‚ ì§œ)

ì ˆëŒ€ ê¸ˆì§€:
- ìœ„ ë‰´ìŠ¤ì— ì—†ëŠ” ë¦¬ìŠ¤í¬ë¥¼ ì§€ì–´ë‚´ì§€ ë§ˆ
- "ê²½ìŸ ì‹¬í™”", "ê°€ê²© ë³€ë™ì„±" ê°™ì€ ì—…ì¢… ìƒì‹œ ë¦¬ìŠ¤í¬ ê¸ˆì§€
- í˜¸ì¬/ê¸ì • ë‰´ìŠ¤ëŠ” ë¬´ì‹œ (ì‹œìŠ¤í…œì´ ì´ë¯¸ ì¢‹ì€ ì¢…ëª©ì„ ê³¨ëìœ¼ë¯€ë¡œ)
- ë¦¬ìŠ¤í¬ ë‰´ìŠ¤ê°€ ì—†ëŠ” ì¢…ëª©ì€ ì—¬ê¸°ì— ì“°ì§€ ë§ˆ

ğŸ“… ì–´ë‹ ì£¼ì˜
ìœ„ [ì–´ë‹ ì¼ì •]ì„ ê·¸ëŒ€ë¡œ í‘œì‹œ. ìˆ˜ì •/ì¶”ê°€ ê¸ˆì§€. ì–´ë‹ ì¼ì •ì´ "í•´ë‹¹ ì—†ìŒ"ì´ë©´ ì´ ì„¹ì…˜ ìƒëµ.

âœ… ë¦¬ìŠ¤í¬ ë¯¸ë°œê²¬
âš ï¸ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ë‚˜ë¨¸ì§€ ì¢…ëª©ì„ Â· ë¡œ êµ¬ë¶„í•´ì„œ í•œ ì¤„ë¡œ ë‚˜ì—´."""

        grounding_tool = types.Tool(google_search=types.GoogleSearch())
        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt,
            config=types.GenerateContentConfig(
                tools=[grounding_tool],
                temperature=0.2,
            ),
        )

        analysis_text = response.text
        if not analysis_text:
            try:
                if hasattr(response, 'candidates') and response.candidates:
                    candidate = response.candidates[0]
                    log(f"Gemini finish_reason: {candidate.finish_reason}", "WARN")
            except Exception:
                pass
            log("Gemini ì‘ë‹µì´ ë¹„ì–´ìˆìŒ â€” ì¬ì‹œë„", "WARN")
            response = client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt,
                config=types.GenerateContentConfig(
                    tools=[grounding_tool],
                    temperature=0.3,
                ),
            )
            analysis_text = response.text
            if not analysis_text:
                log("Gemini ì¬ì‹œë„ë„ ì‹¤íŒ¨", "WARN")
                return None

        # Markdown â†’ Telegram HTML ë³€í™˜
        analysis_html = analysis_text
        analysis_html = analysis_html.replace('&', '&amp;')
        analysis_html = analysis_html.replace('<', '&lt;')
        analysis_html = analysis_html.replace('>', '&gt;')
        analysis_html = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', analysis_html)
        analysis_html = re.sub(r'(?<!\w)\*(?!\s)(.+?)(?<!\s)\*(?!\w)', r'<i>\1</i>', analysis_html)
        analysis_html = re.sub(r'#{1,3}\s*', '', analysis_html)
        analysis_html = analysis_html.replace('---', 'â”â”â”')

        # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í¬ë§·íŒ…
        now = datetime.now()
        if HAS_PYTZ:
            kst = pytz.timezone('Asia/Seoul')
            now = datetime.now(kst)

        lines = []
        lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
        lines.append('      ğŸ¤– AI ë¸Œë¦¬í•‘')
        lines.append('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
        lines.append(f'ğŸ“… {now.strftime("%Yë…„ %mì›” %dì¼")}')
        lines.append('')
        lines.append('ë§¤ìˆ˜ í›„ë³´ì˜ ìµœê·¼ ë‰´ìŠ¤ë¥¼ AIê°€ ë¶„ì„í•´ì„œ')
        lines.append('ë¦¬ìŠ¤í¬ë¥¼ ì²´í¬í–ˆì–´ìš”. ì°¸ê³ ìš©ì´ì—ìš”!')
        lines.append('')
        lines.append(analysis_html)

        log("AI ë¸Œë¦¬í•‘ ì™„ë£Œ")
        return '\n'.join(lines)

    except Exception as e:
        log(f"AI ë¶„ì„ ì‹¤íŒ¨: {e}", "ERROR")
        return None


# ============================================================
# í…”ë ˆê·¸ë¨ ì „ì†¡
# ============================================================

def send_telegram_long(message, config, chat_id=None):
    """ê¸´ ë©”ì‹œì§€ë¥¼ ì—¬ëŸ¬ ê°œë¡œ ë¶„í• í•´ì„œ ì „ì†¡ (chat_id ì§€ì • ê°€ëŠ¥)"""
    if not config.get('telegram_enabled', False):
        return False

    bot_token = config.get('telegram_bot_token', '')
    if chat_id is None:
        chat_id = config.get('telegram_chat_id', '')

    if not bot_token or not chat_id:
        log("í…”ë ˆê·¸ë¨ ì„¤ì • ë¶ˆì™„ì „", "WARN")
        return False

    try:
        import urllib.request
        import urllib.parse

        # 4000ìì”© ë¶„í• 
        chunks = []
        remaining = message.strip()
        while remaining:
            if len(remaining) <= 4000:
                chunks.append(remaining)
                break
            else:
                split_point = remaining[:4000].rfind('\n')
                if split_point <= 0:
                    split_point = 4000
                chunks.append(remaining[:split_point])
                remaining = remaining[split_point:].strip()

        # ë¹ˆ ì²­í¬ ì œê±°
        chunks = [c for c in chunks if c.strip()]

        for i, chunk in enumerate(chunks):
            url = f"https://api.telegram.org/bot{bot_token}/sendMessage"

            data = urllib.parse.urlencode({
                'chat_id': chat_id,
                'text': chunk,
                'parse_mode': 'HTML'
            }).encode()

            req = urllib.request.Request(url, data=data)
            urllib.request.urlopen(req, timeout=10)

        log(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì™„ë£Œ ({len(chunks)}ê°œ ë©”ì‹œì§€)")
        return True

    except Exception as e:
        log(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}", "ERROR")
        return False


# ============================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================

def main():
    """NTM EPS ì‹œìŠ¤í…œ ë©”ì¸ ì‹¤í–‰"""
    log("=" * 60)
    log("EPS Momentum Daily Runner v9.0 - NTM EPS ì‹œìŠ¤í…œ")
    log("=" * 60)

    start_time = datetime.now()

    # ì„¤ì • ë¡œë“œ
    config = load_config()
    log(f"ì„¤ì • ë¡œë“œ ì™„ë£Œ: {CONFIG_PATH}")

    # 1. NTM ë°ì´í„° ìˆ˜ì§‘ + DB ì ì¬
    log("=" * 60)
    log("NTM EPS ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    log("=" * 60)
    results_df, turnaround_df, stats = run_ntm_collection(config)

    # 2. í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ìƒì„±
    import pandas as pd

    msg_part1 = create_part1_message(results_df) if not results_df.empty else None
    msg_part2 = create_part2_message(results_df) if not results_df.empty else None

    # ì‹¤í–‰ ì‹œê°„
    elapsed = (datetime.now() - start_time).total_seconds()
    msg_log = create_system_log_message(stats, elapsed, config)

    # 3. í…”ë ˆê·¸ë¨ ë°œì†¡
    if config.get('telegram_enabled', False):
        is_github = config.get('is_github_actions', False)
        private_id = config.get('telegram_private_id') or config.get('telegram_chat_id')
        channel_id = config.get('telegram_channel_id')

        # ë°œì†¡ ìˆœì„œ: Part 1 â†’ Part 2 â†’ AI ë¸Œë¦¬í•‘ â†’ ì‹œìŠ¤í…œ ë¡œê·¸

        # Part 1 (ëª¨ë©˜í…€ ë­í‚¹)
        if msg_part1:
            if is_github and channel_id:
                send_telegram_long(msg_part1, config, chat_id=channel_id)
                send_telegram_long(msg_part1, config, chat_id=private_id)
                log("Part 1 (ëª¨ë©˜í…€ ë­í‚¹) ì „ì†¡ ì™„ë£Œ â†’ ì±„ë„+ê°œì¸ë´‡")
            else:
                send_telegram_long(msg_part1, config, chat_id=private_id)
                log("Part 1 (ëª¨ë©˜í…€ ë­í‚¹) ì „ì†¡ ì™„ë£Œ â†’ ê°œì¸ë´‡")

        # Part 2 (ë§¤ìˆ˜ í›„ë³´) â€” í•µì‹¬ ë¦¬í¬íŠ¸
        if msg_part2:
            if is_github and channel_id:
                send_telegram_long(msg_part2, config, chat_id=channel_id)
                send_telegram_long(msg_part2, config, chat_id=private_id)
                log("Part 2 (ë§¤ìˆ˜ í›„ë³´) ì „ì†¡ ì™„ë£Œ â†’ ì±„ë„+ê°œì¸ë´‡")
            else:
                send_telegram_long(msg_part2, config, chat_id=private_id)
                log("Part 2 (ë§¤ìˆ˜ í›„ë³´) ì „ì†¡ ì™„ë£Œ â†’ ê°œì¸ë´‡")

        # AI ë¸Œë¦¬í•‘
        msg_ai = run_ai_analysis(msg_part1, msg_part2, None, config, results_df=results_df)
        if msg_ai:
            if is_github and channel_id:
                send_telegram_long(msg_ai, config, chat_id=channel_id)
                send_telegram_long(msg_ai, config, chat_id=private_id)
                log("AI ë¸Œë¦¬í•‘ ì „ì†¡ ì™„ë£Œ â†’ ì±„ë„+ê°œì¸ë´‡")
            else:
                send_telegram_long(msg_ai, config, chat_id=private_id)
                log("AI ë¸Œë¦¬í•‘ ì „ì†¡ ì™„ë£Œ â†’ ê°œì¸ë´‡")

        # ì‹œìŠ¤í…œ ë¡œê·¸ â†’ ê°œì¸ë´‡ì—ë§Œ (í•­ìƒ)
        send_telegram_long(msg_log, config, chat_id=private_id)
        log("ì‹œìŠ¤í…œ ë¡œê·¸ ì „ì†¡ ì™„ë£Œ â†’ ê°œì¸ë´‡")

    # 4. Git commit/push
    git_commit_push(config)

    # ì™„ë£Œ
    log("=" * 60)
    log(f"ì „ì²´ ì™„ë£Œ: {elapsed:.1f}ì´ˆ ì†Œìš”")
    log("=" * 60)

    return 0


if __name__ == '__main__':
    sys.exit(main())
